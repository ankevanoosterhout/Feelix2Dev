{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n// tslint:disable-next-line:max-line-length\nimport { Constant, GlorotNormal, GlorotUniform, HeNormal, HeUniform, Identity, LeCunNormal, LeCunUniform, Ones, Orthogonal, RandomNormal, RandomUniform, TruncatedNormal, VarianceScaling, Zeros } from './initializers';\n/**\n * Initializer that generates tensors initialized to 0.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function zeros() {\n  return new Zeros();\n}\n/**\n * Initializer that generates tensors initialized to 1.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function ones() {\n  return new Ones();\n}\n/**\n * Initializer that generates values initialized to some constant.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function constant(args) {\n  return new Constant(args);\n}\n/**\n * Initializer that generates random values initialized to a uniform\n * distribution.\n *\n * Values will be distributed uniformly between the configured minval and\n * maxval.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function randomUniform(args) {\n  return new RandomUniform(args);\n}\n/**\n * Initializer that generates random values initialized to a normal\n * distribution.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function randomNormal(args) {\n  return new RandomNormal(args);\n}\n/**\n * Initializer that generates random values initialized to a truncated normal\n * distribution.\n *\n * These values are similar to values from a `RandomNormal` except that values\n * more than two standard deviations from the mean are discarded and re-drawn.\n * This is the recommended initializer for neural network weights and filters.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function truncatedNormal(args) {\n  return new TruncatedNormal(args);\n}\n/**\n * Initializer that generates the identity matrix.\n * Only use for square 2D matrices.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function identity(args) {\n  return new Identity(args);\n}\n/**\n * Initializer capable of adapting its scale to the shape of weights.\n * With distribution=NORMAL, samples are drawn from a truncated normal\n * distribution centered on zero, with `stddev = sqrt(scale / n)` where n is:\n *   - number of input units in the weight tensor, if mode = FAN_IN.\n *   - number of output units, if mode = FAN_OUT.\n *   - average of the numbers of input and output units, if mode = FAN_AVG.\n * With distribution=UNIFORM,\n * samples are drawn from a uniform distribution\n * within [-limit, limit], with `limit = sqrt(3 * scale / n)`.\n *\n * @doc {heading: 'Initializers',namespace: 'initializers'}\n */\n\nexport function varianceScaling(config) {\n  return new VarianceScaling(config);\n}\n/**\n * Glorot uniform initializer, also called Xavier uniform initializer.\n * It draws samples from a uniform distribution within [-limit, limit]\n * where `limit` is `sqrt(6 / (fan_in + fan_out))`\n * where `fan_in` is the number of input units in the weight tensor\n * and `fan_out` is the number of output units in the weight tensor\n *\n * Reference:\n *   Glorot & Bengio, AISTATS 2010\n *       http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function glorotUniform(args) {\n  return new GlorotUniform(args);\n}\n/**\n * Glorot normal initializer, also called Xavier normal initializer.\n * It draws samples from a truncated normal distribution centered on 0\n * with `stddev = sqrt(2 / (fan_in + fan_out))`\n * where `fan_in` is the number of input units in the weight tensor\n * and `fan_out` is the number of output units in the weight tensor.\n *\n * Reference:\n *   Glorot & Bengio, AISTATS 2010\n *       http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function glorotNormal(args) {\n  return new GlorotNormal(args);\n}\n/**\n * He normal initializer.\n *\n * It draws samples from a truncated normal distribution centered on 0\n * with `stddev = sqrt(2 / fanIn)`\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * Reference:\n *     He et al., http://arxiv.org/abs/1502.01852\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function heNormal(args) {\n  return new HeNormal(args);\n}\n/**\n * He uniform initializer.\n *\n * It draws samples from a uniform distribution within [-limit, limit]\n * where `limit` is `sqrt(6 / fan_in)`\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * Reference:\n *     He et al., http://arxiv.org/abs/1502.01852\n *\n * @doc {heading: 'Initializers',namespace: 'initializers'}\n */\n\nexport function heUniform(args) {\n  return new HeUniform(args);\n}\n/**\n * LeCun normal initializer.\n *\n * It draws samples from a truncated normal distribution centered on 0\n * with `stddev = sqrt(1 / fanIn)`\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * References:\n *   [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n *   [Efficient Backprop](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function leCunNormal(args) {\n  return new LeCunNormal(args);\n}\n/**\n * LeCun uniform initializer.\n *\n * It draws samples from a uniform distribution in the interval\n * `[-limit, limit]` with `limit = sqrt(3 / fanIn)`,\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function leCunUniform(args) {\n  return new LeCunUniform(args);\n}\n/**\n * Initializer that generates a random orthogonal matrix.\n *\n * Reference:\n * [Saxe et al., http://arxiv.org/abs/1312.6120](http://arxiv.org/abs/1312.6120)\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\n\nexport function orthogonal(args) {\n  return new Orthogonal(args);\n}","map":{"version":3,"names":["Constant","GlorotNormal","GlorotUniform","HeNormal","HeUniform","Identity","LeCunNormal","LeCunUniform","Ones","Orthogonal","RandomNormal","RandomUniform","TruncatedNormal","VarianceScaling","Zeros","zeros","ones","constant","args","randomUniform","randomNormal","truncatedNormal","identity","varianceScaling","config","glorotUniform","glorotNormal","heNormal","heUniform","leCunNormal","leCunUniform","orthogonal"],"sources":["C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@tensorflow/tfjs-layers/dist/exports_initializers.js"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n// tslint:disable-next-line:max-line-length\nimport { Constant, GlorotNormal, GlorotUniform, HeNormal, HeUniform, Identity, LeCunNormal, LeCunUniform, Ones, Orthogonal, RandomNormal, RandomUniform, TruncatedNormal, VarianceScaling, Zeros } from './initializers';\n/**\n * Initializer that generates tensors initialized to 0.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function zeros() {\n    return new Zeros();\n}\n/**\n * Initializer that generates tensors initialized to 1.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function ones() {\n    return new Ones();\n}\n/**\n * Initializer that generates values initialized to some constant.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function constant(args) {\n    return new Constant(args);\n}\n/**\n * Initializer that generates random values initialized to a uniform\n * distribution.\n *\n * Values will be distributed uniformly between the configured minval and\n * maxval.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function randomUniform(args) {\n    return new RandomUniform(args);\n}\n/**\n * Initializer that generates random values initialized to a normal\n * distribution.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function randomNormal(args) {\n    return new RandomNormal(args);\n}\n/**\n * Initializer that generates random values initialized to a truncated normal\n * distribution.\n *\n * These values are similar to values from a `RandomNormal` except that values\n * more than two standard deviations from the mean are discarded and re-drawn.\n * This is the recommended initializer for neural network weights and filters.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function truncatedNormal(args) {\n    return new TruncatedNormal(args);\n}\n/**\n * Initializer that generates the identity matrix.\n * Only use for square 2D matrices.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function identity(args) {\n    return new Identity(args);\n}\n/**\n * Initializer capable of adapting its scale to the shape of weights.\n * With distribution=NORMAL, samples are drawn from a truncated normal\n * distribution centered on zero, with `stddev = sqrt(scale / n)` where n is:\n *   - number of input units in the weight tensor, if mode = FAN_IN.\n *   - number of output units, if mode = FAN_OUT.\n *   - average of the numbers of input and output units, if mode = FAN_AVG.\n * With distribution=UNIFORM,\n * samples are drawn from a uniform distribution\n * within [-limit, limit], with `limit = sqrt(3 * scale / n)`.\n *\n * @doc {heading: 'Initializers',namespace: 'initializers'}\n */\nexport function varianceScaling(config) {\n    return new VarianceScaling(config);\n}\n/**\n * Glorot uniform initializer, also called Xavier uniform initializer.\n * It draws samples from a uniform distribution within [-limit, limit]\n * where `limit` is `sqrt(6 / (fan_in + fan_out))`\n * where `fan_in` is the number of input units in the weight tensor\n * and `fan_out` is the number of output units in the weight tensor\n *\n * Reference:\n *   Glorot & Bengio, AISTATS 2010\n *       http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function glorotUniform(args) {\n    return new GlorotUniform(args);\n}\n/**\n * Glorot normal initializer, also called Xavier normal initializer.\n * It draws samples from a truncated normal distribution centered on 0\n * with `stddev = sqrt(2 / (fan_in + fan_out))`\n * where `fan_in` is the number of input units in the weight tensor\n * and `fan_out` is the number of output units in the weight tensor.\n *\n * Reference:\n *   Glorot & Bengio, AISTATS 2010\n *       http://jmlr.org/proceedings/papers/v9/glorot10a/glorot10a.pdf\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function glorotNormal(args) {\n    return new GlorotNormal(args);\n}\n/**\n * He normal initializer.\n *\n * It draws samples from a truncated normal distribution centered on 0\n * with `stddev = sqrt(2 / fanIn)`\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * Reference:\n *     He et al., http://arxiv.org/abs/1502.01852\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function heNormal(args) {\n    return new HeNormal(args);\n}\n/**\n * He uniform initializer.\n *\n * It draws samples from a uniform distribution within [-limit, limit]\n * where `limit` is `sqrt(6 / fan_in)`\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * Reference:\n *     He et al., http://arxiv.org/abs/1502.01852\n *\n * @doc {heading: 'Initializers',namespace: 'initializers'}\n */\nexport function heUniform(args) {\n    return new HeUniform(args);\n}\n/**\n * LeCun normal initializer.\n *\n * It draws samples from a truncated normal distribution centered on 0\n * with `stddev = sqrt(1 / fanIn)`\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * References:\n *   [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n *   [Efficient Backprop](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf)\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function leCunNormal(args) {\n    return new LeCunNormal(args);\n}\n/**\n * LeCun uniform initializer.\n *\n * It draws samples from a uniform distribution in the interval\n * `[-limit, limit]` with `limit = sqrt(3 / fanIn)`,\n * where `fanIn` is the number of input units in the weight tensor.\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function leCunUniform(args) {\n    return new LeCunUniform(args);\n}\n/**\n * Initializer that generates a random orthogonal matrix.\n *\n * Reference:\n * [Saxe et al., http://arxiv.org/abs/1312.6120](http://arxiv.org/abs/1312.6120)\n *\n * @doc {heading: 'Initializers', namespace: 'initializers'}\n */\nexport function orthogonal(args) {\n    return new Orthogonal(args);\n}\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,QAAT,EAAmBC,YAAnB,EAAiCC,aAAjC,EAAgDC,QAAhD,EAA0DC,SAA1D,EAAqEC,QAArE,EAA+EC,WAA/E,EAA4FC,YAA5F,EAA0GC,IAA1G,EAAgHC,UAAhH,EAA4HC,YAA5H,EAA0IC,aAA1I,EAAyJC,eAAzJ,EAA0KC,eAA1K,EAA2LC,KAA3L,QAAwM,gBAAxM;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,KAAT,GAAiB;EACpB,OAAO,IAAID,KAAJ,EAAP;AACH;AACD;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASE,IAAT,GAAgB;EACnB,OAAO,IAAIR,IAAJ,EAAP;AACH;AACD;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASS,QAAT,CAAkBC,IAAlB,EAAwB;EAC3B,OAAO,IAAIlB,QAAJ,CAAakB,IAAb,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,aAAT,CAAuBD,IAAvB,EAA6B;EAChC,OAAO,IAAIP,aAAJ,CAAkBO,IAAlB,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASE,YAAT,CAAsBF,IAAtB,EAA4B;EAC/B,OAAO,IAAIR,YAAJ,CAAiBQ,IAAjB,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASG,eAAT,CAAyBH,IAAzB,EAA+B;EAClC,OAAO,IAAIN,eAAJ,CAAoBM,IAApB,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASI,QAAT,CAAkBJ,IAAlB,EAAwB;EAC3B,OAAO,IAAIb,QAAJ,CAAaa,IAAb,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASK,eAAT,CAAyBC,MAAzB,EAAiC;EACpC,OAAO,IAAIX,eAAJ,CAAoBW,MAApB,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,aAAT,CAAuBP,IAAvB,EAA6B;EAChC,OAAO,IAAIhB,aAAJ,CAAkBgB,IAAlB,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASQ,YAAT,CAAsBR,IAAtB,EAA4B;EAC/B,OAAO,IAAIjB,YAAJ,CAAiBiB,IAAjB,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASS,QAAT,CAAkBT,IAAlB,EAAwB;EAC3B,OAAO,IAAIf,QAAJ,CAAae,IAAb,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASU,SAAT,CAAmBV,IAAnB,EAAyB;EAC5B,OAAO,IAAId,SAAJ,CAAcc,IAAd,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASW,WAAT,CAAqBX,IAArB,EAA2B;EAC9B,OAAO,IAAIZ,WAAJ,CAAgBY,IAAhB,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASY,YAAT,CAAsBZ,IAAtB,EAA4B;EAC/B,OAAO,IAAIX,YAAJ,CAAiBW,IAAjB,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASa,UAAT,CAAoBb,IAApB,EAA0B;EAC7B,OAAO,IAAIT,UAAJ,CAAeS,IAAf,CAAP;AACH"},"metadata":{},"sourceType":"module"}