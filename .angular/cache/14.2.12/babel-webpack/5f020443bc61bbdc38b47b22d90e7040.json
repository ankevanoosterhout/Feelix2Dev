{"ast":null,"code":"import _asyncToGenerator from \"C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\n\nvar _standardizeWeights;\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { argMax, clone, dispose, mul, reshape, tensor1d, tidy } from '@tensorflow/tfjs-core';\n\nfunction standardizeSampleOrClassWeights(xWeight, outputNames, weightType) {\n  const numOutputs = outputNames.length;\n\n  if (xWeight == null || Array.isArray(xWeight) && xWeight.length === 0) {\n    return outputNames.map(name => null);\n  }\n\n  if (numOutputs === 1) {\n    if (Array.isArray(xWeight) && xWeight.length === 1) {\n      return xWeight;\n    } else if (typeof xWeight === 'object' && outputNames[0] in xWeight) {\n      return [xWeight[outputNames[0]]];\n    } else {\n      return [xWeight];\n    }\n  }\n\n  if (Array.isArray(xWeight)) {\n    if (xWeight.length !== numOutputs) {\n      throw new Error(`Provided ${weightType} is an array of ${xWeight.length} ` + `element(s), but the model has ${numOutputs} outputs. ` + `Make sure a set of weights is provided for each model output.`);\n    }\n\n    return xWeight;\n  } else if (typeof xWeight === 'object' && Object.keys(xWeight).length > 0 && typeof xWeight[Object.keys(xWeight)[0]] === 'object') {\n    const output = [];\n    outputNames.forEach(outputName => {\n      if (outputName in xWeight) {\n        output.push(xWeight[outputName]);\n      } else {\n        output.push(null);\n      }\n    });\n    return output;\n  } else {\n    throw new Error(`The model has multiple (${numOutputs}) outputs, ` + `so ${weightType} must be either an array with ` + `${numOutputs} elements or an object with ${outputNames} keys. ` + `Provided ${weightType} not understood: ${JSON.stringify(xWeight)}`);\n  }\n}\n/**\n * Standardize class weighting objects.\n *\n * This function takes a single class-weighting object, an array of them,\n * or a map from output name to class-weighting object. It compares it to the\n * output name(s) of the model, base on which it outputs an array of\n * class-weighting objects of which the length matches the number of outputs.\n *\n * @param classWeight Input class-weighting object(s).\n * @param outputNames All output name(s) of the model.\n * @return An array of class-weighting objects. The length of the array matches\n *   the model's number of outputs.\n */\n\n\nexport function standardizeClassWeights(classWeight, outputNames) {\n  return standardizeSampleOrClassWeights(classWeight, outputNames, 'classWeight');\n}\nexport function standardizeSampleWeights(classWeight, outputNames) {\n  return standardizeSampleOrClassWeights(classWeight, outputNames, 'sampleWeight');\n}\n/**\n * Standardize by-sample and/or by-class weights for training.\n *\n * Note that this function operates on one model output at a time. For a model\n * with multiple outputs, you must call this function multiple times.\n *\n * @param y The target tensor that the by-sample and/or by-class weight is for.\n *     The values of y are assumed to encode the classes, either directly\n *     as an integer index, or as one-hot encoding.\n * @param sampleWeight By-sample weights.\n * @param classWeight By-class weights: an object mapping class indices\n *     (integers) to a weight (float) to apply to the model's loss for the\n *     samples from this class during training. This can be useful to tell the\n *     model to \"pay more attention\" to samples from an under-represented class.\n * @param sampleWeightMode The mode for the sample weights.\n * @return A Promise of weight tensor, of which the size of the first dimension\n *     matches that of `y`.\n */\n\nexport function standardizeWeights(_x, _x2, _x3, _x4) {\n  return (_standardizeWeights = _standardizeWeights || _asyncToGenerator(function* (y, sampleWeight, classWeight, sampleWeightMode) {\n    if (sampleWeight != null || sampleWeightMode != null) {\n      // TODO(cais): Once 'temporal' mode is implemented, document it in the doc\n      // string.\n      throw new Error('Support sampleWeight is not implemented yet');\n    }\n\n    if (classWeight != null) {\n      // Apply class weights per sample.\n      const yClasses = tidy(() => {\n        if (y.shape.length === 1) {\n          // Assume class indices.\n          return clone(y);\n        } else if (y.shape.length === 2) {\n          if (y.shape[1] > 1) {\n            // Assume one-hot encoding of classes.\n            const axis = 1;\n            return argMax(y, axis);\n          } else if (y.shape[1] === 1) {\n            // Class index.\n            return reshape(y, [y.shape[0]]);\n          } else {\n            throw new Error(`Encountered unexpected last-dimension size (${y.shape[1]}) ` + `during handling of class weights. The size is expected to be ` + `>= 1.`);\n          }\n        } else {\n          throw new Error(`Unexpected rank of target (y) tensor (${y.rank}) during ` + `handling of class weights. The rank is expected to be 1 or 2.`);\n        }\n      });\n      const yClassIndices = Array.from(yield yClasses.data());\n      dispose(yClasses);\n      const classSampleWeight = [];\n      yClassIndices.forEach(classIndex => {\n        if (classWeight[classIndex] == null) {\n          throw new Error(`classWeight must contain all classes in the training data. ` + `The class ${classIndex} exists in the data but not in ` + `classWeight`);\n        } else {\n          classSampleWeight.push(classWeight[classIndex]);\n        }\n      });\n      return tensor1d(classSampleWeight, 'float32');\n    } else {\n      return null;\n    }\n  })).apply(this, arguments);\n}\n/**\n * Apply per-sample weights on the loss values from a number of samples.\n *\n * @param losses Loss tensor of shape `[batchSize]`.\n * @param sampleWeights Per-sample weight tensor of shape `[batchSize]`.\n * @returns Tensor of the same shape as`losses`.\n */\n\nexport function computeWeightedLoss(losses, sampleWeights) {\n  return mul(losses, sampleWeights);\n}","map":{"version":3,"names":["argMax","clone","dispose","mul","reshape","tensor1d","tidy","standardizeSampleOrClassWeights","xWeight","outputNames","weightType","numOutputs","length","Array","isArray","map","name","Error","Object","keys","output","forEach","outputName","push","JSON","stringify","standardizeClassWeights","classWeight","standardizeSampleWeights","standardizeWeights","y","sampleWeight","sampleWeightMode","yClasses","shape","axis","rank","yClassIndices","from","data","classSampleWeight","classIndex","computeWeightedLoss","losses","sampleWeights"],"sources":["C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@tensorflow/tfjs-layers/dist/engine/training_utils.js"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport { argMax, clone, dispose, mul, reshape, tensor1d, tidy } from '@tensorflow/tfjs-core';\nfunction standardizeSampleOrClassWeights(xWeight, outputNames, weightType) {\n    const numOutputs = outputNames.length;\n    if (xWeight == null || (Array.isArray(xWeight) && xWeight.length === 0)) {\n        return outputNames.map(name => null);\n    }\n    if (numOutputs === 1) {\n        if (Array.isArray(xWeight) && xWeight.length === 1) {\n            return xWeight;\n        }\n        else if (typeof xWeight === 'object' && outputNames[0] in xWeight) {\n            return [xWeight[outputNames[0]]];\n        }\n        else {\n            return [xWeight];\n        }\n    }\n    if (Array.isArray(xWeight)) {\n        if (xWeight.length !== numOutputs) {\n            throw new Error(`Provided ${weightType} is an array of ${xWeight.length} ` +\n                `element(s), but the model has ${numOutputs} outputs. ` +\n                `Make sure a set of weights is provided for each model output.`);\n        }\n        return xWeight;\n    }\n    else if (typeof xWeight === 'object' && Object.keys(xWeight).length > 0 &&\n        typeof xWeight[Object.keys(xWeight)[0]] ===\n            'object') {\n        const output = [];\n        outputNames.forEach(outputName => {\n            if (outputName in xWeight) {\n                output.push(xWeight[outputName]);\n            }\n            else {\n                output.push(null);\n            }\n        });\n        return output;\n    }\n    else {\n        throw new Error(`The model has multiple (${numOutputs}) outputs, ` +\n            `so ${weightType} must be either an array with ` +\n            `${numOutputs} elements or an object with ${outputNames} keys. ` +\n            `Provided ${weightType} not understood: ${JSON.stringify(xWeight)}`);\n    }\n}\n/**\n * Standardize class weighting objects.\n *\n * This function takes a single class-weighting object, an array of them,\n * or a map from output name to class-weighting object. It compares it to the\n * output name(s) of the model, base on which it outputs an array of\n * class-weighting objects of which the length matches the number of outputs.\n *\n * @param classWeight Input class-weighting object(s).\n * @param outputNames All output name(s) of the model.\n * @return An array of class-weighting objects. The length of the array matches\n *   the model's number of outputs.\n */\nexport function standardizeClassWeights(classWeight, outputNames) {\n    return standardizeSampleOrClassWeights(classWeight, outputNames, 'classWeight');\n}\nexport function standardizeSampleWeights(classWeight, outputNames) {\n    return standardizeSampleOrClassWeights(classWeight, outputNames, 'sampleWeight');\n}\n/**\n * Standardize by-sample and/or by-class weights for training.\n *\n * Note that this function operates on one model output at a time. For a model\n * with multiple outputs, you must call this function multiple times.\n *\n * @param y The target tensor that the by-sample and/or by-class weight is for.\n *     The values of y are assumed to encode the classes, either directly\n *     as an integer index, or as one-hot encoding.\n * @param sampleWeight By-sample weights.\n * @param classWeight By-class weights: an object mapping class indices\n *     (integers) to a weight (float) to apply to the model's loss for the\n *     samples from this class during training. This can be useful to tell the\n *     model to \"pay more attention\" to samples from an under-represented class.\n * @param sampleWeightMode The mode for the sample weights.\n * @return A Promise of weight tensor, of which the size of the first dimension\n *     matches that of `y`.\n */\nexport async function standardizeWeights(y, sampleWeight, classWeight, sampleWeightMode) {\n    if (sampleWeight != null || sampleWeightMode != null) {\n        // TODO(cais): Once 'temporal' mode is implemented, document it in the doc\n        // string.\n        throw new Error('Support sampleWeight is not implemented yet');\n    }\n    if (classWeight != null) {\n        // Apply class weights per sample.\n        const yClasses = tidy(() => {\n            if (y.shape.length === 1) {\n                // Assume class indices.\n                return clone(y);\n            }\n            else if (y.shape.length === 2) {\n                if (y.shape[1] > 1) {\n                    // Assume one-hot encoding of classes.\n                    const axis = 1;\n                    return argMax(y, axis);\n                }\n                else if (y.shape[1] === 1) {\n                    // Class index.\n                    return reshape(y, [y.shape[0]]);\n                }\n                else {\n                    throw new Error(`Encountered unexpected last-dimension size (${y.shape[1]}) ` +\n                        `during handling of class weights. The size is expected to be ` +\n                        `>= 1.`);\n                }\n            }\n            else {\n                throw new Error(`Unexpected rank of target (y) tensor (${y.rank}) during ` +\n                    `handling of class weights. The rank is expected to be 1 or 2.`);\n            }\n        });\n        const yClassIndices = Array.from(await yClasses.data());\n        dispose(yClasses);\n        const classSampleWeight = [];\n        yClassIndices.forEach(classIndex => {\n            if (classWeight[classIndex] == null) {\n                throw new Error(`classWeight must contain all classes in the training data. ` +\n                    `The class ${classIndex} exists in the data but not in ` +\n                    `classWeight`);\n            }\n            else {\n                classSampleWeight.push(classWeight[classIndex]);\n            }\n        });\n        return tensor1d(classSampleWeight, 'float32');\n    }\n    else {\n        return null;\n    }\n}\n/**\n * Apply per-sample weights on the loss values from a number of samples.\n *\n * @param losses Loss tensor of shape `[batchSize]`.\n * @param sampleWeights Per-sample weight tensor of shape `[batchSize]`.\n * @returns Tensor of the same shape as`losses`.\n */\nexport function computeWeightedLoss(losses, sampleWeights) {\n    return mul(losses, sampleWeights);\n}\n"],"mappings":";;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,MAAT,EAAiBC,KAAjB,EAAwBC,OAAxB,EAAiCC,GAAjC,EAAsCC,OAAtC,EAA+CC,QAA/C,EAAyDC,IAAzD,QAAqE,uBAArE;;AACA,SAASC,+BAAT,CAAyCC,OAAzC,EAAkDC,WAAlD,EAA+DC,UAA/D,EAA2E;EACvE,MAAMC,UAAU,GAAGF,WAAW,CAACG,MAA/B;;EACA,IAAIJ,OAAO,IAAI,IAAX,IAAoBK,KAAK,CAACC,OAAN,CAAcN,OAAd,KAA0BA,OAAO,CAACI,MAAR,KAAmB,CAArE,EAAyE;IACrE,OAAOH,WAAW,CAACM,GAAZ,CAAgBC,IAAI,IAAI,IAAxB,CAAP;EACH;;EACD,IAAIL,UAAU,KAAK,CAAnB,EAAsB;IAClB,IAAIE,KAAK,CAACC,OAAN,CAAcN,OAAd,KAA0BA,OAAO,CAACI,MAAR,KAAmB,CAAjD,EAAoD;MAChD,OAAOJ,OAAP;IACH,CAFD,MAGK,IAAI,OAAOA,OAAP,KAAmB,QAAnB,IAA+BC,WAAW,CAAC,CAAD,CAAX,IAAkBD,OAArD,EAA8D;MAC/D,OAAO,CAACA,OAAO,CAACC,WAAW,CAAC,CAAD,CAAZ,CAAR,CAAP;IACH,CAFI,MAGA;MACD,OAAO,CAACD,OAAD,CAAP;IACH;EACJ;;EACD,IAAIK,KAAK,CAACC,OAAN,CAAcN,OAAd,CAAJ,EAA4B;IACxB,IAAIA,OAAO,CAACI,MAAR,KAAmBD,UAAvB,EAAmC;MAC/B,MAAM,IAAIM,KAAJ,CAAW,YAAWP,UAAW,mBAAkBF,OAAO,CAACI,MAAO,GAAxD,GACX,iCAAgCD,UAAW,YADhC,GAEX,+DAFC,CAAN;IAGH;;IACD,OAAOH,OAAP;EACH,CAPD,MAQK,IAAI,OAAOA,OAAP,KAAmB,QAAnB,IAA+BU,MAAM,CAACC,IAAP,CAAYX,OAAZ,EAAqBI,MAArB,GAA8B,CAA7D,IACL,OAAOJ,OAAO,CAACU,MAAM,CAACC,IAAP,CAAYX,OAAZ,EAAqB,CAArB,CAAD,CAAd,KACI,QAFH,EAEa;IACd,MAAMY,MAAM,GAAG,EAAf;IACAX,WAAW,CAACY,OAAZ,CAAoBC,UAAU,IAAI;MAC9B,IAAIA,UAAU,IAAId,OAAlB,EAA2B;QACvBY,MAAM,CAACG,IAAP,CAAYf,OAAO,CAACc,UAAD,CAAnB;MACH,CAFD,MAGK;QACDF,MAAM,CAACG,IAAP,CAAY,IAAZ;MACH;IACJ,CAPD;IAQA,OAAOH,MAAP;EACH,CAbI,MAcA;IACD,MAAM,IAAIH,KAAJ,CAAW,2BAA0BN,UAAW,aAAtC,GACX,MAAKD,UAAW,gCADL,GAEX,GAAEC,UAAW,+BAA8BF,WAAY,SAF5C,GAGX,YAAWC,UAAW,oBAAmBc,IAAI,CAACC,SAAL,CAAejB,OAAf,CAAwB,EAHhE,CAAN;EAIH;AACJ;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,OAAO,SAASkB,uBAAT,CAAiCC,WAAjC,EAA8ClB,WAA9C,EAA2D;EAC9D,OAAOF,+BAA+B,CAACoB,WAAD,EAAclB,WAAd,EAA2B,aAA3B,CAAtC;AACH;AACD,OAAO,SAASmB,wBAAT,CAAkCD,WAAlC,EAA+ClB,WAA/C,EAA4D;EAC/D,OAAOF,+BAA+B,CAACoB,WAAD,EAAclB,WAAd,EAA2B,cAA3B,CAAtC;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,gBAAsBoB,kBAAtB;EAAA,uEAAO,WAAkCC,CAAlC,EAAqCC,YAArC,EAAmDJ,WAAnD,EAAgEK,gBAAhE,EAAkF;IACrF,IAAID,YAAY,IAAI,IAAhB,IAAwBC,gBAAgB,IAAI,IAAhD,EAAsD;MAClD;MACA;MACA,MAAM,IAAIf,KAAJ,CAAU,6CAAV,CAAN;IACH;;IACD,IAAIU,WAAW,IAAI,IAAnB,EAAyB;MACrB;MACA,MAAMM,QAAQ,GAAG3B,IAAI,CAAC,MAAM;QACxB,IAAIwB,CAAC,CAACI,KAAF,CAAQtB,MAAR,KAAmB,CAAvB,EAA0B;UACtB;UACA,OAAOX,KAAK,CAAC6B,CAAD,CAAZ;QACH,CAHD,MAIK,IAAIA,CAAC,CAACI,KAAF,CAAQtB,MAAR,KAAmB,CAAvB,EAA0B;UAC3B,IAAIkB,CAAC,CAACI,KAAF,CAAQ,CAAR,IAAa,CAAjB,EAAoB;YAChB;YACA,MAAMC,IAAI,GAAG,CAAb;YACA,OAAOnC,MAAM,CAAC8B,CAAD,EAAIK,IAAJ,CAAb;UACH,CAJD,MAKK,IAAIL,CAAC,CAACI,KAAF,CAAQ,CAAR,MAAe,CAAnB,EAAsB;YACvB;YACA,OAAO9B,OAAO,CAAC0B,CAAD,EAAI,CAACA,CAAC,CAACI,KAAF,CAAQ,CAAR,CAAD,CAAJ,CAAd;UACH,CAHI,MAIA;YACD,MAAM,IAAIjB,KAAJ,CAAW,+CAA8Ca,CAAC,CAACI,KAAF,CAAQ,CAAR,CAAW,IAA1D,GACX,+DADW,GAEX,OAFC,CAAN;UAGH;QACJ,CAfI,MAgBA;UACD,MAAM,IAAIjB,KAAJ,CAAW,yCAAwCa,CAAC,CAACM,IAAK,WAAhD,GACX,+DADC,CAAN;QAEH;MACJ,CAzBoB,CAArB;MA0BA,MAAMC,aAAa,GAAGxB,KAAK,CAACyB,IAAN,OAAiBL,QAAQ,CAACM,IAAT,EAAjB,CAAtB;MACArC,OAAO,CAAC+B,QAAD,CAAP;MACA,MAAMO,iBAAiB,GAAG,EAA1B;MACAH,aAAa,CAAChB,OAAd,CAAsBoB,UAAU,IAAI;QAChC,IAAId,WAAW,CAACc,UAAD,CAAX,IAA2B,IAA/B,EAAqC;UACjC,MAAM,IAAIxB,KAAJ,CAAW,6DAAD,GACX,aAAYwB,UAAW,iCADZ,GAEX,aAFC,CAAN;QAGH,CAJD,MAKK;UACDD,iBAAiB,CAACjB,IAAlB,CAAuBI,WAAW,CAACc,UAAD,CAAlC;QACH;MACJ,CATD;MAUA,OAAOpC,QAAQ,CAACmC,iBAAD,EAAoB,SAApB,CAAf;IACH,CA1CD,MA2CK;MACD,OAAO,IAAP;IACH;EACJ,CApDD;AAAA;AAqDA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASE,mBAAT,CAA6BC,MAA7B,EAAqCC,aAArC,EAAoD;EACvD,OAAOzC,GAAG,CAACwC,MAAD,EAASC,aAAT,CAAV;AACH"},"metadata":{},"sourceType":"module"}