{"ast":null,"code":"import { computeStrides, sizeFromShape } from '../util';\n/**\n * Check whether updates.shape = indices.shape[:batchDim] +\n * shape[sliceDim:]\n *\n * @param x The input tensor.\n */\n\nexport function validateUpdateShape(shape, indices, updates) {\n  const sliceDim = indices.rank > 1 ? indices.shape[indices.rank - 1] : 1;\n  const batchDim = indices.rank > 1 ? indices.rank - 1 : 1;\n  const shapeError = 'Must have updates.shape = indices.shape[:batchDim] + ' + `shape[sliceDim:], got updates.shape: ${updates.shape}` + `, indices.shape: ${indices.shape}, shape: ${shape}` + `, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;\n\n  if (updates.rank < batchDim) {\n    throw new Error(shapeError + ` update.rank < ${batchDim}. `);\n  }\n\n  if (shape.length < sliceDim + (updates.rank - batchDim)) {\n    throw new Error(shapeError + ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);\n  }\n\n  if (updates.rank !== batchDim + shape.length - sliceDim) {\n    throw new Error(shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);\n  }\n\n  for (let d = 0; d < batchDim; ++d) {\n    if (updates.shape[d] !== indices.shape[d]) {\n      throw new Error(shapeError + ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${indices.shape[d]}).`);\n    }\n  }\n\n  for (let d = 0; d < updates.rank - batchDim; ++d) {\n    if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {\n      throw new Error(shapeError + ` updates.shape[${d + batchDim}] (${updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${shape[d + batchDim]})`);\n    }\n  }\n}\n/**\n * Validate scatter nd inputs.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n */\n\nexport function validateInput(updates, indices, shape) {\n  if (indices.rank < 1) {\n    throw new Error('tf.scatterND() expects the indices to be rank 1 or higher,' + ` but the rank was ${indices.rank}.`);\n  }\n\n  if (updates.rank < 1) {\n    throw new Error('tf.scatterND() expects the updates to be rank 1 or higher,' + ` but the rank was ${updates.rank}.`);\n  }\n\n  if (indices.dtype !== 'int32') {\n    throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${indices.dtype}`);\n  }\n\n  if (shape.length < 1) {\n    throw new Error(`Output rank must be greater or equal to 1, but got shape: ${shape}`);\n  }\n\n  if (shape.length === 0) {\n    if (indices.size === 0) {\n      throw new Error(`Indices specified for empty output. indices shape: ${indices.shape}`);\n    }\n\n    if (updates.size === 0) {\n      throw new Error(`Updates specified for empty output. updates shape: ${updates.shape}`);\n    }\n  }\n\n  validateUpdateShape(shape, indices, updates);\n}\n/**\n * Calculate the shape information for the output.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n *\n * @returns ScatterShapeInfo\n */\n\nexport function calculateShapes(updates, indices, shape) {\n  // Calculate the number of dimensions in indices\n  const indicesRank = indices.shape.length;\n  const sliceRank = indicesRank > 1 ? indices.shape[indicesRank - 1] : 1; // Calculate the number of elements that make up each slice of our updated\n  // tensor. This allows us to work with flattened tensors and copy over whole\n  // slices at a time.\n\n  const totalNd = shape.length;\n  let sliceSize = 1;\n\n  for (let i = sliceRank; i < totalNd; ++i) {\n    sliceSize *= shape[i];\n  }\n\n  const safeSliceDim = sliceRank < 1 ? 1 : sliceRank;\n  const numUpdates = sizeFromShape(indices.shape) / safeSliceDim;\n  const strides = [...computeStrides(shape.slice(0, sliceRank)), 1];\n  const outputSize = sizeFromShape(shape);\n  return {\n    sliceRank,\n    numUpdates,\n    sliceSize,\n    strides,\n    outputSize\n  };\n}","map":{"version":3,"names":["computeStrides","sizeFromShape","validateUpdateShape","shape","indices","updates","sliceDim","rank","batchDim","shapeError","Error","length","d","validateInput","dtype","size","calculateShapes","indicesRank","sliceRank","totalNd","sliceSize","i","safeSliceDim","numUpdates","strides","slice","outputSize"],"sources":["C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@tensorflow/tfjs-core/dist/ops/scatter_nd_util.js"],"sourcesContent":["import { computeStrides, sizeFromShape } from '../util';\n/**\n * Check whether updates.shape = indices.shape[:batchDim] +\n * shape[sliceDim:]\n *\n * @param x The input tensor.\n */\nexport function validateUpdateShape(shape, indices, updates) {\n    const sliceDim = (indices.rank > 1) ? indices.shape[indices.rank - 1] : 1;\n    const batchDim = (indices.rank > 1) ? indices.rank - 1 : 1;\n    const shapeError = 'Must have updates.shape = indices.shape[:batchDim] + ' +\n        `shape[sliceDim:], got updates.shape: ${updates.shape}` +\n        `, indices.shape: ${indices.shape}, shape: ${shape}` +\n        `, sliceDim: ${sliceDim}, and batchDim: ${batchDim}.`;\n    if (updates.rank < batchDim) {\n        throw new Error(shapeError + ` update.rank < ${batchDim}. `);\n    }\n    if (shape.length < sliceDim + (updates.rank - batchDim)) {\n        throw new Error(shapeError +\n            ` Output shape length < ${sliceDim + (updates.rank - batchDim)}`);\n    }\n    if (updates.rank !== batchDim + shape.length - sliceDim) {\n        throw new Error(shapeError + ` update.rank != ${batchDim + shape.length - sliceDim}`);\n    }\n    for (let d = 0; d < batchDim; ++d) {\n        if (updates.shape[d] !== indices.shape[d]) {\n            throw new Error(shapeError +\n                ` updates.shape[${d}] (${updates.shape[d]}) != indices.shape[${d}] (${indices.shape[d]}).`);\n        }\n    }\n    for (let d = 0; d < updates.rank - batchDim; ++d) {\n        if (updates.shape[d + batchDim] !== shape[d + sliceDim]) {\n            throw new Error(shapeError +\n                ` updates.shape[${d + batchDim}] (${updates.shape[d + batchDim]}) != shape[${d + batchDim}] (${shape[d + batchDim]})`);\n        }\n    }\n}\n/**\n * Validate scatter nd inputs.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n */\nexport function validateInput(updates, indices, shape) {\n    if (indices.rank < 1) {\n        throw new Error('tf.scatterND() expects the indices to be rank 1 or higher,' +\n            ` but the rank was ${indices.rank}.`);\n    }\n    if (updates.rank < 1) {\n        throw new Error('tf.scatterND() expects the updates to be rank 1 or higher,' +\n            ` but the rank was ${updates.rank}.`);\n    }\n    if (indices.dtype !== 'int32') {\n        throw new Error(`The dtype of 'indices' should be int32, but got dtype: ${indices.dtype}`);\n    }\n    if (shape.length < 1) {\n        throw new Error(`Output rank must be greater or equal to 1, but got shape: ${shape}`);\n    }\n    if (shape.length === 0) {\n        if (indices.size === 0) {\n            throw new Error(`Indices specified for empty output. indices shape: ${indices.shape}`);\n        }\n        if (updates.size === 0) {\n            throw new Error(`Updates specified for empty output. updates shape: ${updates.shape}`);\n        }\n    }\n    validateUpdateShape(shape, indices, updates);\n}\n/**\n * Calculate the shape information for the output.\n *\n * @param update The tensor contains the update values.\n * @param indices The tensor contains the indices for the update values.\n * @param shape The shape of the output tensor.\n *\n * @returns ScatterShapeInfo\n */\nexport function calculateShapes(updates, indices, shape) {\n    // Calculate the number of dimensions in indices\n    const indicesRank = indices.shape.length;\n    const sliceRank = (indicesRank > 1) ? indices.shape[indicesRank - 1] : 1;\n    // Calculate the number of elements that make up each slice of our updated\n    // tensor. This allows us to work with flattened tensors and copy over whole\n    // slices at a time.\n    const totalNd = shape.length;\n    let sliceSize = 1;\n    for (let i = sliceRank; i < totalNd; ++i) {\n        sliceSize *= shape[i];\n    }\n    const safeSliceDim = (sliceRank < 1) ? 1 : sliceRank;\n    const numUpdates = sizeFromShape(indices.shape) / safeSliceDim;\n    const strides = [...computeStrides(shape.slice(0, sliceRank)), 1];\n    const outputSize = sizeFromShape(shape);\n    return { sliceRank, numUpdates, sliceSize, strides, outputSize };\n}\n"],"mappings":"AAAA,SAASA,cAAT,EAAyBC,aAAzB,QAA8C,SAA9C;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,mBAAT,CAA6BC,KAA7B,EAAoCC,OAApC,EAA6CC,OAA7C,EAAsD;EACzD,MAAMC,QAAQ,GAAIF,OAAO,CAACG,IAAR,GAAe,CAAhB,GAAqBH,OAAO,CAACD,KAAR,CAAcC,OAAO,CAACG,IAAR,GAAe,CAA7B,CAArB,GAAuD,CAAxE;EACA,MAAMC,QAAQ,GAAIJ,OAAO,CAACG,IAAR,GAAe,CAAhB,GAAqBH,OAAO,CAACG,IAAR,GAAe,CAApC,GAAwC,CAAzD;EACA,MAAME,UAAU,GAAG,0DACd,wCAAuCJ,OAAO,CAACF,KAAM,EADvC,GAEd,oBAAmBC,OAAO,CAACD,KAAM,YAAWA,KAAM,EAFpC,GAGd,eAAcG,QAAS,mBAAkBE,QAAS,GAHvD;;EAIA,IAAIH,OAAO,CAACE,IAAR,GAAeC,QAAnB,EAA6B;IACzB,MAAM,IAAIE,KAAJ,CAAUD,UAAU,GAAI,kBAAiBD,QAAS,IAAlD,CAAN;EACH;;EACD,IAAIL,KAAK,CAACQ,MAAN,GAAeL,QAAQ,IAAID,OAAO,CAACE,IAAR,GAAeC,QAAnB,CAA3B,EAAyD;IACrD,MAAM,IAAIE,KAAJ,CAAUD,UAAU,GACrB,0BAAyBH,QAAQ,IAAID,OAAO,CAACE,IAAR,GAAeC,QAAnB,CAA6B,EAD7D,CAAN;EAEH;;EACD,IAAIH,OAAO,CAACE,IAAR,KAAiBC,QAAQ,GAAGL,KAAK,CAACQ,MAAjB,GAA0BL,QAA/C,EAAyD;IACrD,MAAM,IAAII,KAAJ,CAAUD,UAAU,GAAI,mBAAkBD,QAAQ,GAAGL,KAAK,CAACQ,MAAjB,GAA0BL,QAAS,EAA7E,CAAN;EACH;;EACD,KAAK,IAAIM,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGJ,QAApB,EAA8B,EAAEI,CAAhC,EAAmC;IAC/B,IAAIP,OAAO,CAACF,KAAR,CAAcS,CAAd,MAAqBR,OAAO,CAACD,KAAR,CAAcS,CAAd,CAAzB,EAA2C;MACvC,MAAM,IAAIF,KAAJ,CAAUD,UAAU,GACrB,kBAAiBG,CAAE,MAAKP,OAAO,CAACF,KAAR,CAAcS,CAAd,CAAiB,sBAAqBA,CAAE,MAAKR,OAAO,CAACD,KAAR,CAAcS,CAAd,CAAiB,IADrF,CAAN;IAEH;EACJ;;EACD,KAAK,IAAIA,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGP,OAAO,CAACE,IAAR,GAAeC,QAAnC,EAA6C,EAAEI,CAA/C,EAAkD;IAC9C,IAAIP,OAAO,CAACF,KAAR,CAAcS,CAAC,GAAGJ,QAAlB,MAAgCL,KAAK,CAACS,CAAC,GAAGN,QAAL,CAAzC,EAAyD;MACrD,MAAM,IAAII,KAAJ,CAAUD,UAAU,GACrB,kBAAiBG,CAAC,GAAGJ,QAAS,MAAKH,OAAO,CAACF,KAAR,CAAcS,CAAC,GAAGJ,QAAlB,CAA4B,cAAaI,CAAC,GAAGJ,QAAS,MAAKL,KAAK,CAACS,CAAC,GAAGJ,QAAL,CAAe,GADjH,CAAN;IAEH;EACJ;AACJ;AACD;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASK,aAAT,CAAuBR,OAAvB,EAAgCD,OAAhC,EAAyCD,KAAzC,EAAgD;EACnD,IAAIC,OAAO,CAACG,IAAR,GAAe,CAAnB,EAAsB;IAClB,MAAM,IAAIG,KAAJ,CAAU,+DACX,qBAAoBN,OAAO,CAACG,IAAK,GADhC,CAAN;EAEH;;EACD,IAAIF,OAAO,CAACE,IAAR,GAAe,CAAnB,EAAsB;IAClB,MAAM,IAAIG,KAAJ,CAAU,+DACX,qBAAoBL,OAAO,CAACE,IAAK,GADhC,CAAN;EAEH;;EACD,IAAIH,OAAO,CAACU,KAAR,KAAkB,OAAtB,EAA+B;IAC3B,MAAM,IAAIJ,KAAJ,CAAW,0DAAyDN,OAAO,CAACU,KAAM,EAAlF,CAAN;EACH;;EACD,IAAIX,KAAK,CAACQ,MAAN,GAAe,CAAnB,EAAsB;IAClB,MAAM,IAAID,KAAJ,CAAW,6DAA4DP,KAAM,EAA7E,CAAN;EACH;;EACD,IAAIA,KAAK,CAACQ,MAAN,KAAiB,CAArB,EAAwB;IACpB,IAAIP,OAAO,CAACW,IAAR,KAAiB,CAArB,EAAwB;MACpB,MAAM,IAAIL,KAAJ,CAAW,sDAAqDN,OAAO,CAACD,KAAM,EAA9E,CAAN;IACH;;IACD,IAAIE,OAAO,CAACU,IAAR,KAAiB,CAArB,EAAwB;MACpB,MAAM,IAAIL,KAAJ,CAAW,sDAAqDL,OAAO,CAACF,KAAM,EAA9E,CAAN;IACH;EACJ;;EACDD,mBAAmB,CAACC,KAAD,EAAQC,OAAR,EAAiBC,OAAjB,CAAnB;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASW,eAAT,CAAyBX,OAAzB,EAAkCD,OAAlC,EAA2CD,KAA3C,EAAkD;EACrD;EACA,MAAMc,WAAW,GAAGb,OAAO,CAACD,KAAR,CAAcQ,MAAlC;EACA,MAAMO,SAAS,GAAID,WAAW,GAAG,CAAf,GAAoBb,OAAO,CAACD,KAAR,CAAcc,WAAW,GAAG,CAA5B,CAApB,GAAqD,CAAvE,CAHqD,CAIrD;EACA;EACA;;EACA,MAAME,OAAO,GAAGhB,KAAK,CAACQ,MAAtB;EACA,IAAIS,SAAS,GAAG,CAAhB;;EACA,KAAK,IAAIC,CAAC,GAAGH,SAAb,EAAwBG,CAAC,GAAGF,OAA5B,EAAqC,EAAEE,CAAvC,EAA0C;IACtCD,SAAS,IAAIjB,KAAK,CAACkB,CAAD,CAAlB;EACH;;EACD,MAAMC,YAAY,GAAIJ,SAAS,GAAG,CAAb,GAAkB,CAAlB,GAAsBA,SAA3C;EACA,MAAMK,UAAU,GAAGtB,aAAa,CAACG,OAAO,CAACD,KAAT,CAAb,GAA+BmB,YAAlD;EACA,MAAME,OAAO,GAAG,CAAC,GAAGxB,cAAc,CAACG,KAAK,CAACsB,KAAN,CAAY,CAAZ,EAAeP,SAAf,CAAD,CAAlB,EAA+C,CAA/C,CAAhB;EACA,MAAMQ,UAAU,GAAGzB,aAAa,CAACE,KAAD,CAAhC;EACA,OAAO;IAAEe,SAAF;IAAaK,UAAb;IAAyBH,SAAzB;IAAoCI,OAApC;IAA6CE;EAA7C,CAAP;AACH"},"metadata":{},"sourceType":"module"}