{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Dilation2DBackpropInput, util } from '@tensorflow/tfjs-core';\nexport const dilation2DBackpropInputConfig = {\n  kernelName: Dilation2DBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: ({\n    inputs,\n    backend,\n    attrs\n  }) => {\n    const {\n      x,\n      filter,\n      dy\n    } = inputs;\n    const {\n      strides,\n      pad,\n      dilations\n    } = attrs;\n    const cpuBackend = backend;\n    const $x = util.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);\n    const $filter = util.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } = backend_util.computeDilation2DInfo(x.shape, filter.shape, strides, pad, 'NHWC'\n    /* dataFormat */\n    , dilations);\n    util.assert(dy.rank === outShape.length, () => `Error in ${Dilation2DBackpropInput}, dy ` + `must have the same rank as output ${outShape.length}, but got ` + `${dy.rank}`);\n    const $dy = util.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values); // The computed gradients has the same dimensions as the input:\n    // [batch, inputHeight, inputCols, inChannel]\n\n    const gradients = util.makeZerosNestedTypedArray(x.shape, x.dtype); // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hInMax = hBeg < 0 ? 0 : hBeg;\n            let wInMax = wBeg < 0 ? 0 : wBeg;\n\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n\n                    if (val > curVal) {\n                      curVal = val;\n                      hInMax = hIn;\n                      wInMax = wIn;\n                    }\n                  }\n                }\n              }\n            }\n\n            gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(util.toTypedArray(gradients, x.dtype), x.shape, x.dtype);\n    return {\n      dataId,\n      shape: x.shape,\n      dtype: x.dtype\n    };\n  }\n};","map":{"version":3,"names":["backend_util","Dilation2DBackpropInput","util","dilation2DBackpropInputConfig","kernelName","backendName","kernelFunc","inputs","backend","attrs","x","filter","dy","strides","pad","dilations","cpuBackend","$x","toNestedArray","shape","data","get","dataId","values","$filter","batchSize","inHeight","inWidth","inChannels","outHeight","outWidth","padInfo","strideHeight","strideWidth","filterHeight","filterWidth","dilationHeight","dilationWidth","outShape","computeDilation2DInfo","assert","rank","length","$dy","gradients","makeZerosNestedTypedArray","dtype","b","hOut","hBeg","top","wOut","wBeg","left","d","curVal","Number","MIN_SAFE_INTEGER","hInMax","wInMax","h","hIn","w","wIn","val","write","toTypedArray"],"sources":["C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/Dilation2DBackpropInput.js"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Dilation2DBackpropInput, util } from '@tensorflow/tfjs-core';\nexport const dilation2DBackpropInputConfig = {\n    kernelName: Dilation2DBackpropInput,\n    backendName: 'cpu',\n    kernelFunc: ({ inputs, backend, attrs }) => {\n        const { x, filter, dy } = inputs;\n        const { strides, pad, dilations } = attrs;\n        const cpuBackend = backend;\n        const $x = util.toNestedArray(x.shape, cpuBackend.data.get(x.dataId).values);\n        const $filter = util.toNestedArray(filter.shape, cpuBackend.data.get(filter.dataId).values);\n        const { batchSize, inHeight, inWidth, inChannels, outHeight, outWidth, padInfo, strideHeight, strideWidth, filterHeight, filterWidth, dilationHeight, dilationWidth, outShape } = backend_util.computeDilation2DInfo(x.shape, filter.shape, strides, pad, 'NHWC' /* dataFormat */, dilations);\n        util.assert(dy.rank === outShape.length, () => `Error in ${Dilation2DBackpropInput}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n        const $dy = util.toNestedArray(outShape, cpuBackend.data.get(dy.dataId).values);\n        // The computed gradients has the same dimensions as the input:\n        // [batch, inputHeight, inputCols, inChannel]\n        const gradients = util.makeZerosNestedTypedArray(x.shape, x.dtype);\n        // In the case of multiple argmax branches, we only back-propagate along the\n        // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n        // similarly to the max-pooling backward routines.\n        // This implementation follows the TF c++ implementation:\n        // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n        for (let b = 0; b < batchSize; ++b) {\n            for (let hOut = 0; hOut < outHeight; ++hOut) {\n                const hBeg = hOut * strideHeight - padInfo.top;\n                for (let wOut = 0; wOut < outWidth; ++wOut) {\n                    const wBeg = wOut * strideWidth - padInfo.left;\n                    for (let d = 0; d < inChannels; ++d) {\n                        let curVal = Number.MIN_SAFE_INTEGER;\n                        let hInMax = (hBeg < 0) ? 0 : hBeg;\n                        let wInMax = (wBeg < 0) ? 0 : wBeg;\n                        for (let h = 0; h < filterHeight; ++h) {\n                            const hIn = hBeg + h * dilationHeight;\n                            if (hIn >= 0 && hIn < inHeight) {\n                                for (let w = 0; w < filterWidth; ++w) {\n                                    const wIn = wBeg + w * dilationWidth;\n                                    if (wIn >= 0 && wIn < inWidth) {\n                                        const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                                        if (val > curVal) {\n                                            curVal = val;\n                                            hInMax = hIn;\n                                            wInMax = wIn;\n                                        }\n                                    }\n                                }\n                            }\n                        }\n                        gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];\n                    }\n                }\n            }\n        }\n        const dataId = cpuBackend.write(util.toTypedArray(gradients, x.dtype), x.shape, x.dtype);\n        return { dataId, shape: x.shape, dtype: x.dtype };\n    }\n};\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,YAAT,EAAuBC,uBAAvB,EAAgDC,IAAhD,QAA4D,uBAA5D;AACA,OAAO,MAAMC,6BAA6B,GAAG;EACzCC,UAAU,EAAEH,uBAD6B;EAEzCI,WAAW,EAAE,KAF4B;EAGzCC,UAAU,EAAE,CAAC;IAAEC,MAAF;IAAUC,OAAV;IAAmBC;EAAnB,CAAD,KAAgC;IACxC,MAAM;MAAEC,CAAF;MAAKC,MAAL;MAAaC;IAAb,IAAoBL,MAA1B;IACA,MAAM;MAAEM,OAAF;MAAWC,GAAX;MAAgBC;IAAhB,IAA8BN,KAApC;IACA,MAAMO,UAAU,GAAGR,OAAnB;IACA,MAAMS,EAAE,GAAGf,IAAI,CAACgB,aAAL,CAAmBR,CAAC,CAACS,KAArB,EAA4BH,UAAU,CAACI,IAAX,CAAgBC,GAAhB,CAAoBX,CAAC,CAACY,MAAtB,EAA8BC,MAA1D,CAAX;IACA,MAAMC,OAAO,GAAGtB,IAAI,CAACgB,aAAL,CAAmBP,MAAM,CAACQ,KAA1B,EAAiCH,UAAU,CAACI,IAAX,CAAgBC,GAAhB,CAAoBV,MAAM,CAACW,MAA3B,EAAmCC,MAApE,CAAhB;IACA,MAAM;MAAEE,SAAF;MAAaC,QAAb;MAAuBC,OAAvB;MAAgCC,UAAhC;MAA4CC,SAA5C;MAAuDC,QAAvD;MAAiEC,OAAjE;MAA0EC,YAA1E;MAAwFC,WAAxF;MAAqGC,YAArG;MAAmHC,WAAnH;MAAgIC,cAAhI;MAAgJC,aAAhJ;MAA+JC;IAA/J,IAA4KtC,YAAY,CAACuC,qBAAb,CAAmC7B,CAAC,CAACS,KAArC,EAA4CR,MAAM,CAACQ,KAAnD,EAA0DN,OAA1D,EAAmEC,GAAnE,EAAwE;IAAO;IAA/E,EAAiGC,SAAjG,CAAlL;IACAb,IAAI,CAACsC,MAAL,CAAY5B,EAAE,CAAC6B,IAAH,KAAYH,QAAQ,CAACI,MAAjC,EAAyC,MAAO,YAAWzC,uBAAwB,OAApC,GAC1C,qCAAoCqC,QAAQ,CAACI,MAAO,YADV,GAE1C,GAAE9B,EAAE,CAAC6B,IAAK,EAFf;IAGA,MAAME,GAAG,GAAGzC,IAAI,CAACgB,aAAL,CAAmBoB,QAAnB,EAA6BtB,UAAU,CAACI,IAAX,CAAgBC,GAAhB,CAAoBT,EAAE,CAACU,MAAvB,EAA+BC,MAA5D,CAAZ,CAVwC,CAWxC;IACA;;IACA,MAAMqB,SAAS,GAAG1C,IAAI,CAAC2C,yBAAL,CAA+BnC,CAAC,CAACS,KAAjC,EAAwCT,CAAC,CAACoC,KAA1C,CAAlB,CAbwC,CAcxC;IACA;IACA;IACA;IACA;;IACA,KAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGtB,SAApB,EAA+B,EAAEsB,CAAjC,EAAoC;MAChC,KAAK,IAAIC,IAAI,GAAG,CAAhB,EAAmBA,IAAI,GAAGnB,SAA1B,EAAqC,EAAEmB,IAAvC,EAA6C;QACzC,MAAMC,IAAI,GAAGD,IAAI,GAAGhB,YAAP,GAAsBD,OAAO,CAACmB,GAA3C;;QACA,KAAK,IAAIC,IAAI,GAAG,CAAhB,EAAmBA,IAAI,GAAGrB,QAA1B,EAAoC,EAAEqB,IAAtC,EAA4C;UACxC,MAAMC,IAAI,GAAGD,IAAI,GAAGlB,WAAP,GAAqBF,OAAO,CAACsB,IAA1C;;UACA,KAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG1B,UAApB,EAAgC,EAAE0B,CAAlC,EAAqC;YACjC,IAAIC,MAAM,GAAGC,MAAM,CAACC,gBAApB;YACA,IAAIC,MAAM,GAAIT,IAAI,GAAG,CAAR,GAAa,CAAb,GAAiBA,IAA9B;YACA,IAAIU,MAAM,GAAIP,IAAI,GAAG,CAAR,GAAa,CAAb,GAAiBA,IAA9B;;YACA,KAAK,IAAIQ,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG1B,YAApB,EAAkC,EAAE0B,CAApC,EAAuC;cACnC,MAAMC,GAAG,GAAGZ,IAAI,GAAGW,CAAC,GAAGxB,cAAvB;;cACA,IAAIyB,GAAG,IAAI,CAAP,IAAYA,GAAG,GAAGnC,QAAtB,EAAgC;gBAC5B,KAAK,IAAIoC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG3B,WAApB,EAAiC,EAAE2B,CAAnC,EAAsC;kBAClC,MAAMC,GAAG,GAAGX,IAAI,GAAGU,CAAC,GAAGzB,aAAvB;;kBACA,IAAI0B,GAAG,IAAI,CAAP,IAAYA,GAAG,GAAGpC,OAAtB,EAA+B;oBAC3B,MAAMqC,GAAG,GAAG/C,EAAE,CAAC8B,CAAD,CAAF,CAAMc,GAAN,EAAWE,GAAX,EAAgBT,CAAhB,IAAqB9B,OAAO,CAACoC,CAAD,CAAP,CAAWE,CAAX,EAAcR,CAAd,CAAjC;;oBACA,IAAIU,GAAG,GAAGT,MAAV,EAAkB;sBACdA,MAAM,GAAGS,GAAT;sBACAN,MAAM,GAAGG,GAAT;sBACAF,MAAM,GAAGI,GAAT;oBACH;kBACJ;gBACJ;cACJ;YACJ;;YACDnB,SAAS,CAACG,CAAD,CAAT,CAAaW,MAAb,EAAqBC,MAArB,EAA6BL,CAA7B,KAAmCX,GAAG,CAACI,CAAD,CAAH,CAAOC,IAAP,EAAaG,IAAb,EAAmBG,CAAnB,CAAnC;UACH;QACJ;MACJ;IACJ;;IACD,MAAMhC,MAAM,GAAGN,UAAU,CAACiD,KAAX,CAAiB/D,IAAI,CAACgE,YAAL,CAAkBtB,SAAlB,EAA6BlC,CAAC,CAACoC,KAA/B,CAAjB,EAAwDpC,CAAC,CAACS,KAA1D,EAAiET,CAAC,CAACoC,KAAnE,CAAf;IACA,OAAO;MAAExB,MAAF;MAAUH,KAAK,EAAET,CAAC,CAACS,KAAnB;MAA0B2B,KAAK,EAAEpC,CAAC,CAACoC;IAAnC,CAAP;EACH;AAtDwC,CAAtC"},"metadata":{},"sourceType":"module"}