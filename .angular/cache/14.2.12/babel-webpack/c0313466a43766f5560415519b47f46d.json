{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Merge Layers.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { serialization, tidy, util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { Layer } from '../engine/topology';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { l2Normalize } from '../losses';\nimport * as generic_utils from '../utils/generic_utils';\nimport * as mathUtils from '../utils/math_utils';\nimport { getExactlyOneShape } from '../utils/types_utils';\n/**\n * Generic Merge layer for element-wise merge functions.\n *\n * Used to implement `Sum`, `Average`, `Concatenate`, etc.\n */\n\nexport class Merge extends Layer {\n  constructor(args) {\n    super(args || {});\n    this.supportsMasking = true;\n  }\n  /**\n   * Logic for merging multiple tensors, to be overridden by subclasses.\n   * @param inputs\n   */\n\n\n  mergeFunction(inputs) {\n    throw new NotImplementedError();\n  }\n  /**\n   * Computes the shape of the result of an elementwise operation.\n   *\n   * @param shape1: Shape of the first tensor.\n   * @param shape2: Shape of the second tensor.\n   * @returns Expected output shape when an elementwise operation is carried\n   *   out on 2 tensors with shapes `shape1` and `shape2`.\n   * @throws ValueError: If `shape1` and `shape2` are not compatible for\n   *   element-wise operations.\n   */\n\n\n  computeElementwiseOpOutputShape(shape1, shape2) {\n    if (shape1 == null || shape2 == null) {\n      return null;\n    } else if (shape1.length < shape2.length) {\n      return this.computeElementwiseOpOutputShape(shape2, shape1);\n    } else if (shape2.length === 0) {\n      return shape1;\n    }\n\n    const outputShape = shape1.slice(0, shape1.length - shape2.length);\n\n    for (let k = 0; k < shape2.length; ++k) {\n      const i = shape1[shape1.length - shape2.length + k];\n      const j = shape2[k];\n\n      if (i == null || j == null || i < 0 || j < 0) {\n        outputShape.push(null);\n      } else if (i === 1) {\n        outputShape.push(j);\n      } else if (j === 1) {\n        outputShape.push(i);\n      } else {\n        if (i !== j) {\n          throw new ValueError('Operands could not be broadcast together with shapes ' + JSON.stringify(shape1) + ' ' + JSON.stringify(shape2));\n        }\n\n        outputShape.push(i);\n      }\n    }\n\n    return outputShape;\n  }\n\n  build(inputShape) {\n    // Used purely for shape validation.\n    if (Array.isArray(inputShape) && !Array.isArray(inputShape[0])) {\n      // Make sure that inputShape is an Array of shape.\n      inputShape = [getExactlyOneShape(inputShape)];\n    }\n\n    inputShape = inputShape;\n\n    if (inputShape.length < 2) {\n      throw new ValueError('A merge layer should be called on an Array of at least 2 inputs.' + ` Got ${inputShape.length} input(s).`);\n    } // Make sure that there is at most one unique batch size among the input\n    // shapes.\n\n\n    let batchSizes = [];\n\n    for (const shape of inputShape) {\n      if (shape != null && shape[0] !== null) {\n        batchSizes.push(shape[0]);\n      }\n    }\n\n    batchSizes = generic_utils.unique(batchSizes);\n\n    if (batchSizes.length > 1) {\n      throw new ValueError(`Can not merge tensors with different batch sizes. ` + `Got tensors with shapes: ${JSON.stringify(inputShape)}.`);\n    }\n\n    let outputShape = inputShape[0] == null ? null : inputShape[0].slice(1);\n\n    for (let i = 1; i < inputShape.length; ++i) {\n      const shape = inputShape[i] == null ? null : inputShape[i].slice(1);\n      outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);\n    } // If the inputs have different ranks, we have to reshape them to make them\n    // broadcastable.\n\n\n    const allRanks = inputShape.map(shape => shape.length);\n\n    if (inputShape.indexOf(null) === -1 && generic_utils.unique(allRanks).length === 1) {\n      this.reshapeRequired = false;\n    } else {\n      this.reshapeRequired = true;\n    }\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      inputs = inputs;\n\n      if (this.reshapeRequired) {\n        const reshapedInputs = [];\n        const inputDims = inputs.map(input => input.rank);\n\n        if (inputDims.indexOf(null) === -1) {\n          // If ranks of all inputs are available, we simply expand each of them\n          // at axis=1 until all of them have the same rank.\n          const maxNDim = mathUtils.max(inputDims);\n\n          for (let x of inputs) {\n            const xNDim = x.rank;\n\n            for (let k = 0; k < maxNDim - xNDim; ++k) {\n              x = K.expandDims(x, 1);\n            }\n\n            reshapedInputs.push(x);\n          }\n\n          return this.mergeFunction(reshapedInputs);\n        } else {\n          // Transpose all inputs so that batch size is the last dimension.\n          // [batchSize, dim1, dim2, ...] -> [dim1, dim2, ..., batchSize]\n          let transposed = false;\n\n          for (const x of inputs) {\n            const xNDim = x.rank;\n\n            if (xNDim == null) {\n              const xShape = x.shape;\n              const batchSize = xShape[0];\n              const newShape = xShape.slice(1).concat([batchSize]);\n              let xTransposed = tfc.reshape(x, [batchSize].concat(mathUtils.arrayProd(xShape.slice(1))));\n              xTransposed = tfc.transpose(xTransposed, [1, 0]);\n              xTransposed = tfc.reshape(xTransposed, newShape);\n              reshapedInputs.push(xTransposed);\n              transposed = true;\n            } else if (xNDim > 1) {\n              const dims = mathUtils.range(1, xNDim).concat([0]);\n              reshapedInputs.push(tfc.transpose(x, dims));\n              transposed = true;\n            } else {\n              // We don't transpose inputs if they are 1D vectors or scalars.\n              reshapedInputs.push(x);\n            }\n          }\n\n          let y = this.mergeFunction(reshapedInputs);\n          const yNDim = y.rank;\n\n          if (transposed) {\n            // If inputs have been transposed, we have to transpose the output\n            // too.\n            if (yNDim == null) {\n              const yShape = y.shape;\n              const yNDim = yShape.length;\n              const batchSize = yShape[yNDim - 1];\n              const newShape = [batchSize].concat(yShape.slice(0, yShape.length - 1));\n              y = tfc.reshape(tfc.transpose(tfc.reshape(y, [-1, batchSize]), [1, 0]), newShape);\n            } else if (yNDim > 1) {\n              const dims = [yNDim - 1].concat(mathUtils.range(0, yNDim - 1));\n              y = tfc.transpose(y, dims);\n            }\n          }\n\n          return y;\n        }\n      } else {\n        return this.mergeFunction(inputs);\n      }\n    });\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = inputShape;\n    let outputShape;\n\n    if (inputShape[0] == null) {\n      outputShape = null;\n    } else {\n      outputShape = inputShape[0].slice(1);\n    }\n\n    for (let i = 1; i < inputShape.length; ++i) {\n      const shape = inputShape[i] == null ? null : inputShape[i].slice(1);\n      outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);\n    }\n\n    let batchSizes = [];\n\n    for (const shape of inputShape) {\n      if (shape != null && shape[0] !== null) {\n        batchSizes.push(shape[0]);\n      }\n    }\n\n    batchSizes = generic_utils.unique(batchSizes);\n\n    if (batchSizes.length === 1) {\n      outputShape = batchSizes.concat(outputShape);\n    } else {\n      outputShape = [null].concat(outputShape);\n    }\n\n    return outputShape;\n  }\n\n  computeMask(inputs, mask) {\n    return tfc.tidy(() => {\n      if (mask == null) {\n        return null;\n      }\n\n      if (!Array.isArray(mask)) {\n        throw new ValueError('`mask` should be an Array');\n      }\n\n      if (!Array.isArray(inputs)) {\n        throw new ValueError('`inputs` should be an Array');\n      }\n\n      if (mask.length !== inputs.length) {\n        throw new ValueError(`The Array 'inputs' and 'mask' are expected to have the same ` + `length, but have different lengths ` + `(${inputs.length} vs ${mask.length})`);\n      }\n\n      if (mask.every(m => m == null)) {\n        return null;\n      }\n\n      mask = mask.map(m => m == null ? m : tfc.expandDims(m, 0));\n      let output = mask[0];\n\n      for (let i = 1; i < mask.length - 1; ++i) {\n        output = tfc.logicalAnd(output, mask[i]);\n      }\n\n      return output;\n    });\n  }\n\n}\nexport class Add extends Merge {\n  constructor(args) {\n    super(args);\n  }\n\n  mergeFunction(inputs) {\n    return tidy(() => {\n      let output = inputs[0].clone();\n\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.add(output, inputs[i]);\n      }\n\n      return output;\n    });\n  }\n\n}\n/** @nocollapse */\n\nAdd.className = 'Add';\nserialization.registerClass(Add);\n/**\n * Calculate the element-wise sum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Add` layer, by using no input argument\n *    or a single configuration argument. The resultant `Add` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const addLayer = tf.layers.add();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = addLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.add([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.add([input1, input2]).print();\n * // Gives [[11, 22], [33, 44]].\n *\n */\n\nexport function add(config) {\n  if (Array.isArray(config)) {\n    const layer = new Add({});\n    return layer.apply(config);\n  } else {\n    return new Add(config);\n  }\n}\nexport class Multiply extends Merge {\n  constructor(args) {\n    super(args);\n  }\n\n  mergeFunction(inputs) {\n    return tidy(() => {\n      let output = inputs[0].clone();\n\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.mul(output, inputs[i]);\n      }\n\n      return output;\n    });\n  }\n\n}\n/** @nocollapse */\n\nMultiply.className = 'Multiply';\nserialization.registerClass(Multiply);\n/**\n * Calculate the element-wise product of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Multiply` layer, by using no input argument\n *    or a single configuration argument. The resultant `Multiply` layer can\n *    then be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const multiplyLayer = tf.layers.multiply();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = multiplyLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.multiply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.multiply([input1, input2]).print();\n * // Gives [[10, 40], [90, 160]].\n *\n */\n\nexport function multiply(config) {\n  if (Array.isArray(config)) {\n    const layer = new Multiply({});\n    return layer.apply(config);\n  } else {\n    return new Multiply(config);\n  }\n}\nexport class Average extends Merge {\n  constructor(args) {\n    super(args);\n  }\n\n  mergeFunction(inputs) {\n    return tidy(() => {\n      let output = inputs[0].clone();\n\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.add(output, inputs[i]);\n      }\n\n      return tfc.mul(1 / inputs.length, output);\n    });\n  }\n\n}\n/** @nocollapse */\n\nAverage.className = 'Average';\nserialization.registerClass(Average);\n/**\n * Calculate the element-wise arithmetic mean of inputs, which all have the same\n * shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Average` layer, by using no input argument\n *    or a single configuration argument. The resultant `Average` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const averageLayer = tf.layers.average();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = averageLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.average([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.average([input1, input2]).print();\n * // Gives [[5.5, 11], [16.5, 22]].\n *\n */\n\nexport function average(config) {\n  if (Array.isArray(config)) {\n    const layer = new Average({});\n    return layer.apply(config);\n  } else {\n    return new Average(config);\n  }\n}\nexport class Maximum extends Merge {\n  constructor(args) {\n    super(args);\n  }\n\n  mergeFunction(inputs) {\n    return tidy(() => {\n      let output = inputs[0];\n\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.maximum(output, inputs[i]);\n      }\n\n      return output;\n    });\n  }\n\n}\n/** @nocollapse */\n\nMaximum.className = 'Maximum';\nserialization.registerClass(Maximum);\n/**\n * Calculate the element-wise maximum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Maximum` layer, by using no input argument\n *    or a single configuration argument. The resultant `Maximum` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const maximumLayer = tf.layers.maximum();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = maximumLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.maximum([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 20, 3, 40], [2, 2]);\n * const input2 = tf.tensor2d([10, 2, 30, 4], [2, 2]);\n * tf.layers.maximum([input1, input2]).print();\n * // Gives [[10, 20], [30, 40]].\n *\n */\n\nexport function maximum(config) {\n  if (Array.isArray(config)) {\n    const layer = new Maximum({});\n    return layer.apply(config);\n  } else {\n    return new Maximum(config);\n  }\n}\nexport class Minimum extends Merge {\n  constructor(args) {\n    super(args);\n  }\n\n  mergeFunction(inputs) {\n    return tidy(() => {\n      let output = inputs[0];\n\n      for (let i = 1; i < inputs.length; ++i) {\n        output = tfc.minimum(output, inputs[i]);\n      }\n\n      return output;\n    });\n  }\n\n}\n/** @nocollapse */\n\nMinimum.className = 'Minimum';\nserialization.registerClass(Minimum);\n/**\n * Calculate the element-wise minimum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Minimum` layer, by using no input argument\n *    or a single configuration argument. The resultant `Minimum` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const minimumLayer = tf.layers.minimum();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = minimumLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.minimum([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 20, 3, 40], [2, 2]);\n * const input2 = tf.tensor2d([10, 2, 30, 4], [2, 2]);\n * tf.layers.minimum([input1, input2]).print();\n * // Gives [[1, 2], [3, 4]].\n *\n */\n\nexport function minimum(config) {\n  if (Array.isArray(config)) {\n    const layer = new Minimum({});\n    return layer.apply(config);\n  } else {\n    return new Minimum(config);\n  }\n}\nexport class Concatenate extends Merge {\n  constructor(args) {\n    super(args);\n    this.DEFAULT_AXIS = -1;\n\n    if (args == null) {\n      args = {};\n    }\n\n    this.axis = args.axis == null ? this.DEFAULT_AXIS : args.axis;\n    this.supportsMasking = true;\n    this.reshapeRequired = false;\n  }\n\n  build(inputShape) {\n    // Used purely for shape validation.]\n    if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0])) || inputShape.length === 1) {\n      throw new ValueError('A `Concatenate` layer should be called on a list of at least 2 ' + 'inputs');\n    }\n\n    inputShape = inputShape;\n    let allNoneShape = true;\n\n    for (const shape of inputShape) {\n      if (shape != null) {\n        allNoneShape = false;\n        break;\n      }\n    }\n\n    if (allNoneShape) {\n      return;\n    }\n\n    const shapeSet = [];\n\n    for (let i = 0; i < inputShape.length; ++i) {\n      const shapeWithoutConcatAxis = inputShape[i].slice();\n      shapeWithoutConcatAxis.splice(this.axis, 1);\n      let exists = false;\n\n      for (const shape of shapeSet) {\n        if (util.arraysEqual(shape, shapeWithoutConcatAxis)) {\n          exists = true;\n          break;\n        }\n      }\n\n      if (!exists) {\n        shapeSet.push(shapeWithoutConcatAxis);\n      }\n    }\n\n    if (shapeSet.length > 1) {\n      throw new ValueError('A `Concatenate` layer requires inputs with matching shapes ' + 'except for the concat axis. Got input shapes: ' + JSON.stringify(inputShape));\n    }\n  }\n\n  mergeFunction(inputs) {\n    return tidy(() => {\n      return K.concatenate(inputs, this.axis);\n    });\n  }\n\n  computeOutputShape(inputShape) {\n    if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0]))) {\n      throw new ValueError('A `Concatenate` layer should be called on a list of inputs.');\n    }\n\n    const inputShapes = inputShape;\n    const outputShape = inputShapes[0].slice();\n    const axis = this.axis < 0 ? outputShape.length + this.axis : this.axis; // Porting Note: the line above is because TypeScript doesn't support\n    //   negative indices.\n\n    for (const shape of inputShapes.slice(1)) {\n      if (outputShape[axis] == null || shape[axis] == null) {\n        outputShape[axis] = null;\n        break;\n      }\n\n      outputShape[axis] += shape[axis];\n    }\n\n    return outputShape;\n  }\n\n  computeMask(inputs, mask) {\n    if (mask == null) {\n      return null;\n    }\n\n    if (!Array.isArray(mask)) {\n      throw new ValueError('`mask` should be an array for Concatenate');\n    }\n\n    if (!Array.isArray(inputs)) {\n      throw new ValueError('`inputs` should be an array for Concatenate');\n    }\n\n    if (mask.length !== inputs.length) {\n      throw new ValueError(`Mismatch in the length of mask (${mask.length}) ` + `and the legnth of inputs (${inputs.length})`);\n    }\n\n    return tfc.tidy(() => {\n      let allNullMasks = true;\n      mask.forEach(m => {\n        if (m != null) {\n          allNullMasks = false;\n          return;\n        }\n      });\n\n      if (allNullMasks) {\n        return null;\n      }\n\n      const outputMasks = [];\n\n      for (let i = 0; i < inputs.length; ++i) {\n        if (mask[i] == null) {\n          // Input is unmasked. Append all 1's to masks.\n          outputMasks.push(tfc.cast(tfc.onesLike(inputs[i]), 'bool'));\n        } else if (mask[i].rank < inputs[i].rank) {\n          // Mask is smaller than the input, expand it.\n          outputMasks.push(tfc.expandDims(mask[i], -1));\n        } else {\n          outputMasks.push(mask[i]);\n        }\n      }\n\n      const concatenatedMasks = tfc.concat(outputMasks, this.axis);\n      return tfc.all(concatenatedMasks, -1, false);\n    });\n  }\n\n  getConfig() {\n    const config = {\n      'axis': this.axis\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nConcatenate.className = 'Concatenate';\nserialization.registerClass(Concatenate);\n/**\n * Concatenate an `Array` of inputs.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Concatenate` layer, by using no input argument\n *    or a single configuration argument. The resultant `Concatenate` layer can\n *    then be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const concatLayer = tf.layers.concatenate();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 3]});\n * const input2 = tf.input({shape: [2, 4]});\n * const output = concatLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 7], with the first dimension as the undetermined batch\n * // dimension and the last dimension as the result of concatenating the\n * // last dimensions of the two inputs.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 3]});\n * const input2 = tf.input({shape: [2, 4]});\n * const output = tf.layers.concatenate([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension and the last dimension as the result of concatenating the\n * // last dimensions of the two inputs.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([[1, 2], [3, 4]], [2, 2]);\n * const input2 = tf.tensor2d([[10, 20], [30, 40]], [2, 2]);\n * tf.layers.concatenate([input1, input2]).print();\n * // Gives [[1, 2, 10, 20], [3, 4, 30, 40]].\n *\n */\n\nexport function concatenate(config) {\n  if (Array.isArray(config)) {\n    const layer = new Concatenate({});\n    return layer.apply(config);\n  } else {\n    return new Concatenate(config);\n  }\n}\n/**\n * Interpretable potentially negative axis index.\n *\n * For example, given axis = -1, and dim = 3, this function will return 2.\n *\n * @param axis The axis index, may be a positive, zero or negative integer.\n * @param dim Total number of dimensions, a positive integer.\n * @returns A non-negative axis index equivalent to the input `axis`.\n */\n\nfunction interpretAxis(axis, dim) {\n  while (axis < 0) {\n    axis += dim;\n  }\n\n  return axis;\n}\n\nfunction batchDot(x, y, axes) {\n  if (x.shape.length > 3 || y.shape.length > 3) {\n    throw new NotImplementedError('batchDot is not implemented for tensors of 4D or higher rank yet');\n  }\n\n  tfc.util.assert(x.shape.length >= 2, () => `batchDot requires the rank of x to be >= 2, ` + `but got ${x.shape.length}`);\n  tfc.util.assert(x.shape.length >= 2, () => `batchDot requires the rank of y to be >= 2, ` + `but got ${y.shape.length}`);\n\n  if (typeof axes === 'number') {\n    axes = [axes, axes];\n  }\n\n  if (x.dtype === 'complex64' || y.dtype === 'complex64') {\n    throw new NotImplementedError('batchDot is not implemented for complex64-type Tensors yet.');\n  }\n\n  const xNDim = x.shape.length;\n  const yNDim = y.shape.length;\n\n  if (axes == null) {\n    // Behave like batchMatmul by default.\n    axes = [xNDim - 1, yNDim - 2];\n  }\n\n  const axesArray = axes;\n  return tfc.tidy(() => {\n    let diff;\n\n    if (xNDim > yNDim) {\n      diff = xNDim - yNDim;\n      const diffShape = [];\n\n      for (let i = 0; i < diff; ++i) {\n        diffShape.push(1);\n      }\n\n      y = tfc.reshape(y, y.shape.concat(diffShape));\n    } else if (yNDim > xNDim) {\n      diff = yNDim - xNDim;\n      const diffShape = [];\n\n      for (let i = 0; i < diff; ++i) {\n        diffShape.push(1);\n      }\n\n      x = tfc.reshape(x, x.shape.concat(diffShape));\n    } else {\n      diff = 0;\n    }\n\n    let out;\n\n    if (x.shape.length === 2 && y.shape.length === 2) {\n      if (axesArray[0] === axesArray[1]) {\n        out = tfc.sum(tfc.mul(x, y), axesArray[0]);\n      } else {\n        out = tfc.sum(tfc.mul(tfc.transpose(x, [1, 0]), y), axesArray[1]);\n      }\n    } else {\n      const adjX = axesArray[0] !== x.shape.length - 1;\n      const adjY = axesArray[1] === y.shape.length - 1;\n      out = tfc.matMul(x, y, adjX, adjY);\n    }\n\n    if (diff > 0) {\n      let idx;\n\n      if (xNDim > yNDim) {\n        idx = xNDim + yNDim - 3;\n      } else {\n        idx = xNDim - 1;\n      }\n\n      const squeezeAxes = [];\n\n      for (let i = idx; i < idx + diff; ++i) {\n        squeezeAxes.push(i);\n      }\n\n      out = tfc.squeeze(out, squeezeAxes);\n    }\n\n    if (out.shape.length === 1) {\n      out = tfc.expandDims(out, 1);\n    }\n\n    return out;\n  });\n}\n\nexport class Dot extends Merge {\n  constructor(args) {\n    super(args);\n    this.axes = args.axes;\n    this.normalize = args.normalize == null ? false : args.normalize;\n    this.supportsMasking = true;\n    this.reshapeRequired = false;\n  }\n\n  build(inputShape) {\n    tfc.util.assert(Array.isArray(inputShape) && inputShape.length === 2 && Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), () => 'A `Dot` layer should be called on a list of exactly 2 inputs.');\n    const shape1 = inputShape[0];\n    const shape2 = inputShape[1];\n\n    if (shape1.length > 3 || shape2.length > 3) {\n      throw new NotImplementedError('Dot layer does not support tensors of 4D or higher rank yet.');\n    }\n\n    const axes = this.interpretAxes(shape1, shape2);\n\n    if (shape1[axes[0]] !== shape2[axes[1]]) {\n      throw new ValueError(`Dimension incompatibility: ` + `${shape1[axes[0]]} !== ${shape2[axes[1]]}`);\n    }\n  }\n\n  mergeFunction(inputs) {\n    if (inputs.length !== 2) {\n      throw new ValueError('A `Dot` layer must be called on exactly 2 inputs, ' + `but received ${inputs.length} input(s).`);\n    }\n\n    let x1 = inputs[0];\n    let x2 = inputs[1];\n    let axes;\n\n    if (!Array.isArray(this.axes)) {\n      axes = [interpretAxis(this.axes, x1.shape.length), interpretAxis(this.axes, x2.shape.length)];\n    } else {\n      axes = this.axes.map((axis, i) => interpretAxis(axis, inputs[i].shape.length));\n    }\n\n    if (this.normalize) {\n      x1 = l2Normalize(x1, axes[0]);\n      x2 = l2Normalize(x2, axes[1]);\n    }\n\n    return batchDot(x1, x2, axes);\n  }\n\n  interpretAxes(shape1, shape2) {\n    let axes;\n\n    if (!Array.isArray(this.axes)) {\n      // `this.axes` is a single integer.\n      axes = [interpretAxis(this.axes, shape1.length), interpretAxis(this.axes, shape2.length)];\n    } else {\n      // `this.axes` is an Array of integers.\n      axes = this.axes;\n    }\n\n    return axes;\n  }\n\n  computeOutputShape(inputShape) {\n    tfc.util.assert(Array.isArray(inputShape) && inputShape.length === 2 && Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), () => 'A `Dot` layer should be called on a list of exactly 2 inputs.');\n    const shape1 = inputShape[0].slice();\n    const shape2 = inputShape[1].slice();\n\n    if (shape1.length > 3 || shape2.length > 3) {\n      throw new NotImplementedError('Dot layer does not support tensors of 4D or higher rank yet.');\n    }\n\n    const axes = this.interpretAxes(shape1, shape2);\n    shape1.splice(axes[0], 1);\n    shape2.splice(axes[1], 1);\n    shape2.splice(0, 1);\n    const outputShape = shape1.concat(shape2);\n\n    if (outputShape.length === 1) {\n      outputShape.push(1);\n    }\n\n    return outputShape;\n  }\n\n  computeMask(inputs, mask) {\n    return null;\n  }\n\n  getConfig() {\n    const config = {\n      'axes': this.axes,\n      'normalize': this.normalize\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nDot.className = 'Dot';\nserialization.registerClass(Dot); // TODO(cais): Add functional interfaces for the merge layers.","map":{"version":3,"names":["tfc","serialization","tidy","util","K","Layer","NotImplementedError","ValueError","l2Normalize","generic_utils","mathUtils","getExactlyOneShape","Merge","constructor","args","supportsMasking","mergeFunction","inputs","computeElementwiseOpOutputShape","shape1","shape2","length","outputShape","slice","k","i","j","push","JSON","stringify","build","inputShape","Array","isArray","batchSizes","shape","unique","allRanks","map","indexOf","reshapeRequired","call","kwargs","reshapedInputs","inputDims","input","rank","maxNDim","max","x","xNDim","expandDims","transposed","xShape","batchSize","newShape","concat","xTransposed","reshape","arrayProd","transpose","dims","range","y","yNDim","yShape","computeOutputShape","computeMask","mask","every","m","output","logicalAnd","Add","clone","add","className","registerClass","config","layer","apply","Multiply","mul","multiply","Average","average","Maximum","maximum","Minimum","minimum","Concatenate","DEFAULT_AXIS","axis","allNoneShape","shapeSet","shapeWithoutConcatAxis","splice","exists","arraysEqual","concatenate","inputShapes","allNullMasks","forEach","outputMasks","cast","onesLike","concatenatedMasks","all","getConfig","baseConfig","Object","assign","interpretAxis","dim","batchDot","axes","assert","dtype","axesArray","diff","diffShape","out","sum","adjX","adjY","matMul","idx","squeezeAxes","squeeze","Dot","normalize","interpretAxes","x1","x2"],"sources":["C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@tensorflow/tfjs-layers/dist/layers/merge.js"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * TensorFlow.js Layers: Merge Layers.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { serialization, tidy, util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { Layer } from '../engine/topology';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { l2Normalize } from '../losses';\nimport * as generic_utils from '../utils/generic_utils';\nimport * as mathUtils from '../utils/math_utils';\nimport { getExactlyOneShape } from '../utils/types_utils';\n/**\n * Generic Merge layer for element-wise merge functions.\n *\n * Used to implement `Sum`, `Average`, `Concatenate`, etc.\n */\nexport class Merge extends Layer {\n    constructor(args) {\n        super(args || {});\n        this.supportsMasking = true;\n    }\n    /**\n     * Logic for merging multiple tensors, to be overridden by subclasses.\n     * @param inputs\n     */\n    mergeFunction(inputs) {\n        throw new NotImplementedError();\n    }\n    /**\n     * Computes the shape of the result of an elementwise operation.\n     *\n     * @param shape1: Shape of the first tensor.\n     * @param shape2: Shape of the second tensor.\n     * @returns Expected output shape when an elementwise operation is carried\n     *   out on 2 tensors with shapes `shape1` and `shape2`.\n     * @throws ValueError: If `shape1` and `shape2` are not compatible for\n     *   element-wise operations.\n     */\n    computeElementwiseOpOutputShape(shape1, shape2) {\n        if (shape1 == null || shape2 == null) {\n            return null;\n        }\n        else if (shape1.length < shape2.length) {\n            return this.computeElementwiseOpOutputShape(shape2, shape1);\n        }\n        else if (shape2.length === 0) {\n            return shape1;\n        }\n        const outputShape = shape1.slice(0, shape1.length - shape2.length);\n        for (let k = 0; k < shape2.length; ++k) {\n            const i = shape1[shape1.length - shape2.length + k];\n            const j = shape2[k];\n            if (i == null || j == null || i < 0 || j < 0) {\n                outputShape.push(null);\n            }\n            else if (i === 1) {\n                outputShape.push(j);\n            }\n            else if (j === 1) {\n                outputShape.push(i);\n            }\n            else {\n                if (i !== j) {\n                    throw new ValueError('Operands could not be broadcast together with shapes ' +\n                        JSON.stringify(shape1) + ' ' + JSON.stringify(shape2));\n                }\n                outputShape.push(i);\n            }\n        }\n        return outputShape;\n    }\n    build(inputShape) {\n        // Used purely for shape validation.\n        if (Array.isArray(inputShape) && !Array.isArray(inputShape[0])) {\n            // Make sure that inputShape is an Array of shape.\n            inputShape = [getExactlyOneShape(inputShape)];\n        }\n        inputShape = inputShape;\n        if (inputShape.length < 2) {\n            throw new ValueError('A merge layer should be called on an Array of at least 2 inputs.' +\n                ` Got ${inputShape.length} input(s).`);\n        }\n        // Make sure that there is at most one unique batch size among the input\n        // shapes.\n        let batchSizes = [];\n        for (const shape of inputShape) {\n            if (shape != null && shape[0] !== null) {\n                batchSizes.push(shape[0]);\n            }\n        }\n        batchSizes = generic_utils.unique(batchSizes);\n        if (batchSizes.length > 1) {\n            throw new ValueError(`Can not merge tensors with different batch sizes. ` +\n                `Got tensors with shapes: ${JSON.stringify(inputShape)}.`);\n        }\n        let outputShape = inputShape[0] == null ? null : inputShape[0].slice(1);\n        for (let i = 1; i < inputShape.length; ++i) {\n            const shape = inputShape[i] == null ? null : inputShape[i].slice(1);\n            outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);\n        }\n        // If the inputs have different ranks, we have to reshape them to make them\n        // broadcastable.\n        const allRanks = inputShape.map(shape => shape.length);\n        if (inputShape.indexOf(null) === -1 &&\n            generic_utils.unique(allRanks).length === 1) {\n            this.reshapeRequired = false;\n        }\n        else {\n            this.reshapeRequired = true;\n        }\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            inputs = inputs;\n            if (this.reshapeRequired) {\n                const reshapedInputs = [];\n                const inputDims = inputs.map(input => input.rank);\n                if (inputDims.indexOf(null) === -1) {\n                    // If ranks of all inputs are available, we simply expand each of them\n                    // at axis=1 until all of them have the same rank.\n                    const maxNDim = mathUtils.max(inputDims);\n                    for (let x of inputs) {\n                        const xNDim = x.rank;\n                        for (let k = 0; k < maxNDim - xNDim; ++k) {\n                            x = K.expandDims(x, 1);\n                        }\n                        reshapedInputs.push(x);\n                    }\n                    return this.mergeFunction(reshapedInputs);\n                }\n                else {\n                    // Transpose all inputs so that batch size is the last dimension.\n                    // [batchSize, dim1, dim2, ...] -> [dim1, dim2, ..., batchSize]\n                    let transposed = false;\n                    for (const x of inputs) {\n                        const xNDim = x.rank;\n                        if (xNDim == null) {\n                            const xShape = x.shape;\n                            const batchSize = xShape[0];\n                            const newShape = xShape.slice(1).concat([batchSize]);\n                            let xTransposed = tfc.reshape(x, [batchSize].concat(mathUtils.arrayProd(xShape.slice(1))));\n                            xTransposed = tfc.transpose(xTransposed, [1, 0]);\n                            xTransposed = tfc.reshape(xTransposed, newShape);\n                            reshapedInputs.push(xTransposed);\n                            transposed = true;\n                        }\n                        else if (xNDim > 1) {\n                            const dims = mathUtils.range(1, xNDim).concat([0]);\n                            reshapedInputs.push(tfc.transpose(x, dims));\n                            transposed = true;\n                        }\n                        else {\n                            // We don't transpose inputs if they are 1D vectors or scalars.\n                            reshapedInputs.push(x);\n                        }\n                    }\n                    let y = this.mergeFunction(reshapedInputs);\n                    const yNDim = y.rank;\n                    if (transposed) {\n                        // If inputs have been transposed, we have to transpose the output\n                        // too.\n                        if (yNDim == null) {\n                            const yShape = y.shape;\n                            const yNDim = yShape.length;\n                            const batchSize = yShape[yNDim - 1];\n                            const newShape = [batchSize].concat(yShape.slice(0, yShape.length - 1));\n                            y = tfc.reshape(tfc.transpose(tfc.reshape(y, [-1, batchSize]), [1, 0]), newShape);\n                        }\n                        else if (yNDim > 1) {\n                            const dims = [yNDim - 1].concat(mathUtils.range(0, yNDim - 1));\n                            y = tfc.transpose(y, dims);\n                        }\n                    }\n                    return y;\n                }\n            }\n            else {\n                return this.mergeFunction(inputs);\n            }\n        });\n    }\n    computeOutputShape(inputShape) {\n        inputShape = inputShape;\n        let outputShape;\n        if (inputShape[0] == null) {\n            outputShape = null;\n        }\n        else {\n            outputShape = inputShape[0].slice(1);\n        }\n        for (let i = 1; i < inputShape.length; ++i) {\n            const shape = inputShape[i] == null ? null : inputShape[i].slice(1);\n            outputShape = this.computeElementwiseOpOutputShape(outputShape, shape);\n        }\n        let batchSizes = [];\n        for (const shape of inputShape) {\n            if (shape != null && shape[0] !== null) {\n                batchSizes.push(shape[0]);\n            }\n        }\n        batchSizes = generic_utils.unique(batchSizes);\n        if (batchSizes.length === 1) {\n            outputShape = batchSizes.concat(outputShape);\n        }\n        else {\n            outputShape = [null].concat(outputShape);\n        }\n        return outputShape;\n    }\n    computeMask(inputs, mask) {\n        return tfc.tidy(() => {\n            if (mask == null) {\n                return null;\n            }\n            if (!Array.isArray(mask)) {\n                throw new ValueError('`mask` should be an Array');\n            }\n            if (!Array.isArray(inputs)) {\n                throw new ValueError('`inputs` should be an Array');\n            }\n            if (mask.length !== inputs.length) {\n                throw new ValueError(`The Array 'inputs' and 'mask' are expected to have the same ` +\n                    `length, but have different lengths ` +\n                    `(${inputs.length} vs ${mask.length})`);\n            }\n            if (mask.every(m => m == null)) {\n                return null;\n            }\n            mask = mask.map(m => m == null ? m : tfc.expandDims(m, 0));\n            let output = mask[0];\n            for (let i = 1; i < mask.length - 1; ++i) {\n                output = tfc.logicalAnd(output, mask[i]);\n            }\n            return output;\n        });\n    }\n}\nexport class Add extends Merge {\n    constructor(args) {\n        super(args);\n    }\n    mergeFunction(inputs) {\n        return tidy(() => {\n            let output = inputs[0].clone();\n            for (let i = 1; i < inputs.length; ++i) {\n                output = tfc.add(output, inputs[i]);\n            }\n            return output;\n        });\n    }\n}\n/** @nocollapse */\nAdd.className = 'Add';\nserialization.registerClass(Add);\n/**\n * Calculate the element-wise sum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Add` layer, by using no input argument\n *    or a single configuration argument. The resultant `Add` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const addLayer = tf.layers.add();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = addLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.add([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.add([input1, input2]).print();\n * // Gives [[11, 22], [33, 44]].\n *\n */\nexport function add(config) {\n    if (Array.isArray(config)) {\n        const layer = new Add({});\n        return layer.apply(config);\n    }\n    else {\n        return new Add(config);\n    }\n}\nexport class Multiply extends Merge {\n    constructor(args) {\n        super(args);\n    }\n    mergeFunction(inputs) {\n        return tidy(() => {\n            let output = inputs[0].clone();\n            for (let i = 1; i < inputs.length; ++i) {\n                output = tfc.mul(output, inputs[i]);\n            }\n            return output;\n        });\n    }\n}\n/** @nocollapse */\nMultiply.className = 'Multiply';\nserialization.registerClass(Multiply);\n/**\n * Calculate the element-wise product of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Multiply` layer, by using no input argument\n *    or a single configuration argument. The resultant `Multiply` layer can\n *    then be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const multiplyLayer = tf.layers.multiply();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = multiplyLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.multiply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.multiply([input1, input2]).print();\n * // Gives [[10, 40], [90, 160]].\n *\n */\nexport function multiply(config) {\n    if (Array.isArray(config)) {\n        const layer = new Multiply({});\n        return layer.apply(config);\n    }\n    else {\n        return new Multiply(config);\n    }\n}\nexport class Average extends Merge {\n    constructor(args) {\n        super(args);\n    }\n    mergeFunction(inputs) {\n        return tidy(() => {\n            let output = inputs[0].clone();\n            for (let i = 1; i < inputs.length; ++i) {\n                output = tfc.add(output, inputs[i]);\n            }\n            return tfc.mul(1 / inputs.length, output);\n        });\n    }\n}\n/** @nocollapse */\nAverage.className = 'Average';\nserialization.registerClass(Average);\n/**\n * Calculate the element-wise arithmetic mean of inputs, which all have the same\n * shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Average` layer, by using no input argument\n *    or a single configuration argument. The resultant `Average` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const averageLayer = tf.layers.average();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = averageLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.average([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 2, 3, 4], [2, 2]);\n * const input2 = tf.tensor2d([10, 20, 30, 40], [2, 2]);\n * tf.layers.average([input1, input2]).print();\n * // Gives [[5.5, 11], [16.5, 22]].\n *\n */\nexport function average(config) {\n    if (Array.isArray(config)) {\n        const layer = new Average({});\n        return layer.apply(config);\n    }\n    else {\n        return new Average(config);\n    }\n}\nexport class Maximum extends Merge {\n    constructor(args) {\n        super(args);\n    }\n    mergeFunction(inputs) {\n        return tidy(() => {\n            let output = inputs[0];\n            for (let i = 1; i < inputs.length; ++i) {\n                output = tfc.maximum(output, inputs[i]);\n            }\n            return output;\n        });\n    }\n}\n/** @nocollapse */\nMaximum.className = 'Maximum';\nserialization.registerClass(Maximum);\n/**\n * Calculate the element-wise maximum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Maximum` layer, by using no input argument\n *    or a single configuration argument. The resultant `Maximum` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const maximumLayer = tf.layers.maximum();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = maximumLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.maximum([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 20, 3, 40], [2, 2]);\n * const input2 = tf.tensor2d([10, 2, 30, 4], [2, 2]);\n * tf.layers.maximum([input1, input2]).print();\n * // Gives [[10, 20], [30, 40]].\n *\n */\nexport function maximum(config) {\n    if (Array.isArray(config)) {\n        const layer = new Maximum({});\n        return layer.apply(config);\n    }\n    else {\n        return new Maximum(config);\n    }\n}\nexport class Minimum extends Merge {\n    constructor(args) {\n        super(args);\n    }\n    mergeFunction(inputs) {\n        return tidy(() => {\n            let output = inputs[0];\n            for (let i = 1; i < inputs.length; ++i) {\n                output = tfc.minimum(output, inputs[i]);\n            }\n            return output;\n        });\n    }\n}\n/** @nocollapse */\nMinimum.className = 'Minimum';\nserialization.registerClass(Minimum);\n/**\n * Calculate the element-wise minimum of inputs, which all have the same shape.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Minimum` layer, by using no input argument\n *    or a single configuration argument. The resultant `Minimum` layer can then\n *    be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const minimumLayer = tf.layers.minimum();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = minimumLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 2]});\n * const input2 = tf.input({shape: [2, 2]});\n * const output = tf.layers.minimum([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([1, 20, 3, 40], [2, 2]);\n * const input2 = tf.tensor2d([10, 2, 30, 4], [2, 2]);\n * tf.layers.minimum([input1, input2]).print();\n * // Gives [[1, 2], [3, 4]].\n *\n */\nexport function minimum(config) {\n    if (Array.isArray(config)) {\n        const layer = new Minimum({});\n        return layer.apply(config);\n    }\n    else {\n        return new Minimum(config);\n    }\n}\nexport class Concatenate extends Merge {\n    constructor(args) {\n        super(args);\n        this.DEFAULT_AXIS = -1;\n        if (args == null) {\n            args = {};\n        }\n        this.axis = args.axis == null ? this.DEFAULT_AXIS : args.axis;\n        this.supportsMasking = true;\n        this.reshapeRequired = false;\n    }\n    build(inputShape) {\n        // Used purely for shape validation.]\n        if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0])) ||\n            inputShape.length === 1) {\n            throw new ValueError('A `Concatenate` layer should be called on a list of at least 2 ' +\n                'inputs');\n        }\n        inputShape = inputShape;\n        let allNoneShape = true;\n        for (const shape of inputShape) {\n            if (shape != null) {\n                allNoneShape = false;\n                break;\n            }\n        }\n        if (allNoneShape) {\n            return;\n        }\n        const shapeSet = [];\n        for (let i = 0; i < inputShape.length; ++i) {\n            const shapeWithoutConcatAxis = inputShape[i].slice();\n            shapeWithoutConcatAxis.splice(this.axis, 1);\n            let exists = false;\n            for (const shape of shapeSet) {\n                if (util.arraysEqual(shape, shapeWithoutConcatAxis)) {\n                    exists = true;\n                    break;\n                }\n            }\n            if (!exists) {\n                shapeSet.push(shapeWithoutConcatAxis);\n            }\n        }\n        if (shapeSet.length > 1) {\n            throw new ValueError('A `Concatenate` layer requires inputs with matching shapes ' +\n                'except for the concat axis. Got input shapes: ' +\n                JSON.stringify(inputShape));\n        }\n    }\n    mergeFunction(inputs) {\n        return tidy(() => {\n            return K.concatenate(inputs, this.axis);\n        });\n    }\n    computeOutputShape(inputShape) {\n        if (!(Array.isArray(inputShape) && Array.isArray(inputShape[0]))) {\n            throw new ValueError('A `Concatenate` layer should be called on a list of inputs.');\n        }\n        const inputShapes = inputShape;\n        const outputShape = inputShapes[0].slice();\n        const axis = this.axis < 0 ? outputShape.length + this.axis : this.axis;\n        // Porting Note: the line above is because TypeScript doesn't support\n        //   negative indices.\n        for (const shape of inputShapes.slice(1)) {\n            if (outputShape[axis] == null || shape[axis] == null) {\n                outputShape[axis] = null;\n                break;\n            }\n            outputShape[axis] += shape[axis];\n        }\n        return outputShape;\n    }\n    computeMask(inputs, mask) {\n        if (mask == null) {\n            return null;\n        }\n        if (!Array.isArray(mask)) {\n            throw new ValueError('`mask` should be an array for Concatenate');\n        }\n        if (!Array.isArray(inputs)) {\n            throw new ValueError('`inputs` should be an array for Concatenate');\n        }\n        if (mask.length !== inputs.length) {\n            throw new ValueError(`Mismatch in the length of mask (${mask.length}) ` +\n                `and the legnth of inputs (${inputs.length})`);\n        }\n        return tfc.tidy(() => {\n            let allNullMasks = true;\n            mask.forEach(m => {\n                if (m != null) {\n                    allNullMasks = false;\n                    return;\n                }\n            });\n            if (allNullMasks) {\n                return null;\n            }\n            const outputMasks = [];\n            for (let i = 0; i < inputs.length; ++i) {\n                if (mask[i] == null) {\n                    // Input is unmasked. Append all 1's to masks.\n                    outputMasks.push(tfc.cast(tfc.onesLike(inputs[i]), 'bool'));\n                }\n                else if (mask[i].rank < inputs[i].rank) {\n                    // Mask is smaller than the input, expand it.\n                    outputMasks.push(tfc.expandDims(mask[i], -1));\n                }\n                else {\n                    outputMasks.push(mask[i]);\n                }\n            }\n            const concatenatedMasks = tfc.concat(outputMasks, this.axis);\n            return tfc.all(concatenatedMasks, -1, false);\n        });\n    }\n    getConfig() {\n        const config = {\n            'axis': this.axis,\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nConcatenate.className = 'Concatenate';\nserialization.registerClass(Concatenate);\n/**\n * Concatenate an `Array` of inputs.\n *\n * This function can be invoked in three ways.\n *\n * 1. Construct an instance of `Concatenate` layer, by using no input argument\n *    or a single configuration argument. The resultant `Concatenate` layer can\n *    then be used on `tf.SymbolicTensor`s or `tf.Tensor`s. For example:\n *\n * ```js\n * const concatLayer = tf.layers.concatenate();\n *\n * // The layer can be applied to inputs.\n * const input1 = tf.input({shape: [2, 3]});\n * const input2 = tf.input({shape: [2, 4]});\n * const output = concatLayer.apply([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 7], with the first dimension as the undetermined batch\n * // dimension and the last dimension as the result of concatenating the\n * // last dimensions of the two inputs.\n * ```\n *\n * 2. Invoke directly on an `Array` of `tf.SymbolicTensor`s. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.SymbolicTensor`. For example:\n *\n * ```js\n * const input1 = tf.input({shape: [2, 3]});\n * const input2 = tf.input({shape: [2, 4]});\n * const output = tf.layers.concatenate([input1, input2]);\n * console.log(output.shape);\n * // You get [null, 2, 2], with the first dimension as the undetermined batch\n * // dimension and the last dimension as the result of concatenating the\n * // last dimensions of the two inputs.\n * ```\n *\n * 3. Invoke directly on `tf.Tensor`s, i.e., concrete values. This constructs\n *    an `Layer` object internally and calls its `apply` method on the inputs,\n *    generating a new `tf.Tensor` as the result of the computation. For\n * example:\n *\n * ```js\n * const input1 = tf.tensor2d([[1, 2], [3, 4]], [2, 2]);\n * const input2 = tf.tensor2d([[10, 20], [30, 40]], [2, 2]);\n * tf.layers.concatenate([input1, input2]).print();\n * // Gives [[1, 2, 10, 20], [3, 4, 30, 40]].\n *\n */\nexport function concatenate(config) {\n    if (Array.isArray(config)) {\n        const layer = new Concatenate({});\n        return layer.apply(config);\n    }\n    else {\n        return new Concatenate(config);\n    }\n}\n/**\n * Interpretable potentially negative axis index.\n *\n * For example, given axis = -1, and dim = 3, this function will return 2.\n *\n * @param axis The axis index, may be a positive, zero or negative integer.\n * @param dim Total number of dimensions, a positive integer.\n * @returns A non-negative axis index equivalent to the input `axis`.\n */\nfunction interpretAxis(axis, dim) {\n    while (axis < 0) {\n        axis += dim;\n    }\n    return axis;\n}\nfunction batchDot(x, y, axes) {\n    if (x.shape.length > 3 || y.shape.length > 3) {\n        throw new NotImplementedError('batchDot is not implemented for tensors of 4D or higher rank yet');\n    }\n    tfc.util.assert(x.shape.length >= 2, () => `batchDot requires the rank of x to be >= 2, ` +\n        `but got ${x.shape.length}`);\n    tfc.util.assert(x.shape.length >= 2, () => `batchDot requires the rank of y to be >= 2, ` +\n        `but got ${y.shape.length}`);\n    if (typeof axes === 'number') {\n        axes = [axes, axes];\n    }\n    if (x.dtype === 'complex64' || y.dtype === 'complex64') {\n        throw new NotImplementedError('batchDot is not implemented for complex64-type Tensors yet.');\n    }\n    const xNDim = x.shape.length;\n    const yNDim = y.shape.length;\n    if (axes == null) {\n        // Behave like batchMatmul by default.\n        axes = [xNDim - 1, yNDim - 2];\n    }\n    const axesArray = axes;\n    return tfc.tidy(() => {\n        let diff;\n        if (xNDim > yNDim) {\n            diff = xNDim - yNDim;\n            const diffShape = [];\n            for (let i = 0; i < diff; ++i) {\n                diffShape.push(1);\n            }\n            y = tfc.reshape(y, y.shape.concat(diffShape));\n        }\n        else if (yNDim > xNDim) {\n            diff = yNDim - xNDim;\n            const diffShape = [];\n            for (let i = 0; i < diff; ++i) {\n                diffShape.push(1);\n            }\n            x = tfc.reshape(x, x.shape.concat(diffShape));\n        }\n        else {\n            diff = 0;\n        }\n        let out;\n        if (x.shape.length === 2 && y.shape.length === 2) {\n            if (axesArray[0] === axesArray[1]) {\n                out = tfc.sum(tfc.mul(x, y), axesArray[0]);\n            }\n            else {\n                out = tfc.sum(tfc.mul(tfc.transpose(x, [1, 0]), y), axesArray[1]);\n            }\n        }\n        else {\n            const adjX = axesArray[0] !== x.shape.length - 1;\n            const adjY = axesArray[1] === y.shape.length - 1;\n            out = tfc.matMul(x, y, adjX, adjY);\n        }\n        if (diff > 0) {\n            let idx;\n            if (xNDim > yNDim) {\n                idx = xNDim + yNDim - 3;\n            }\n            else {\n                idx = xNDim - 1;\n            }\n            const squeezeAxes = [];\n            for (let i = idx; i < idx + diff; ++i) {\n                squeezeAxes.push(i);\n            }\n            out = tfc.squeeze(out, squeezeAxes);\n        }\n        if (out.shape.length === 1) {\n            out = tfc.expandDims(out, 1);\n        }\n        return out;\n    });\n}\nexport class Dot extends Merge {\n    constructor(args) {\n        super(args);\n        this.axes = args.axes;\n        this.normalize = args.normalize == null ? false : args.normalize;\n        this.supportsMasking = true;\n        this.reshapeRequired = false;\n    }\n    build(inputShape) {\n        tfc.util.assert(Array.isArray(inputShape) && inputShape.length === 2 &&\n            Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), () => 'A `Dot` layer should be called on a list of exactly 2 inputs.');\n        const shape1 = inputShape[0];\n        const shape2 = inputShape[1];\n        if (shape1.length > 3 || shape2.length > 3) {\n            throw new NotImplementedError('Dot layer does not support tensors of 4D or higher rank yet.');\n        }\n        const axes = this.interpretAxes(shape1, shape2);\n        if (shape1[axes[0]] !== shape2[axes[1]]) {\n            throw new ValueError(`Dimension incompatibility: ` +\n                `${shape1[axes[0]]} !== ${shape2[axes[1]]}`);\n        }\n    }\n    mergeFunction(inputs) {\n        if (inputs.length !== 2) {\n            throw new ValueError('A `Dot` layer must be called on exactly 2 inputs, ' +\n                `but received ${inputs.length} input(s).`);\n        }\n        let x1 = inputs[0];\n        let x2 = inputs[1];\n        let axes;\n        if (!Array.isArray(this.axes)) {\n            axes = [\n                interpretAxis(this.axes, x1.shape.length),\n                interpretAxis(this.axes, x2.shape.length)\n            ];\n        }\n        else {\n            axes = this.axes.map((axis, i) => interpretAxis(axis, inputs[i].shape.length));\n        }\n        if (this.normalize) {\n            x1 = l2Normalize(x1, axes[0]);\n            x2 = l2Normalize(x2, axes[1]);\n        }\n        return batchDot(x1, x2, axes);\n    }\n    interpretAxes(shape1, shape2) {\n        let axes;\n        if (!Array.isArray(this.axes)) {\n            // `this.axes` is a single integer.\n            axes = [\n                interpretAxis(this.axes, shape1.length),\n                interpretAxis(this.axes, shape2.length)\n            ];\n        }\n        else {\n            // `this.axes` is an Array of integers.\n            axes = this.axes;\n        }\n        return axes;\n    }\n    computeOutputShape(inputShape) {\n        tfc.util.assert(Array.isArray(inputShape) && inputShape.length === 2 &&\n            Array.isArray(inputShape[0]) && Array.isArray(inputShape[1]), () => 'A `Dot` layer should be called on a list of exactly 2 inputs.');\n        const shape1 = inputShape[0].slice();\n        const shape2 = inputShape[1].slice();\n        if (shape1.length > 3 || shape2.length > 3) {\n            throw new NotImplementedError('Dot layer does not support tensors of 4D or higher rank yet.');\n        }\n        const axes = this.interpretAxes(shape1, shape2);\n        shape1.splice(axes[0], 1);\n        shape2.splice(axes[1], 1);\n        shape2.splice(0, 1);\n        const outputShape = shape1.concat(shape2);\n        if (outputShape.length === 1) {\n            outputShape.push(1);\n        }\n        return outputShape;\n    }\n    computeMask(inputs, mask) {\n        return null;\n    }\n    getConfig() {\n        const config = {\n            'axes': this.axes,\n            'normalize': this.normalize\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nDot.className = 'Dot';\nserialization.registerClass(Dot);\n// TODO(cais): Add functional interfaces for the merge layers.\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA;AACA;AACA;AACA,OAAO,KAAKA,GAAZ,MAAqB,uBAArB;AACA,SAASC,aAAT,EAAwBC,IAAxB,EAA8BC,IAA9B,QAA0C,uBAA1C;AACA,OAAO,KAAKC,CAAZ,MAAmB,yBAAnB;AACA,SAASC,KAAT,QAAsB,oBAAtB;AACA,SAASC,mBAAT,EAA8BC,UAA9B,QAAgD,WAAhD;AACA,SAASC,WAAT,QAA4B,WAA5B;AACA,OAAO,KAAKC,aAAZ,MAA+B,wBAA/B;AACA,OAAO,KAAKC,SAAZ,MAA2B,qBAA3B;AACA,SAASC,kBAAT,QAAmC,sBAAnC;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,MAAMC,KAAN,SAAoBP,KAApB,CAA0B;EAC7BQ,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAI,IAAI,EAAd;IACA,KAAKC,eAAL,GAAuB,IAAvB;EACH;EACD;AACJ;AACA;AACA;;;EACIC,aAAa,CAACC,MAAD,EAAS;IAClB,MAAM,IAAIX,mBAAJ,EAAN;EACH;EACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACIY,+BAA+B,CAACC,MAAD,EAASC,MAAT,EAAiB;IAC5C,IAAID,MAAM,IAAI,IAAV,IAAkBC,MAAM,IAAI,IAAhC,EAAsC;MAClC,OAAO,IAAP;IACH,CAFD,MAGK,IAAID,MAAM,CAACE,MAAP,GAAgBD,MAAM,CAACC,MAA3B,EAAmC;MACpC,OAAO,KAAKH,+BAAL,CAAqCE,MAArC,EAA6CD,MAA7C,CAAP;IACH,CAFI,MAGA,IAAIC,MAAM,CAACC,MAAP,KAAkB,CAAtB,EAAyB;MAC1B,OAAOF,MAAP;IACH;;IACD,MAAMG,WAAW,GAAGH,MAAM,CAACI,KAAP,CAAa,CAAb,EAAgBJ,MAAM,CAACE,MAAP,GAAgBD,MAAM,CAACC,MAAvC,CAApB;;IACA,KAAK,IAAIG,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGJ,MAAM,CAACC,MAA3B,EAAmC,EAAEG,CAArC,EAAwC;MACpC,MAAMC,CAAC,GAAGN,MAAM,CAACA,MAAM,CAACE,MAAP,GAAgBD,MAAM,CAACC,MAAvB,GAAgCG,CAAjC,CAAhB;MACA,MAAME,CAAC,GAAGN,MAAM,CAACI,CAAD,CAAhB;;MACA,IAAIC,CAAC,IAAI,IAAL,IAAaC,CAAC,IAAI,IAAlB,IAA0BD,CAAC,GAAG,CAA9B,IAAmCC,CAAC,GAAG,CAA3C,EAA8C;QAC1CJ,WAAW,CAACK,IAAZ,CAAiB,IAAjB;MACH,CAFD,MAGK,IAAIF,CAAC,KAAK,CAAV,EAAa;QACdH,WAAW,CAACK,IAAZ,CAAiBD,CAAjB;MACH,CAFI,MAGA,IAAIA,CAAC,KAAK,CAAV,EAAa;QACdJ,WAAW,CAACK,IAAZ,CAAiBF,CAAjB;MACH,CAFI,MAGA;QACD,IAAIA,CAAC,KAAKC,CAAV,EAAa;UACT,MAAM,IAAInB,UAAJ,CAAe,0DACjBqB,IAAI,CAACC,SAAL,CAAeV,MAAf,CADiB,GACQ,GADR,GACcS,IAAI,CAACC,SAAL,CAAeT,MAAf,CAD7B,CAAN;QAEH;;QACDE,WAAW,CAACK,IAAZ,CAAiBF,CAAjB;MACH;IACJ;;IACD,OAAOH,WAAP;EACH;;EACDQ,KAAK,CAACC,UAAD,EAAa;IACd;IACA,IAAIC,KAAK,CAACC,OAAN,CAAcF,UAAd,KAA6B,CAACC,KAAK,CAACC,OAAN,CAAcF,UAAU,CAAC,CAAD,CAAxB,CAAlC,EAAgE;MAC5D;MACAA,UAAU,GAAG,CAACpB,kBAAkB,CAACoB,UAAD,CAAnB,CAAb;IACH;;IACDA,UAAU,GAAGA,UAAb;;IACA,IAAIA,UAAU,CAACV,MAAX,GAAoB,CAAxB,EAA2B;MACvB,MAAM,IAAId,UAAJ,CAAe,qEAChB,QAAOwB,UAAU,CAACV,MAAO,YADxB,CAAN;IAEH,CAVa,CAWd;IACA;;;IACA,IAAIa,UAAU,GAAG,EAAjB;;IACA,KAAK,MAAMC,KAAX,IAAoBJ,UAApB,EAAgC;MAC5B,IAAII,KAAK,IAAI,IAAT,IAAiBA,KAAK,CAAC,CAAD,CAAL,KAAa,IAAlC,EAAwC;QACpCD,UAAU,CAACP,IAAX,CAAgBQ,KAAK,CAAC,CAAD,CAArB;MACH;IACJ;;IACDD,UAAU,GAAGzB,aAAa,CAAC2B,MAAd,CAAqBF,UAArB,CAAb;;IACA,IAAIA,UAAU,CAACb,MAAX,GAAoB,CAAxB,EAA2B;MACvB,MAAM,IAAId,UAAJ,CAAgB,oDAAD,GAChB,4BAA2BqB,IAAI,CAACC,SAAL,CAAeE,UAAf,CAA2B,GADrD,CAAN;IAEH;;IACD,IAAIT,WAAW,GAAGS,UAAU,CAAC,CAAD,CAAV,IAAiB,IAAjB,GAAwB,IAAxB,GAA+BA,UAAU,CAAC,CAAD,CAAV,CAAcR,KAAd,CAAoB,CAApB,CAAjD;;IACA,KAAK,IAAIE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGM,UAAU,CAACV,MAA/B,EAAuC,EAAEI,CAAzC,EAA4C;MACxC,MAAMU,KAAK,GAAGJ,UAAU,CAACN,CAAD,CAAV,IAAiB,IAAjB,GAAwB,IAAxB,GAA+BM,UAAU,CAACN,CAAD,CAAV,CAAcF,KAAd,CAAoB,CAApB,CAA7C;MACAD,WAAW,GAAG,KAAKJ,+BAAL,CAAqCI,WAArC,EAAkDa,KAAlD,CAAd;IACH,CA5Ba,CA6Bd;IACA;;;IACA,MAAME,QAAQ,GAAGN,UAAU,CAACO,GAAX,CAAeH,KAAK,IAAIA,KAAK,CAACd,MAA9B,CAAjB;;IACA,IAAIU,UAAU,CAACQ,OAAX,CAAmB,IAAnB,MAA6B,CAAC,CAA9B,IACA9B,aAAa,CAAC2B,MAAd,CAAqBC,QAArB,EAA+BhB,MAA/B,KAA0C,CAD9C,EACiD;MAC7C,KAAKmB,eAAL,GAAuB,KAAvB;IACH,CAHD,MAIK;MACD,KAAKA,eAAL,GAAuB,IAAvB;IACH;EACJ;;EACDC,IAAI,CAACxB,MAAD,EAASyB,MAAT,EAAiB;IACjB,OAAOxC,IAAI,CAAC,MAAM;MACde,MAAM,GAAGA,MAAT;;MACA,IAAI,KAAKuB,eAAT,EAA0B;QACtB,MAAMG,cAAc,GAAG,EAAvB;QACA,MAAMC,SAAS,GAAG3B,MAAM,CAACqB,GAAP,CAAWO,KAAK,IAAIA,KAAK,CAACC,IAA1B,CAAlB;;QACA,IAAIF,SAAS,CAACL,OAAV,CAAkB,IAAlB,MAA4B,CAAC,CAAjC,EAAoC;UAChC;UACA;UACA,MAAMQ,OAAO,GAAGrC,SAAS,CAACsC,GAAV,CAAcJ,SAAd,CAAhB;;UACA,KAAK,IAAIK,CAAT,IAAchC,MAAd,EAAsB;YAClB,MAAMiC,KAAK,GAAGD,CAAC,CAACH,IAAhB;;YACA,KAAK,IAAItB,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGuB,OAAO,GAAGG,KAA9B,EAAqC,EAAE1B,CAAvC,EAA0C;cACtCyB,CAAC,GAAG7C,CAAC,CAAC+C,UAAF,CAAaF,CAAb,EAAgB,CAAhB,CAAJ;YACH;;YACDN,cAAc,CAAChB,IAAf,CAAoBsB,CAApB;UACH;;UACD,OAAO,KAAKjC,aAAL,CAAmB2B,cAAnB,CAAP;QACH,CAZD,MAaK;UACD;UACA;UACA,IAAIS,UAAU,GAAG,KAAjB;;UACA,KAAK,MAAMH,CAAX,IAAgBhC,MAAhB,EAAwB;YACpB,MAAMiC,KAAK,GAAGD,CAAC,CAACH,IAAhB;;YACA,IAAII,KAAK,IAAI,IAAb,EAAmB;cACf,MAAMG,MAAM,GAAGJ,CAAC,CAACd,KAAjB;cACA,MAAMmB,SAAS,GAAGD,MAAM,CAAC,CAAD,CAAxB;cACA,MAAME,QAAQ,GAAGF,MAAM,CAAC9B,KAAP,CAAa,CAAb,EAAgBiC,MAAhB,CAAuB,CAACF,SAAD,CAAvB,CAAjB;cACA,IAAIG,WAAW,GAAGzD,GAAG,CAAC0D,OAAJ,CAAYT,CAAZ,EAAe,CAACK,SAAD,EAAYE,MAAZ,CAAmB9C,SAAS,CAACiD,SAAV,CAAoBN,MAAM,CAAC9B,KAAP,CAAa,CAAb,CAApB,CAAnB,CAAf,CAAlB;cACAkC,WAAW,GAAGzD,GAAG,CAAC4D,SAAJ,CAAcH,WAAd,EAA2B,CAAC,CAAD,EAAI,CAAJ,CAA3B,CAAd;cACAA,WAAW,GAAGzD,GAAG,CAAC0D,OAAJ,CAAYD,WAAZ,EAAyBF,QAAzB,CAAd;cACAZ,cAAc,CAAChB,IAAf,CAAoB8B,WAApB;cACAL,UAAU,GAAG,IAAb;YACH,CATD,MAUK,IAAIF,KAAK,GAAG,CAAZ,EAAe;cAChB,MAAMW,IAAI,GAAGnD,SAAS,CAACoD,KAAV,CAAgB,CAAhB,EAAmBZ,KAAnB,EAA0BM,MAA1B,CAAiC,CAAC,CAAD,CAAjC,CAAb;cACAb,cAAc,CAAChB,IAAf,CAAoB3B,GAAG,CAAC4D,SAAJ,CAAcX,CAAd,EAAiBY,IAAjB,CAApB;cACAT,UAAU,GAAG,IAAb;YACH,CAJI,MAKA;cACD;cACAT,cAAc,CAAChB,IAAf,CAAoBsB,CAApB;YACH;UACJ;;UACD,IAAIc,CAAC,GAAG,KAAK/C,aAAL,CAAmB2B,cAAnB,CAAR;UACA,MAAMqB,KAAK,GAAGD,CAAC,CAACjB,IAAhB;;UACA,IAAIM,UAAJ,EAAgB;YACZ;YACA;YACA,IAAIY,KAAK,IAAI,IAAb,EAAmB;cACf,MAAMC,MAAM,GAAGF,CAAC,CAAC5B,KAAjB;cACA,MAAM6B,KAAK,GAAGC,MAAM,CAAC5C,MAArB;cACA,MAAMiC,SAAS,GAAGW,MAAM,CAACD,KAAK,GAAG,CAAT,CAAxB;cACA,MAAMT,QAAQ,GAAG,CAACD,SAAD,EAAYE,MAAZ,CAAmBS,MAAM,CAAC1C,KAAP,CAAa,CAAb,EAAgB0C,MAAM,CAAC5C,MAAP,GAAgB,CAAhC,CAAnB,CAAjB;cACA0C,CAAC,GAAG/D,GAAG,CAAC0D,OAAJ,CAAY1D,GAAG,CAAC4D,SAAJ,CAAc5D,GAAG,CAAC0D,OAAJ,CAAYK,CAAZ,EAAe,CAAC,CAAC,CAAF,EAAKT,SAAL,CAAf,CAAd,EAA+C,CAAC,CAAD,EAAI,CAAJ,CAA/C,CAAZ,EAAoEC,QAApE,CAAJ;YACH,CAND,MAOK,IAAIS,KAAK,GAAG,CAAZ,EAAe;cAChB,MAAMH,IAAI,GAAG,CAACG,KAAK,GAAG,CAAT,EAAYR,MAAZ,CAAmB9C,SAAS,CAACoD,KAAV,CAAgB,CAAhB,EAAmBE,KAAK,GAAG,CAA3B,CAAnB,CAAb;cACAD,CAAC,GAAG/D,GAAG,CAAC4D,SAAJ,CAAcG,CAAd,EAAiBF,IAAjB,CAAJ;YACH;UACJ;;UACD,OAAOE,CAAP;QACH;MACJ,CA7DD,MA8DK;QACD,OAAO,KAAK/C,aAAL,CAAmBC,MAAnB,CAAP;MACH;IACJ,CAnEU,CAAX;EAoEH;;EACDiD,kBAAkB,CAACnC,UAAD,EAAa;IAC3BA,UAAU,GAAGA,UAAb;IACA,IAAIT,WAAJ;;IACA,IAAIS,UAAU,CAAC,CAAD,CAAV,IAAiB,IAArB,EAA2B;MACvBT,WAAW,GAAG,IAAd;IACH,CAFD,MAGK;MACDA,WAAW,GAAGS,UAAU,CAAC,CAAD,CAAV,CAAcR,KAAd,CAAoB,CAApB,CAAd;IACH;;IACD,KAAK,IAAIE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGM,UAAU,CAACV,MAA/B,EAAuC,EAAEI,CAAzC,EAA4C;MACxC,MAAMU,KAAK,GAAGJ,UAAU,CAACN,CAAD,CAAV,IAAiB,IAAjB,GAAwB,IAAxB,GAA+BM,UAAU,CAACN,CAAD,CAAV,CAAcF,KAAd,CAAoB,CAApB,CAA7C;MACAD,WAAW,GAAG,KAAKJ,+BAAL,CAAqCI,WAArC,EAAkDa,KAAlD,CAAd;IACH;;IACD,IAAID,UAAU,GAAG,EAAjB;;IACA,KAAK,MAAMC,KAAX,IAAoBJ,UAApB,EAAgC;MAC5B,IAAII,KAAK,IAAI,IAAT,IAAiBA,KAAK,CAAC,CAAD,CAAL,KAAa,IAAlC,EAAwC;QACpCD,UAAU,CAACP,IAAX,CAAgBQ,KAAK,CAAC,CAAD,CAArB;MACH;IACJ;;IACDD,UAAU,GAAGzB,aAAa,CAAC2B,MAAd,CAAqBF,UAArB,CAAb;;IACA,IAAIA,UAAU,CAACb,MAAX,KAAsB,CAA1B,EAA6B;MACzBC,WAAW,GAAGY,UAAU,CAACsB,MAAX,CAAkBlC,WAAlB,CAAd;IACH,CAFD,MAGK;MACDA,WAAW,GAAG,CAAC,IAAD,EAAOkC,MAAP,CAAclC,WAAd,CAAd;IACH;;IACD,OAAOA,WAAP;EACH;;EACD6C,WAAW,CAAClD,MAAD,EAASmD,IAAT,EAAe;IACtB,OAAOpE,GAAG,CAACE,IAAJ,CAAS,MAAM;MAClB,IAAIkE,IAAI,IAAI,IAAZ,EAAkB;QACd,OAAO,IAAP;MACH;;MACD,IAAI,CAACpC,KAAK,CAACC,OAAN,CAAcmC,IAAd,CAAL,EAA0B;QACtB,MAAM,IAAI7D,UAAJ,CAAe,2BAAf,CAAN;MACH;;MACD,IAAI,CAACyB,KAAK,CAACC,OAAN,CAAchB,MAAd,CAAL,EAA4B;QACxB,MAAM,IAAIV,UAAJ,CAAe,6BAAf,CAAN;MACH;;MACD,IAAI6D,IAAI,CAAC/C,MAAL,KAAgBJ,MAAM,CAACI,MAA3B,EAAmC;QAC/B,MAAM,IAAId,UAAJ,CAAgB,8DAAD,GAChB,qCADgB,GAEhB,IAAGU,MAAM,CAACI,MAAO,OAAM+C,IAAI,CAAC/C,MAAO,GAFlC,CAAN;MAGH;;MACD,IAAI+C,IAAI,CAACC,KAAL,CAAWC,CAAC,IAAIA,CAAC,IAAI,IAArB,CAAJ,EAAgC;QAC5B,OAAO,IAAP;MACH;;MACDF,IAAI,GAAGA,IAAI,CAAC9B,GAAL,CAASgC,CAAC,IAAIA,CAAC,IAAI,IAAL,GAAYA,CAAZ,GAAgBtE,GAAG,CAACmD,UAAJ,CAAemB,CAAf,EAAkB,CAAlB,CAA9B,CAAP;MACA,IAAIC,MAAM,GAAGH,IAAI,CAAC,CAAD,CAAjB;;MACA,KAAK,IAAI3C,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG2C,IAAI,CAAC/C,MAAL,GAAc,CAAlC,EAAqC,EAAEI,CAAvC,EAA0C;QACtC8C,MAAM,GAAGvE,GAAG,CAACwE,UAAJ,CAAeD,MAAf,EAAuBH,IAAI,CAAC3C,CAAD,CAA3B,CAAT;MACH;;MACD,OAAO8C,MAAP;IACH,CAxBM,CAAP;EAyBH;;AA3N4B;AA6NjC,OAAO,MAAME,GAAN,SAAkB7D,KAAlB,CAAwB;EAC3BC,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAN;EACH;;EACDE,aAAa,CAACC,MAAD,EAAS;IAClB,OAAOf,IAAI,CAAC,MAAM;MACd,IAAIqE,MAAM,GAAGtD,MAAM,CAAC,CAAD,CAAN,CAAUyD,KAAV,EAAb;;MACA,KAAK,IAAIjD,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGR,MAAM,CAACI,MAA3B,EAAmC,EAAEI,CAArC,EAAwC;QACpC8C,MAAM,GAAGvE,GAAG,CAAC2E,GAAJ,CAAQJ,MAAR,EAAgBtD,MAAM,CAACQ,CAAD,CAAtB,CAAT;MACH;;MACD,OAAO8C,MAAP;IACH,CANU,CAAX;EAOH;;AAZ0B;AAc/B;;AACAE,GAAG,CAACG,SAAJ,GAAgB,KAAhB;AACA3E,aAAa,CAAC4E,aAAd,CAA4BJ,GAA5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASE,GAAT,CAAaG,MAAb,EAAqB;EACxB,IAAI9C,KAAK,CAACC,OAAN,CAAc6C,MAAd,CAAJ,EAA2B;IACvB,MAAMC,KAAK,GAAG,IAAIN,GAAJ,CAAQ,EAAR,CAAd;IACA,OAAOM,KAAK,CAACC,KAAN,CAAYF,MAAZ,CAAP;EACH,CAHD,MAIK;IACD,OAAO,IAAIL,GAAJ,CAAQK,MAAR,CAAP;EACH;AACJ;AACD,OAAO,MAAMG,QAAN,SAAuBrE,KAAvB,CAA6B;EAChCC,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAN;EACH;;EACDE,aAAa,CAACC,MAAD,EAAS;IAClB,OAAOf,IAAI,CAAC,MAAM;MACd,IAAIqE,MAAM,GAAGtD,MAAM,CAAC,CAAD,CAAN,CAAUyD,KAAV,EAAb;;MACA,KAAK,IAAIjD,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGR,MAAM,CAACI,MAA3B,EAAmC,EAAEI,CAArC,EAAwC;QACpC8C,MAAM,GAAGvE,GAAG,CAACkF,GAAJ,CAAQX,MAAR,EAAgBtD,MAAM,CAACQ,CAAD,CAAtB,CAAT;MACH;;MACD,OAAO8C,MAAP;IACH,CANU,CAAX;EAOH;;AAZ+B;AAcpC;;AACAU,QAAQ,CAACL,SAAT,GAAqB,UAArB;AACA3E,aAAa,CAAC4E,aAAd,CAA4BI,QAA5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASE,QAAT,CAAkBL,MAAlB,EAA0B;EAC7B,IAAI9C,KAAK,CAACC,OAAN,CAAc6C,MAAd,CAAJ,EAA2B;IACvB,MAAMC,KAAK,GAAG,IAAIE,QAAJ,CAAa,EAAb,CAAd;IACA,OAAOF,KAAK,CAACC,KAAN,CAAYF,MAAZ,CAAP;EACH,CAHD,MAIK;IACD,OAAO,IAAIG,QAAJ,CAAaH,MAAb,CAAP;EACH;AACJ;AACD,OAAO,MAAMM,OAAN,SAAsBxE,KAAtB,CAA4B;EAC/BC,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAN;EACH;;EACDE,aAAa,CAACC,MAAD,EAAS;IAClB,OAAOf,IAAI,CAAC,MAAM;MACd,IAAIqE,MAAM,GAAGtD,MAAM,CAAC,CAAD,CAAN,CAAUyD,KAAV,EAAb;;MACA,KAAK,IAAIjD,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGR,MAAM,CAACI,MAA3B,EAAmC,EAAEI,CAArC,EAAwC;QACpC8C,MAAM,GAAGvE,GAAG,CAAC2E,GAAJ,CAAQJ,MAAR,EAAgBtD,MAAM,CAACQ,CAAD,CAAtB,CAAT;MACH;;MACD,OAAOzB,GAAG,CAACkF,GAAJ,CAAQ,IAAIjE,MAAM,CAACI,MAAnB,EAA2BkD,MAA3B,CAAP;IACH,CANU,CAAX;EAOH;;AAZ8B;AAcnC;;AACAa,OAAO,CAACR,SAAR,GAAoB,SAApB;AACA3E,aAAa,CAAC4E,aAAd,CAA4BO,OAA5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,OAAT,CAAiBP,MAAjB,EAAyB;EAC5B,IAAI9C,KAAK,CAACC,OAAN,CAAc6C,MAAd,CAAJ,EAA2B;IACvB,MAAMC,KAAK,GAAG,IAAIK,OAAJ,CAAY,EAAZ,CAAd;IACA,OAAOL,KAAK,CAACC,KAAN,CAAYF,MAAZ,CAAP;EACH,CAHD,MAIK;IACD,OAAO,IAAIM,OAAJ,CAAYN,MAAZ,CAAP;EACH;AACJ;AACD,OAAO,MAAMQ,OAAN,SAAsB1E,KAAtB,CAA4B;EAC/BC,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAN;EACH;;EACDE,aAAa,CAACC,MAAD,EAAS;IAClB,OAAOf,IAAI,CAAC,MAAM;MACd,IAAIqE,MAAM,GAAGtD,MAAM,CAAC,CAAD,CAAnB;;MACA,KAAK,IAAIQ,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGR,MAAM,CAACI,MAA3B,EAAmC,EAAEI,CAArC,EAAwC;QACpC8C,MAAM,GAAGvE,GAAG,CAACuF,OAAJ,CAAYhB,MAAZ,EAAoBtD,MAAM,CAACQ,CAAD,CAA1B,CAAT;MACH;;MACD,OAAO8C,MAAP;IACH,CANU,CAAX;EAOH;;AAZ8B;AAcnC;;AACAe,OAAO,CAACV,SAAR,GAAoB,SAApB;AACA3E,aAAa,CAAC4E,aAAd,CAA4BS,OAA5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,OAAT,CAAiBT,MAAjB,EAAyB;EAC5B,IAAI9C,KAAK,CAACC,OAAN,CAAc6C,MAAd,CAAJ,EAA2B;IACvB,MAAMC,KAAK,GAAG,IAAIO,OAAJ,CAAY,EAAZ,CAAd;IACA,OAAOP,KAAK,CAACC,KAAN,CAAYF,MAAZ,CAAP;EACH,CAHD,MAIK;IACD,OAAO,IAAIQ,OAAJ,CAAYR,MAAZ,CAAP;EACH;AACJ;AACD,OAAO,MAAMU,OAAN,SAAsB5E,KAAtB,CAA4B;EAC/BC,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAN;EACH;;EACDE,aAAa,CAACC,MAAD,EAAS;IAClB,OAAOf,IAAI,CAAC,MAAM;MACd,IAAIqE,MAAM,GAAGtD,MAAM,CAAC,CAAD,CAAnB;;MACA,KAAK,IAAIQ,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGR,MAAM,CAACI,MAA3B,EAAmC,EAAEI,CAArC,EAAwC;QACpC8C,MAAM,GAAGvE,GAAG,CAACyF,OAAJ,CAAYlB,MAAZ,EAAoBtD,MAAM,CAACQ,CAAD,CAA1B,CAAT;MACH;;MACD,OAAO8C,MAAP;IACH,CANU,CAAX;EAOH;;AAZ8B;AAcnC;;AACAiB,OAAO,CAACZ,SAAR,GAAoB,SAApB;AACA3E,aAAa,CAAC4E,aAAd,CAA4BW,OAA5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,OAAT,CAAiBX,MAAjB,EAAyB;EAC5B,IAAI9C,KAAK,CAACC,OAAN,CAAc6C,MAAd,CAAJ,EAA2B;IACvB,MAAMC,KAAK,GAAG,IAAIS,OAAJ,CAAY,EAAZ,CAAd;IACA,OAAOT,KAAK,CAACC,KAAN,CAAYF,MAAZ,CAAP;EACH,CAHD,MAIK;IACD,OAAO,IAAIU,OAAJ,CAAYV,MAAZ,CAAP;EACH;AACJ;AACD,OAAO,MAAMY,WAAN,SAA0B9E,KAA1B,CAAgC;EACnCC,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAN;IACA,KAAK6E,YAAL,GAAoB,CAAC,CAArB;;IACA,IAAI7E,IAAI,IAAI,IAAZ,EAAkB;MACdA,IAAI,GAAG,EAAP;IACH;;IACD,KAAK8E,IAAL,GAAY9E,IAAI,CAAC8E,IAAL,IAAa,IAAb,GAAoB,KAAKD,YAAzB,GAAwC7E,IAAI,CAAC8E,IAAzD;IACA,KAAK7E,eAAL,GAAuB,IAAvB;IACA,KAAKyB,eAAL,GAAuB,KAAvB;EACH;;EACDV,KAAK,CAACC,UAAD,EAAa;IACd;IACA,IAAI,EAAEC,KAAK,CAACC,OAAN,CAAcF,UAAd,KAA6BC,KAAK,CAACC,OAAN,CAAcF,UAAU,CAAC,CAAD,CAAxB,CAA/B,KACAA,UAAU,CAACV,MAAX,KAAsB,CAD1B,EAC6B;MACzB,MAAM,IAAId,UAAJ,CAAe,oEACjB,QADE,CAAN;IAEH;;IACDwB,UAAU,GAAGA,UAAb;IACA,IAAI8D,YAAY,GAAG,IAAnB;;IACA,KAAK,MAAM1D,KAAX,IAAoBJ,UAApB,EAAgC;MAC5B,IAAII,KAAK,IAAI,IAAb,EAAmB;QACf0D,YAAY,GAAG,KAAf;QACA;MACH;IACJ;;IACD,IAAIA,YAAJ,EAAkB;MACd;IACH;;IACD,MAAMC,QAAQ,GAAG,EAAjB;;IACA,KAAK,IAAIrE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGM,UAAU,CAACV,MAA/B,EAAuC,EAAEI,CAAzC,EAA4C;MACxC,MAAMsE,sBAAsB,GAAGhE,UAAU,CAACN,CAAD,CAAV,CAAcF,KAAd,EAA/B;MACAwE,sBAAsB,CAACC,MAAvB,CAA8B,KAAKJ,IAAnC,EAAyC,CAAzC;MACA,IAAIK,MAAM,GAAG,KAAb;;MACA,KAAK,MAAM9D,KAAX,IAAoB2D,QAApB,EAA8B;QAC1B,IAAI3F,IAAI,CAAC+F,WAAL,CAAiB/D,KAAjB,EAAwB4D,sBAAxB,CAAJ,EAAqD;UACjDE,MAAM,GAAG,IAAT;UACA;QACH;MACJ;;MACD,IAAI,CAACA,MAAL,EAAa;QACTH,QAAQ,CAACnE,IAAT,CAAcoE,sBAAd;MACH;IACJ;;IACD,IAAID,QAAQ,CAACzE,MAAT,GAAkB,CAAtB,EAAyB;MACrB,MAAM,IAAId,UAAJ,CAAe,gEACjB,gDADiB,GAEjBqB,IAAI,CAACC,SAAL,CAAeE,UAAf,CAFE,CAAN;IAGH;EACJ;;EACDf,aAAa,CAACC,MAAD,EAAS;IAClB,OAAOf,IAAI,CAAC,MAAM;MACd,OAAOE,CAAC,CAAC+F,WAAF,CAAclF,MAAd,EAAsB,KAAK2E,IAA3B,CAAP;IACH,CAFU,CAAX;EAGH;;EACD1B,kBAAkB,CAACnC,UAAD,EAAa;IAC3B,IAAI,EAAEC,KAAK,CAACC,OAAN,CAAcF,UAAd,KAA6BC,KAAK,CAACC,OAAN,CAAcF,UAAU,CAAC,CAAD,CAAxB,CAA/B,CAAJ,EAAkE;MAC9D,MAAM,IAAIxB,UAAJ,CAAe,6DAAf,CAAN;IACH;;IACD,MAAM6F,WAAW,GAAGrE,UAApB;IACA,MAAMT,WAAW,GAAG8E,WAAW,CAAC,CAAD,CAAX,CAAe7E,KAAf,EAApB;IACA,MAAMqE,IAAI,GAAG,KAAKA,IAAL,GAAY,CAAZ,GAAgBtE,WAAW,CAACD,MAAZ,GAAqB,KAAKuE,IAA1C,GAAiD,KAAKA,IAAnE,CAN2B,CAO3B;IACA;;IACA,KAAK,MAAMzD,KAAX,IAAoBiE,WAAW,CAAC7E,KAAZ,CAAkB,CAAlB,CAApB,EAA0C;MACtC,IAAID,WAAW,CAACsE,IAAD,CAAX,IAAqB,IAArB,IAA6BzD,KAAK,CAACyD,IAAD,CAAL,IAAe,IAAhD,EAAsD;QAClDtE,WAAW,CAACsE,IAAD,CAAX,GAAoB,IAApB;QACA;MACH;;MACDtE,WAAW,CAACsE,IAAD,CAAX,IAAqBzD,KAAK,CAACyD,IAAD,CAA1B;IACH;;IACD,OAAOtE,WAAP;EACH;;EACD6C,WAAW,CAAClD,MAAD,EAASmD,IAAT,EAAe;IACtB,IAAIA,IAAI,IAAI,IAAZ,EAAkB;MACd,OAAO,IAAP;IACH;;IACD,IAAI,CAACpC,KAAK,CAACC,OAAN,CAAcmC,IAAd,CAAL,EAA0B;MACtB,MAAM,IAAI7D,UAAJ,CAAe,2CAAf,CAAN;IACH;;IACD,IAAI,CAACyB,KAAK,CAACC,OAAN,CAAchB,MAAd,CAAL,EAA4B;MACxB,MAAM,IAAIV,UAAJ,CAAe,6CAAf,CAAN;IACH;;IACD,IAAI6D,IAAI,CAAC/C,MAAL,KAAgBJ,MAAM,CAACI,MAA3B,EAAmC;MAC/B,MAAM,IAAId,UAAJ,CAAgB,mCAAkC6D,IAAI,CAAC/C,MAAO,IAA/C,GAChB,6BAA4BJ,MAAM,CAACI,MAAO,GADzC,CAAN;IAEH;;IACD,OAAOrB,GAAG,CAACE,IAAJ,CAAS,MAAM;MAClB,IAAImG,YAAY,GAAG,IAAnB;MACAjC,IAAI,CAACkC,OAAL,CAAahC,CAAC,IAAI;QACd,IAAIA,CAAC,IAAI,IAAT,EAAe;UACX+B,YAAY,GAAG,KAAf;UACA;QACH;MACJ,CALD;;MAMA,IAAIA,YAAJ,EAAkB;QACd,OAAO,IAAP;MACH;;MACD,MAAME,WAAW,GAAG,EAApB;;MACA,KAAK,IAAI9E,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGR,MAAM,CAACI,MAA3B,EAAmC,EAAEI,CAArC,EAAwC;QACpC,IAAI2C,IAAI,CAAC3C,CAAD,CAAJ,IAAW,IAAf,EAAqB;UACjB;UACA8E,WAAW,CAAC5E,IAAZ,CAAiB3B,GAAG,CAACwG,IAAJ,CAASxG,GAAG,CAACyG,QAAJ,CAAaxF,MAAM,CAACQ,CAAD,CAAnB,CAAT,EAAkC,MAAlC,CAAjB;QACH,CAHD,MAIK,IAAI2C,IAAI,CAAC3C,CAAD,CAAJ,CAAQqB,IAAR,GAAe7B,MAAM,CAACQ,CAAD,CAAN,CAAUqB,IAA7B,EAAmC;UACpC;UACAyD,WAAW,CAAC5E,IAAZ,CAAiB3B,GAAG,CAACmD,UAAJ,CAAeiB,IAAI,CAAC3C,CAAD,CAAnB,EAAwB,CAAC,CAAzB,CAAjB;QACH,CAHI,MAIA;UACD8E,WAAW,CAAC5E,IAAZ,CAAiByC,IAAI,CAAC3C,CAAD,CAArB;QACH;MACJ;;MACD,MAAMiF,iBAAiB,GAAG1G,GAAG,CAACwD,MAAJ,CAAW+C,WAAX,EAAwB,KAAKX,IAA7B,CAA1B;MACA,OAAO5F,GAAG,CAAC2G,GAAJ,CAAQD,iBAAR,EAA2B,CAAC,CAA5B,EAA+B,KAA/B,CAAP;IACH,CA3BM,CAAP;EA4BH;;EACDE,SAAS,GAAG;IACR,MAAM9B,MAAM,GAAG;MACX,QAAQ,KAAKc;IADF,CAAf;IAGA,MAAMiB,UAAU,GAAG,MAAMD,SAAN,EAAnB;IACAE,MAAM,CAACC,MAAP,CAAcjC,MAAd,EAAsB+B,UAAtB;IACA,OAAO/B,MAAP;EACH;;AA3HkC;AA6HvC;;AACAY,WAAW,CAACd,SAAZ,GAAwB,aAAxB;AACA3E,aAAa,CAAC4E,aAAd,CAA4Ba,WAA5B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASS,WAAT,CAAqBrB,MAArB,EAA6B;EAChC,IAAI9C,KAAK,CAACC,OAAN,CAAc6C,MAAd,CAAJ,EAA2B;IACvB,MAAMC,KAAK,GAAG,IAAIW,WAAJ,CAAgB,EAAhB,CAAd;IACA,OAAOX,KAAK,CAACC,KAAN,CAAYF,MAAZ,CAAP;EACH,CAHD,MAIK;IACD,OAAO,IAAIY,WAAJ,CAAgBZ,MAAhB,CAAP;EACH;AACJ;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,SAASkC,aAAT,CAAuBpB,IAAvB,EAA6BqB,GAA7B,EAAkC;EAC9B,OAAOrB,IAAI,GAAG,CAAd,EAAiB;IACbA,IAAI,IAAIqB,GAAR;EACH;;EACD,OAAOrB,IAAP;AACH;;AACD,SAASsB,QAAT,CAAkBjE,CAAlB,EAAqBc,CAArB,EAAwBoD,IAAxB,EAA8B;EAC1B,IAAIlE,CAAC,CAACd,KAAF,CAAQd,MAAR,GAAiB,CAAjB,IAAsB0C,CAAC,CAAC5B,KAAF,CAAQd,MAAR,GAAiB,CAA3C,EAA8C;IAC1C,MAAM,IAAIf,mBAAJ,CAAwB,kEAAxB,CAAN;EACH;;EACDN,GAAG,CAACG,IAAJ,CAASiH,MAAT,CAAgBnE,CAAC,CAACd,KAAF,CAAQd,MAAR,IAAkB,CAAlC,EAAqC,MAAO,8CAAD,GACtC,WAAU4B,CAAC,CAACd,KAAF,CAAQd,MAAO,EAD9B;EAEArB,GAAG,CAACG,IAAJ,CAASiH,MAAT,CAAgBnE,CAAC,CAACd,KAAF,CAAQd,MAAR,IAAkB,CAAlC,EAAqC,MAAO,8CAAD,GACtC,WAAU0C,CAAC,CAAC5B,KAAF,CAAQd,MAAO,EAD9B;;EAEA,IAAI,OAAO8F,IAAP,KAAgB,QAApB,EAA8B;IAC1BA,IAAI,GAAG,CAACA,IAAD,EAAOA,IAAP,CAAP;EACH;;EACD,IAAIlE,CAAC,CAACoE,KAAF,KAAY,WAAZ,IAA2BtD,CAAC,CAACsD,KAAF,KAAY,WAA3C,EAAwD;IACpD,MAAM,IAAI/G,mBAAJ,CAAwB,6DAAxB,CAAN;EACH;;EACD,MAAM4C,KAAK,GAAGD,CAAC,CAACd,KAAF,CAAQd,MAAtB;EACA,MAAM2C,KAAK,GAAGD,CAAC,CAAC5B,KAAF,CAAQd,MAAtB;;EACA,IAAI8F,IAAI,IAAI,IAAZ,EAAkB;IACd;IACAA,IAAI,GAAG,CAACjE,KAAK,GAAG,CAAT,EAAYc,KAAK,GAAG,CAApB,CAAP;EACH;;EACD,MAAMsD,SAAS,GAAGH,IAAlB;EACA,OAAOnH,GAAG,CAACE,IAAJ,CAAS,MAAM;IAClB,IAAIqH,IAAJ;;IACA,IAAIrE,KAAK,GAAGc,KAAZ,EAAmB;MACfuD,IAAI,GAAGrE,KAAK,GAAGc,KAAf;MACA,MAAMwD,SAAS,GAAG,EAAlB;;MACA,KAAK,IAAI/F,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG8F,IAApB,EAA0B,EAAE9F,CAA5B,EAA+B;QAC3B+F,SAAS,CAAC7F,IAAV,CAAe,CAAf;MACH;;MACDoC,CAAC,GAAG/D,GAAG,CAAC0D,OAAJ,CAAYK,CAAZ,EAAeA,CAAC,CAAC5B,KAAF,CAAQqB,MAAR,CAAegE,SAAf,CAAf,CAAJ;IACH,CAPD,MAQK,IAAIxD,KAAK,GAAGd,KAAZ,EAAmB;MACpBqE,IAAI,GAAGvD,KAAK,GAAGd,KAAf;MACA,MAAMsE,SAAS,GAAG,EAAlB;;MACA,KAAK,IAAI/F,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG8F,IAApB,EAA0B,EAAE9F,CAA5B,EAA+B;QAC3B+F,SAAS,CAAC7F,IAAV,CAAe,CAAf;MACH;;MACDsB,CAAC,GAAGjD,GAAG,CAAC0D,OAAJ,CAAYT,CAAZ,EAAeA,CAAC,CAACd,KAAF,CAAQqB,MAAR,CAAegE,SAAf,CAAf,CAAJ;IACH,CAPI,MAQA;MACDD,IAAI,GAAG,CAAP;IACH;;IACD,IAAIE,GAAJ;;IACA,IAAIxE,CAAC,CAACd,KAAF,CAAQd,MAAR,KAAmB,CAAnB,IAAwB0C,CAAC,CAAC5B,KAAF,CAAQd,MAAR,KAAmB,CAA/C,EAAkD;MAC9C,IAAIiG,SAAS,CAAC,CAAD,CAAT,KAAiBA,SAAS,CAAC,CAAD,CAA9B,EAAmC;QAC/BG,GAAG,GAAGzH,GAAG,CAAC0H,GAAJ,CAAQ1H,GAAG,CAACkF,GAAJ,CAAQjC,CAAR,EAAWc,CAAX,CAAR,EAAuBuD,SAAS,CAAC,CAAD,CAAhC,CAAN;MACH,CAFD,MAGK;QACDG,GAAG,GAAGzH,GAAG,CAAC0H,GAAJ,CAAQ1H,GAAG,CAACkF,GAAJ,CAAQlF,GAAG,CAAC4D,SAAJ,CAAcX,CAAd,EAAiB,CAAC,CAAD,EAAI,CAAJ,CAAjB,CAAR,EAAkCc,CAAlC,CAAR,EAA8CuD,SAAS,CAAC,CAAD,CAAvD,CAAN;MACH;IACJ,CAPD,MAQK;MACD,MAAMK,IAAI,GAAGL,SAAS,CAAC,CAAD,CAAT,KAAiBrE,CAAC,CAACd,KAAF,CAAQd,MAAR,GAAiB,CAA/C;MACA,MAAMuG,IAAI,GAAGN,SAAS,CAAC,CAAD,CAAT,KAAiBvD,CAAC,CAAC5B,KAAF,CAAQd,MAAR,GAAiB,CAA/C;MACAoG,GAAG,GAAGzH,GAAG,CAAC6H,MAAJ,CAAW5E,CAAX,EAAcc,CAAd,EAAiB4D,IAAjB,EAAuBC,IAAvB,CAAN;IACH;;IACD,IAAIL,IAAI,GAAG,CAAX,EAAc;MACV,IAAIO,GAAJ;;MACA,IAAI5E,KAAK,GAAGc,KAAZ,EAAmB;QACf8D,GAAG,GAAG5E,KAAK,GAAGc,KAAR,GAAgB,CAAtB;MACH,CAFD,MAGK;QACD8D,GAAG,GAAG5E,KAAK,GAAG,CAAd;MACH;;MACD,MAAM6E,WAAW,GAAG,EAApB;;MACA,KAAK,IAAItG,CAAC,GAAGqG,GAAb,EAAkBrG,CAAC,GAAGqG,GAAG,GAAGP,IAA5B,EAAkC,EAAE9F,CAApC,EAAuC;QACnCsG,WAAW,CAACpG,IAAZ,CAAiBF,CAAjB;MACH;;MACDgG,GAAG,GAAGzH,GAAG,CAACgI,OAAJ,CAAYP,GAAZ,EAAiBM,WAAjB,CAAN;IACH;;IACD,IAAIN,GAAG,CAACtF,KAAJ,CAAUd,MAAV,KAAqB,CAAzB,EAA4B;MACxBoG,GAAG,GAAGzH,GAAG,CAACmD,UAAJ,CAAesE,GAAf,EAAoB,CAApB,CAAN;IACH;;IACD,OAAOA,GAAP;EACH,CArDM,CAAP;AAsDH;;AACD,OAAO,MAAMQ,GAAN,SAAkBrH,KAAlB,CAAwB;EAC3BC,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAN;IACA,KAAKqG,IAAL,GAAYrG,IAAI,CAACqG,IAAjB;IACA,KAAKe,SAAL,GAAiBpH,IAAI,CAACoH,SAAL,IAAkB,IAAlB,GAAyB,KAAzB,GAAiCpH,IAAI,CAACoH,SAAvD;IACA,KAAKnH,eAAL,GAAuB,IAAvB;IACA,KAAKyB,eAAL,GAAuB,KAAvB;EACH;;EACDV,KAAK,CAACC,UAAD,EAAa;IACd/B,GAAG,CAACG,IAAJ,CAASiH,MAAT,CAAgBpF,KAAK,CAACC,OAAN,CAAcF,UAAd,KAA6BA,UAAU,CAACV,MAAX,KAAsB,CAAnD,IACZW,KAAK,CAACC,OAAN,CAAcF,UAAU,CAAC,CAAD,CAAxB,CADY,IACoBC,KAAK,CAACC,OAAN,CAAcF,UAAU,CAAC,CAAD,CAAxB,CADpC,EACkE,MAAM,+DADxE;IAEA,MAAMZ,MAAM,GAAGY,UAAU,CAAC,CAAD,CAAzB;IACA,MAAMX,MAAM,GAAGW,UAAU,CAAC,CAAD,CAAzB;;IACA,IAAIZ,MAAM,CAACE,MAAP,GAAgB,CAAhB,IAAqBD,MAAM,CAACC,MAAP,GAAgB,CAAzC,EAA4C;MACxC,MAAM,IAAIf,mBAAJ,CAAwB,8DAAxB,CAAN;IACH;;IACD,MAAM6G,IAAI,GAAG,KAAKgB,aAAL,CAAmBhH,MAAnB,EAA2BC,MAA3B,CAAb;;IACA,IAAID,MAAM,CAACgG,IAAI,CAAC,CAAD,CAAL,CAAN,KAAoB/F,MAAM,CAAC+F,IAAI,CAAC,CAAD,CAAL,CAA9B,EAAyC;MACrC,MAAM,IAAI5G,UAAJ,CAAgB,6BAAD,GAChB,GAAEY,MAAM,CAACgG,IAAI,CAAC,CAAD,CAAL,CAAU,QAAO/F,MAAM,CAAC+F,IAAI,CAAC,CAAD,CAAL,CAAU,EADxC,CAAN;IAEH;EACJ;;EACDnG,aAAa,CAACC,MAAD,EAAS;IAClB,IAAIA,MAAM,CAACI,MAAP,KAAkB,CAAtB,EAAyB;MACrB,MAAM,IAAId,UAAJ,CAAe,uDAChB,gBAAeU,MAAM,CAACI,MAAO,YAD5B,CAAN;IAEH;;IACD,IAAI+G,EAAE,GAAGnH,MAAM,CAAC,CAAD,CAAf;IACA,IAAIoH,EAAE,GAAGpH,MAAM,CAAC,CAAD,CAAf;IACA,IAAIkG,IAAJ;;IACA,IAAI,CAACnF,KAAK,CAACC,OAAN,CAAc,KAAKkF,IAAnB,CAAL,EAA+B;MAC3BA,IAAI,GAAG,CACHH,aAAa,CAAC,KAAKG,IAAN,EAAYiB,EAAE,CAACjG,KAAH,CAASd,MAArB,CADV,EAEH2F,aAAa,CAAC,KAAKG,IAAN,EAAYkB,EAAE,CAAClG,KAAH,CAASd,MAArB,CAFV,CAAP;IAIH,CALD,MAMK;MACD8F,IAAI,GAAG,KAAKA,IAAL,CAAU7E,GAAV,CAAc,CAACsD,IAAD,EAAOnE,CAAP,KAAauF,aAAa,CAACpB,IAAD,EAAO3E,MAAM,CAACQ,CAAD,CAAN,CAAUU,KAAV,CAAgBd,MAAvB,CAAxC,CAAP;IACH;;IACD,IAAI,KAAK6G,SAAT,EAAoB;MAChBE,EAAE,GAAG5H,WAAW,CAAC4H,EAAD,EAAKjB,IAAI,CAAC,CAAD,CAAT,CAAhB;MACAkB,EAAE,GAAG7H,WAAW,CAAC6H,EAAD,EAAKlB,IAAI,CAAC,CAAD,CAAT,CAAhB;IACH;;IACD,OAAOD,QAAQ,CAACkB,EAAD,EAAKC,EAAL,EAASlB,IAAT,CAAf;EACH;;EACDgB,aAAa,CAAChH,MAAD,EAASC,MAAT,EAAiB;IAC1B,IAAI+F,IAAJ;;IACA,IAAI,CAACnF,KAAK,CAACC,OAAN,CAAc,KAAKkF,IAAnB,CAAL,EAA+B;MAC3B;MACAA,IAAI,GAAG,CACHH,aAAa,CAAC,KAAKG,IAAN,EAAYhG,MAAM,CAACE,MAAnB,CADV,EAEH2F,aAAa,CAAC,KAAKG,IAAN,EAAY/F,MAAM,CAACC,MAAnB,CAFV,CAAP;IAIH,CAND,MAOK;MACD;MACA8F,IAAI,GAAG,KAAKA,IAAZ;IACH;;IACD,OAAOA,IAAP;EACH;;EACDjD,kBAAkB,CAACnC,UAAD,EAAa;IAC3B/B,GAAG,CAACG,IAAJ,CAASiH,MAAT,CAAgBpF,KAAK,CAACC,OAAN,CAAcF,UAAd,KAA6BA,UAAU,CAACV,MAAX,KAAsB,CAAnD,IACZW,KAAK,CAACC,OAAN,CAAcF,UAAU,CAAC,CAAD,CAAxB,CADY,IACoBC,KAAK,CAACC,OAAN,CAAcF,UAAU,CAAC,CAAD,CAAxB,CADpC,EACkE,MAAM,+DADxE;IAEA,MAAMZ,MAAM,GAAGY,UAAU,CAAC,CAAD,CAAV,CAAcR,KAAd,EAAf;IACA,MAAMH,MAAM,GAAGW,UAAU,CAAC,CAAD,CAAV,CAAcR,KAAd,EAAf;;IACA,IAAIJ,MAAM,CAACE,MAAP,GAAgB,CAAhB,IAAqBD,MAAM,CAACC,MAAP,GAAgB,CAAzC,EAA4C;MACxC,MAAM,IAAIf,mBAAJ,CAAwB,8DAAxB,CAAN;IACH;;IACD,MAAM6G,IAAI,GAAG,KAAKgB,aAAL,CAAmBhH,MAAnB,EAA2BC,MAA3B,CAAb;IACAD,MAAM,CAAC6E,MAAP,CAAcmB,IAAI,CAAC,CAAD,CAAlB,EAAuB,CAAvB;IACA/F,MAAM,CAAC4E,MAAP,CAAcmB,IAAI,CAAC,CAAD,CAAlB,EAAuB,CAAvB;IACA/F,MAAM,CAAC4E,MAAP,CAAc,CAAd,EAAiB,CAAjB;IACA,MAAM1E,WAAW,GAAGH,MAAM,CAACqC,MAAP,CAAcpC,MAAd,CAApB;;IACA,IAAIE,WAAW,CAACD,MAAZ,KAAuB,CAA3B,EAA8B;MAC1BC,WAAW,CAACK,IAAZ,CAAiB,CAAjB;IACH;;IACD,OAAOL,WAAP;EACH;;EACD6C,WAAW,CAAClD,MAAD,EAASmD,IAAT,EAAe;IACtB,OAAO,IAAP;EACH;;EACDwC,SAAS,GAAG;IACR,MAAM9B,MAAM,GAAG;MACX,QAAQ,KAAKqC,IADF;MAEX,aAAa,KAAKe;IAFP,CAAf;IAIA,MAAMrB,UAAU,GAAG,MAAMD,SAAN,EAAnB;IACAE,MAAM,CAACC,MAAP,CAAcjC,MAAd,EAAsB+B,UAAtB;IACA,OAAO/B,MAAP;EACH;;AAzF0B;AA2F/B;;AACAmD,GAAG,CAACrD,SAAJ,GAAgB,KAAhB;AACA3E,aAAa,CAAC4E,aAAd,CAA4BoD,GAA5B,E,CACA"},"metadata":{},"sourceType":"module"}