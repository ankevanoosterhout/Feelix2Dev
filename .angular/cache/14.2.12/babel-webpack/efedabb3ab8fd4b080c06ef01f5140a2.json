{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { variableGrads } from '@tensorflow/tfjs-core';\nimport { getNextUniqueTensorId } from './backend/state';\nimport { getScopedTensorName, getUniqueTensorName } from './common';\nimport { NotImplementedError } from './errors';\nconst DEFAULT_VARIABLE_NAME_PREFIX = 'Variable';\n/**\n * A `tf.layers.LayerVariable` is similar to a `tf.Tensor` in that it has a\n * dtype and shape, but its value is mutable.  The value is itself represented\n * as a`tf.Tensor`, and can be read with the `read()` method and updated with\n * the `write()` method.\n */\n\nexport class LayerVariable {\n  /**\n   * Construct Variable from a `tf.Tensor`.\n   *\n   * If not explicitly named, the Variable will be given a name with the\n   * prefix 'Variable'. Variable names are unique. In the case of name\n   * collision, suffixies '_<num>' will be added to the name.\n   *\n   * @param val Initial value of the Variable.\n   * @param name Name of the variable. If `null` or `undefined` is provided, it\n   *   will default a name with the prefix 'Variable'.\n   * @param constraint Optional, projection function to be applied to the\n   * variable after optimize updates\n   * @throws ValueError if `name` is `null` or `undefined`.\n   */\n  constructor(val, dtype = 'float32', name = DEFAULT_VARIABLE_NAME_PREFIX, trainable = true, constraint = null) {\n    this.dtype = dtype == null ? 'float32' : dtype;\n    this.shape = val.shape;\n    this.id = getNextUniqueTensorId();\n    name = name == null ? DEFAULT_VARIABLE_NAME_PREFIX : name;\n    this.originalName = getScopedTensorName(name);\n    this.name = getUniqueTensorName(this.originalName);\n    this.trainable_ = trainable;\n    this.constraint = constraint;\n    this.val = tfc.variable(val, this.trainable_, this.name, this.dtype);\n  }\n  /**\n   * Get a snapshot of the Variable's value.\n   *\n   * The returned value is a snapshot of the Variable's value at the time of\n   * the invocation. Future mutations in the value of the tensor will only\n   * be reflected by future calls to this method.\n   */\n\n\n  read() {\n    this.assertNotDisposed();\n    return this.val;\n  }\n  /**\n   * Update the value of the Variable.\n   *\n   * @param newVal: The new value to update to. Must be consistent with the\n   *   dtype and shape of the Variable.\n   * @return This Variable.\n   */\n\n\n  write(newVal) {\n    // TODO(cais): Once  TF.js Core supports Tensor.dtype, check dtype match.\n    this.assertNotDisposed();\n    checkShapesMatch(this.val, newVal); // Skip updating if this is the exact same tensor.\n\n    if (this.val.id !== newVal.id) {\n      this.val.assign(newVal);\n\n      if (this.constraint != null) {\n        this.val.assign(this.constraint.apply(this.val));\n      }\n    }\n\n    return this;\n  }\n  /**\n   * Dispose this LayersVariable instance from memory.\n   */\n\n\n  dispose() {\n    this.assertNotDisposed();\n    this.val.dispose();\n  }\n\n  assertNotDisposed() {\n    if (this.val.isDisposed) {\n      throw new Error(`LayersVariable ${this.name} is already disposed.`);\n    }\n  }\n\n  get trainable() {\n    return this.trainable_;\n  }\n\n  set trainable(trainable) {\n    this.trainable_ = trainable;\n    this.val.trainable = trainable;\n  }\n\n}\n\nfunction checkShapesMatch(x, y) {\n  if (x.shape.toString() !== y.shape.toString()) {\n    throw new Error('Shape mismatch: ' + JSON.stringify(x.shape) + ' vs. ' + JSON.stringify(y.shape));\n  }\n}\n/**\n * Create a Variable.\n * @param x The initial value of the `Variable`.\n * @param dtype optional, the type of the variable.\n * @param name optional, the name of the variable, default provided by\n * Variable.\n * @param constraint optional, a constraint to be applied after every update.\n * @return The newly instantiated `Variable`.\n */\n\n\nexport function variable(x, dtype, name, constraint) {\n  return new LayerVariable(x, dtype, name, true, constraint);\n}\n/**\n * Instantiates an all-zeros Variable and returns it.\n *\n * @param shape Shape of the tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return An all-zero Variable.\n */\n\nexport function zerosVariable(shape, dtype, name) {\n  // TODO(cais): Implement logic for dtype.\n  return new LayerVariable(tfc.zeros(shape), dtype, name);\n}\n/**\n * Instantiates an all-zeros tensor of the same shape as another tensor.\n *\n * @param x The other tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return A newly instantiated Variable.\n */\n\nexport function zerosLike(x, dtype, name) {\n  return new LayerVariable(tfc.zerosLike(x), dtype, name);\n}\n/**\n * Instantiates an all-ones tensor and returns it.\n *\n * @param shape Shape of the tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return An all-ones Variable.\n */\n\nexport function onesVariable(shape, dtype, name) {\n  // TODO(cais): Implement logic for dtype.\n  const allocated = tfc.ones(shape);\n  return new LayerVariable(allocated, dtype, name);\n}\n/**\n * Instantiates an all-ones tensor of the same shape as another tensor.\n *\n * @param x The other tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return A newly instantiated Variable.\n */\n\nexport function onesLike(x, dtype, name) {\n  const allocated = tfc.onesLike(x);\n  return new LayerVariable(allocated, dtype, name);\n}\n/**\n * Instantiate an identity matrix and returns it, as a Variable\n *\n * @param size Number of rows/columns.\n * @param dtype Data type of returned Variable.\n * @param name Name of returned Variable.\n * @return A Variable, an identity matrix.\n */\n\nexport function eyeVariable(size, dtype, name) {\n  return new LayerVariable(tfc.eye(size), dtype, name);\n}\n/**\n * Get a Variable with uniform distribution of values.\n * @param shape Shape of the tensor.\n * @param minval Lower bound of the uniform distribution.\n * @param maxval Upper bound of the uniform distribution.\n * @param dtype\n * @param seed\n * @param name Optional name.\n * @return The uniform-random Variable.\n */\n\nexport function randomUniformVariable(shape, minval, maxval, dtype, seed, name = 'randomUniform') {\n  return new LayerVariable(tfc.randomUniform(shape, minval, maxval, dtype), dtype, name);\n}\n/**\n * Get a Variable with truncated-normal distribution of values.\n * @param shape Shape of the tensor.\n * @param mean mean value of the normal distribution.\n * @param stddev standard deviation of the normal distribution.\n * @param dtype\n * @param seed\n * @param name Optional name.\n * @return The truncated-normal-random Variable.\n */\n\nexport function truncatedNormalVariable(shape, mean = 0.0, stddev = 1.0, dtype, seed, name = 'truncatedNormal') {\n  // TODO(cais): Implement logic for dtype and seed once they are supported\n  // by deeplearn.js.\n  dtype = dtype || 'float32';\n\n  if (dtype !== 'float32' && dtype !== 'int32') {\n    throw new NotImplementedError(`randomNormal does not support dType ${dtype}.`);\n  }\n\n  return new LayerVariable(tfc.truncatedNormal(shape, mean, stddev, dtype, seed), dtype, name);\n}\n/**\n * Get a Variable with normal distribution of values.\n * @param shape Shape of the tensor.\n * @param mean mean value of the normal distribution.\n * @param stddev standard deviation of the normal distribution.\n * @param dtype\n * @param seed\n * @param name Optional name.\n * @return The truncated-normal-random Variable.\n */\n\nexport function randomNormalVariable(shape, mean = 0.0, stddev = 1.0, dtype, seed, name = 'randomNormal') {\n  dtype = dtype || 'float32';\n\n  if (dtype !== 'float32' && dtype !== 'int32') {\n    throw new NotImplementedError(`randomNormalVariable does not support dType ${dtype}.`);\n  }\n\n  return new LayerVariable(tfc.randomNormal(shape, mean, stddev, dtype, seed), dtype, name);\n}\n/**\n * Update the value of a Variable.\n * @param x The Variable to be updated.\n * @param xNew The new value to update to.\n * @return The Variable updated.\n */\n\nexport function update(x, xNew) {\n  return x.write(xNew);\n}\n/**\n * Update the value of a Variable by adding an increment.\n * @param x The Variable to be updated.\n * @param increment The incrment to add to `x`.\n * @return The Variable updated.\n */\n\nexport function updateAdd(x, increment) {\n  return x.write(tfc.add(x.read(), increment));\n}\n/**\n * Update the value of a Variable by subtracting a decrement.\n * @param x The Variable to be updated.\n * @param decrement The decrement to subtract from `x`.\n * @return The Variable updated.\n */\n\nexport function updateSub(x, decrement) {\n  return x.write(tfc.sub(x.read(), decrement));\n}\n/**\n * Get the values of an array of Variables.\n *\n * @param tensors An `Array` of `Variable`s to get the values of.\n * @return The values of the inputs, as an `Array` of`tf.Tensor`s.\n */\n\nexport function batchGetValue(xs) {\n  return xs.map(x => x.read());\n}\n/**\n * Update the value of multiple Variables at once.\n *\n * @param variablesAndValues An `Array`, each element is of type\n *   [Variable, Tensor]. The first item is the\n *   `Variable` of which the value is to be updated. The second item\n *   carries the new value.\n */\n\nexport function batchSetValue(variablesAndValues) {\n  variablesAndValues.forEach(variableAndValue => {\n    const variable = variableAndValue[0];\n    variable.write(variableAndValue[1]);\n  });\n}\n/**\n * Returns the gradients of `variables` w.r.t. the return value of `lossFn`.\n * @param lossFn A function which returns a Scalar to be used as the function\n *   value (i.e., numerator) for differentiation.\n * @param variables List of variables to be used as the independent variables\n *   (i.e., denominator) for differentiation.\n * @returns An Array of gradients tensors.\n */\n\nexport function gradients(lossFn, variables) {\n  // TODO(cais): The return type signature can be simplified if deeplearn makes\n  //   the corresponding type public.\n  const variableList = variables.map(variable => variable.read());\n  const valudAndGrads = variableGrads(lossFn, variableList);\n  return variables.map(variable => valudAndGrads.grads[variable.name]);\n}","map":{"version":3,"names":["tfc","variableGrads","getNextUniqueTensorId","getScopedTensorName","getUniqueTensorName","NotImplementedError","DEFAULT_VARIABLE_NAME_PREFIX","LayerVariable","constructor","val","dtype","name","trainable","constraint","shape","id","originalName","trainable_","variable","read","assertNotDisposed","write","newVal","checkShapesMatch","assign","apply","dispose","isDisposed","Error","x","y","toString","JSON","stringify","zerosVariable","zeros","zerosLike","onesVariable","allocated","ones","onesLike","eyeVariable","size","eye","randomUniformVariable","minval","maxval","seed","randomUniform","truncatedNormalVariable","mean","stddev","truncatedNormal","randomNormalVariable","randomNormal","update","xNew","updateAdd","increment","add","updateSub","decrement","sub","batchGetValue","xs","map","batchSetValue","variablesAndValues","forEach","variableAndValue","gradients","lossFn","variables","variableList","valudAndGrads","grads"],"sources":["C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@tensorflow/tfjs-layers/dist/variables.js"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { variableGrads } from '@tensorflow/tfjs-core';\nimport { getNextUniqueTensorId } from './backend/state';\nimport { getScopedTensorName, getUniqueTensorName } from './common';\nimport { NotImplementedError } from './errors';\nconst DEFAULT_VARIABLE_NAME_PREFIX = 'Variable';\n/**\n * A `tf.layers.LayerVariable` is similar to a `tf.Tensor` in that it has a\n * dtype and shape, but its value is mutable.  The value is itself represented\n * as a`tf.Tensor`, and can be read with the `read()` method and updated with\n * the `write()` method.\n */\nexport class LayerVariable {\n    /**\n     * Construct Variable from a `tf.Tensor`.\n     *\n     * If not explicitly named, the Variable will be given a name with the\n     * prefix 'Variable'. Variable names are unique. In the case of name\n     * collision, suffixies '_<num>' will be added to the name.\n     *\n     * @param val Initial value of the Variable.\n     * @param name Name of the variable. If `null` or `undefined` is provided, it\n     *   will default a name with the prefix 'Variable'.\n     * @param constraint Optional, projection function to be applied to the\n     * variable after optimize updates\n     * @throws ValueError if `name` is `null` or `undefined`.\n     */\n    constructor(val, dtype = 'float32', name = DEFAULT_VARIABLE_NAME_PREFIX, trainable = true, constraint = null) {\n        this.dtype = dtype == null ? 'float32' : dtype;\n        this.shape = val.shape;\n        this.id = getNextUniqueTensorId();\n        name = name == null ? DEFAULT_VARIABLE_NAME_PREFIX : name;\n        this.originalName = getScopedTensorName(name);\n        this.name = getUniqueTensorName(this.originalName);\n        this.trainable_ = trainable;\n        this.constraint = constraint;\n        this.val = tfc.variable(val, this.trainable_, this.name, this.dtype);\n    }\n    /**\n     * Get a snapshot of the Variable's value.\n     *\n     * The returned value is a snapshot of the Variable's value at the time of\n     * the invocation. Future mutations in the value of the tensor will only\n     * be reflected by future calls to this method.\n     */\n    read() {\n        this.assertNotDisposed();\n        return this.val;\n    }\n    /**\n     * Update the value of the Variable.\n     *\n     * @param newVal: The new value to update to. Must be consistent with the\n     *   dtype and shape of the Variable.\n     * @return This Variable.\n     */\n    write(newVal) {\n        // TODO(cais): Once  TF.js Core supports Tensor.dtype, check dtype match.\n        this.assertNotDisposed();\n        checkShapesMatch(this.val, newVal);\n        // Skip updating if this is the exact same tensor.\n        if (this.val.id !== newVal.id) {\n            this.val.assign(newVal);\n            if (this.constraint != null) {\n                this.val.assign(this.constraint.apply(this.val));\n            }\n        }\n        return this;\n    }\n    /**\n     * Dispose this LayersVariable instance from memory.\n     */\n    dispose() {\n        this.assertNotDisposed();\n        this.val.dispose();\n    }\n    assertNotDisposed() {\n        if (this.val.isDisposed) {\n            throw new Error(`LayersVariable ${this.name} is already disposed.`);\n        }\n    }\n    get trainable() {\n        return this.trainable_;\n    }\n    set trainable(trainable) {\n        this.trainable_ = trainable;\n        this.val.trainable = trainable;\n    }\n}\nfunction checkShapesMatch(x, y) {\n    if (x.shape.toString() !== y.shape.toString()) {\n        throw new Error('Shape mismatch: ' + JSON.stringify(x.shape) + ' vs. ' +\n            JSON.stringify(y.shape));\n    }\n}\n/**\n * Create a Variable.\n * @param x The initial value of the `Variable`.\n * @param dtype optional, the type of the variable.\n * @param name optional, the name of the variable, default provided by\n * Variable.\n * @param constraint optional, a constraint to be applied after every update.\n * @return The newly instantiated `Variable`.\n */\nexport function variable(x, dtype, name, constraint) {\n    return new LayerVariable(x, dtype, name, true, constraint);\n}\n/**\n * Instantiates an all-zeros Variable and returns it.\n *\n * @param shape Shape of the tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return An all-zero Variable.\n */\nexport function zerosVariable(shape, dtype, name) {\n    // TODO(cais): Implement logic for dtype.\n    return new LayerVariable(tfc.zeros(shape), dtype, name);\n}\n/**\n * Instantiates an all-zeros tensor of the same shape as another tensor.\n *\n * @param x The other tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return A newly instantiated Variable.\n */\nexport function zerosLike(x, dtype, name) {\n    return new LayerVariable(tfc.zerosLike(x), dtype, name);\n}\n/**\n * Instantiates an all-ones tensor and returns it.\n *\n * @param shape Shape of the tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return An all-ones Variable.\n */\nexport function onesVariable(shape, dtype, name) {\n    // TODO(cais): Implement logic for dtype.\n    const allocated = tfc.ones(shape);\n    return new LayerVariable(allocated, dtype, name);\n}\n/**\n * Instantiates an all-ones tensor of the same shape as another tensor.\n *\n * @param x The other tensor.\n * @param dtype DType of the tensor.\n * @param name Name of the tensor.\n * @return A newly instantiated Variable.\n */\nexport function onesLike(x, dtype, name) {\n    const allocated = tfc.onesLike(x);\n    return new LayerVariable(allocated, dtype, name);\n}\n/**\n * Instantiate an identity matrix and returns it, as a Variable\n *\n * @param size Number of rows/columns.\n * @param dtype Data type of returned Variable.\n * @param name Name of returned Variable.\n * @return A Variable, an identity matrix.\n */\nexport function eyeVariable(size, dtype, name) {\n    return new LayerVariable(tfc.eye(size), dtype, name);\n}\n/**\n * Get a Variable with uniform distribution of values.\n * @param shape Shape of the tensor.\n * @param minval Lower bound of the uniform distribution.\n * @param maxval Upper bound of the uniform distribution.\n * @param dtype\n * @param seed\n * @param name Optional name.\n * @return The uniform-random Variable.\n */\nexport function randomUniformVariable(shape, minval, maxval, dtype, seed, name = 'randomUniform') {\n    return new LayerVariable(tfc.randomUniform(shape, minval, maxval, dtype), dtype, name);\n}\n/**\n * Get a Variable with truncated-normal distribution of values.\n * @param shape Shape of the tensor.\n * @param mean mean value of the normal distribution.\n * @param stddev standard deviation of the normal distribution.\n * @param dtype\n * @param seed\n * @param name Optional name.\n * @return The truncated-normal-random Variable.\n */\nexport function truncatedNormalVariable(shape, mean = 0.0, stddev = 1.0, dtype, seed, name = 'truncatedNormal') {\n    // TODO(cais): Implement logic for dtype and seed once they are supported\n    // by deeplearn.js.\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new NotImplementedError(`randomNormal does not support dType ${dtype}.`);\n    }\n    return new LayerVariable(tfc.truncatedNormal(shape, mean, stddev, dtype, seed), dtype, name);\n}\n/**\n * Get a Variable with normal distribution of values.\n * @param shape Shape of the tensor.\n * @param mean mean value of the normal distribution.\n * @param stddev standard deviation of the normal distribution.\n * @param dtype\n * @param seed\n * @param name Optional name.\n * @return The truncated-normal-random Variable.\n */\nexport function randomNormalVariable(shape, mean = 0.0, stddev = 1.0, dtype, seed, name = 'randomNormal') {\n    dtype = dtype || 'float32';\n    if (dtype !== 'float32' && dtype !== 'int32') {\n        throw new NotImplementedError(`randomNormalVariable does not support dType ${dtype}.`);\n    }\n    return new LayerVariable(tfc.randomNormal(shape, mean, stddev, dtype, seed), dtype, name);\n}\n/**\n * Update the value of a Variable.\n * @param x The Variable to be updated.\n * @param xNew The new value to update to.\n * @return The Variable updated.\n */\nexport function update(x, xNew) {\n    return x.write(xNew);\n}\n/**\n * Update the value of a Variable by adding an increment.\n * @param x The Variable to be updated.\n * @param increment The incrment to add to `x`.\n * @return The Variable updated.\n */\nexport function updateAdd(x, increment) {\n    return x.write(tfc.add(x.read(), increment));\n}\n/**\n * Update the value of a Variable by subtracting a decrement.\n * @param x The Variable to be updated.\n * @param decrement The decrement to subtract from `x`.\n * @return The Variable updated.\n */\nexport function updateSub(x, decrement) {\n    return x.write(tfc.sub(x.read(), decrement));\n}\n/**\n * Get the values of an array of Variables.\n *\n * @param tensors An `Array` of `Variable`s to get the values of.\n * @return The values of the inputs, as an `Array` of`tf.Tensor`s.\n */\nexport function batchGetValue(xs) {\n    return xs.map(x => x.read());\n}\n/**\n * Update the value of multiple Variables at once.\n *\n * @param variablesAndValues An `Array`, each element is of type\n *   [Variable, Tensor]. The first item is the\n *   `Variable` of which the value is to be updated. The second item\n *   carries the new value.\n */\nexport function batchSetValue(variablesAndValues) {\n    variablesAndValues.forEach(variableAndValue => {\n        const variable = variableAndValue[0];\n        variable.write(variableAndValue[1]);\n    });\n}\n/**\n * Returns the gradients of `variables` w.r.t. the return value of `lossFn`.\n * @param lossFn A function which returns a Scalar to be used as the function\n *   value (i.e., numerator) for differentiation.\n * @param variables List of variables to be used as the independent variables\n *   (i.e., denominator) for differentiation.\n * @returns An Array of gradients tensors.\n */\nexport function gradients(lossFn, variables) {\n    // TODO(cais): The return type signature can be simplified if deeplearn makes\n    //   the corresponding type public.\n    const variableList = variables.map(variable => variable.read());\n    const valudAndGrads = variableGrads(lossFn, variableList);\n    return variables.map(variable => valudAndGrads.grads[variable.name]);\n}\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,KAAKA,GAAZ,MAAqB,uBAArB;AACA,SAASC,aAAT,QAA8B,uBAA9B;AACA,SAASC,qBAAT,QAAsC,iBAAtC;AACA,SAASC,mBAAT,EAA8BC,mBAA9B,QAAyD,UAAzD;AACA,SAASC,mBAAT,QAAoC,UAApC;AACA,MAAMC,4BAA4B,GAAG,UAArC;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,MAAMC,aAAN,CAAoB;EACvB;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACIC,WAAW,CAACC,GAAD,EAAMC,KAAK,GAAG,SAAd,EAAyBC,IAAI,GAAGL,4BAAhC,EAA8DM,SAAS,GAAG,IAA1E,EAAgFC,UAAU,GAAG,IAA7F,EAAmG;IAC1G,KAAKH,KAAL,GAAaA,KAAK,IAAI,IAAT,GAAgB,SAAhB,GAA4BA,KAAzC;IACA,KAAKI,KAAL,GAAaL,GAAG,CAACK,KAAjB;IACA,KAAKC,EAAL,GAAUb,qBAAqB,EAA/B;IACAS,IAAI,GAAGA,IAAI,IAAI,IAAR,GAAeL,4BAAf,GAA8CK,IAArD;IACA,KAAKK,YAAL,GAAoBb,mBAAmB,CAACQ,IAAD,CAAvC;IACA,KAAKA,IAAL,GAAYP,mBAAmB,CAAC,KAAKY,YAAN,CAA/B;IACA,KAAKC,UAAL,GAAkBL,SAAlB;IACA,KAAKC,UAAL,GAAkBA,UAAlB;IACA,KAAKJ,GAAL,GAAWT,GAAG,CAACkB,QAAJ,CAAaT,GAAb,EAAkB,KAAKQ,UAAvB,EAAmC,KAAKN,IAAxC,EAA8C,KAAKD,KAAnD,CAAX;EACH;EACD;AACJ;AACA;AACA;AACA;AACA;AACA;;;EACIS,IAAI,GAAG;IACH,KAAKC,iBAAL;IACA,OAAO,KAAKX,GAAZ;EACH;EACD;AACJ;AACA;AACA;AACA;AACA;AACA;;;EACIY,KAAK,CAACC,MAAD,EAAS;IACV;IACA,KAAKF,iBAAL;IACAG,gBAAgB,CAAC,KAAKd,GAAN,EAAWa,MAAX,CAAhB,CAHU,CAIV;;IACA,IAAI,KAAKb,GAAL,CAASM,EAAT,KAAgBO,MAAM,CAACP,EAA3B,EAA+B;MAC3B,KAAKN,GAAL,CAASe,MAAT,CAAgBF,MAAhB;;MACA,IAAI,KAAKT,UAAL,IAAmB,IAAvB,EAA6B;QACzB,KAAKJ,GAAL,CAASe,MAAT,CAAgB,KAAKX,UAAL,CAAgBY,KAAhB,CAAsB,KAAKhB,GAA3B,CAAhB;MACH;IACJ;;IACD,OAAO,IAAP;EACH;EACD;AACJ;AACA;;;EACIiB,OAAO,GAAG;IACN,KAAKN,iBAAL;IACA,KAAKX,GAAL,CAASiB,OAAT;EACH;;EACDN,iBAAiB,GAAG;IAChB,IAAI,KAAKX,GAAL,CAASkB,UAAb,EAAyB;MACrB,MAAM,IAAIC,KAAJ,CAAW,kBAAiB,KAAKjB,IAAK,uBAAtC,CAAN;IACH;EACJ;;EACY,IAATC,SAAS,GAAG;IACZ,OAAO,KAAKK,UAAZ;EACH;;EACY,IAATL,SAAS,CAACA,SAAD,EAAY;IACrB,KAAKK,UAAL,GAAkBL,SAAlB;IACA,KAAKH,GAAL,CAASG,SAAT,GAAqBA,SAArB;EACH;;AA3EsB;;AA6E3B,SAASW,gBAAT,CAA0BM,CAA1B,EAA6BC,CAA7B,EAAgC;EAC5B,IAAID,CAAC,CAACf,KAAF,CAAQiB,QAAR,OAAuBD,CAAC,CAAChB,KAAF,CAAQiB,QAAR,EAA3B,EAA+C;IAC3C,MAAM,IAAIH,KAAJ,CAAU,qBAAqBI,IAAI,CAACC,SAAL,CAAeJ,CAAC,CAACf,KAAjB,CAArB,GAA+C,OAA/C,GACZkB,IAAI,CAACC,SAAL,CAAeH,CAAC,CAAChB,KAAjB,CADE,CAAN;EAEH;AACJ;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,OAAO,SAASI,QAAT,CAAkBW,CAAlB,EAAqBnB,KAArB,EAA4BC,IAA5B,EAAkCE,UAAlC,EAA8C;EACjD,OAAO,IAAIN,aAAJ,CAAkBsB,CAAlB,EAAqBnB,KAArB,EAA4BC,IAA5B,EAAkC,IAAlC,EAAwCE,UAAxC,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASqB,aAAT,CAAuBpB,KAAvB,EAA8BJ,KAA9B,EAAqCC,IAArC,EAA2C;EAC9C;EACA,OAAO,IAAIJ,aAAJ,CAAkBP,GAAG,CAACmC,KAAJ,CAAUrB,KAAV,CAAlB,EAAoCJ,KAApC,EAA2CC,IAA3C,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASyB,SAAT,CAAmBP,CAAnB,EAAsBnB,KAAtB,EAA6BC,IAA7B,EAAmC;EACtC,OAAO,IAAIJ,aAAJ,CAAkBP,GAAG,CAACoC,SAAJ,CAAcP,CAAd,CAAlB,EAAoCnB,KAApC,EAA2CC,IAA3C,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAAS0B,YAAT,CAAsBvB,KAAtB,EAA6BJ,KAA7B,EAAoCC,IAApC,EAA0C;EAC7C;EACA,MAAM2B,SAAS,GAAGtC,GAAG,CAACuC,IAAJ,CAASzB,KAAT,CAAlB;EACA,OAAO,IAAIP,aAAJ,CAAkB+B,SAAlB,EAA6B5B,KAA7B,EAAoCC,IAApC,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAAS6B,QAAT,CAAkBX,CAAlB,EAAqBnB,KAArB,EAA4BC,IAA5B,EAAkC;EACrC,MAAM2B,SAAS,GAAGtC,GAAG,CAACwC,QAAJ,CAAaX,CAAb,CAAlB;EACA,OAAO,IAAItB,aAAJ,CAAkB+B,SAAlB,EAA6B5B,KAA7B,EAAoCC,IAApC,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAAS8B,WAAT,CAAqBC,IAArB,EAA2BhC,KAA3B,EAAkCC,IAAlC,EAAwC;EAC3C,OAAO,IAAIJ,aAAJ,CAAkBP,GAAG,CAAC2C,GAAJ,CAAQD,IAAR,CAAlB,EAAiChC,KAAjC,EAAwCC,IAAxC,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASiC,qBAAT,CAA+B9B,KAA/B,EAAsC+B,MAAtC,EAA8CC,MAA9C,EAAsDpC,KAAtD,EAA6DqC,IAA7D,EAAmEpC,IAAI,GAAG,eAA1E,EAA2F;EAC9F,OAAO,IAAIJ,aAAJ,CAAkBP,GAAG,CAACgD,aAAJ,CAAkBlC,KAAlB,EAAyB+B,MAAzB,EAAiCC,MAAjC,EAAyCpC,KAAzC,CAAlB,EAAmEA,KAAnE,EAA0EC,IAA1E,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASsC,uBAAT,CAAiCnC,KAAjC,EAAwCoC,IAAI,GAAG,GAA/C,EAAoDC,MAAM,GAAG,GAA7D,EAAkEzC,KAAlE,EAAyEqC,IAAzE,EAA+EpC,IAAI,GAAG,iBAAtF,EAAyG;EAC5G;EACA;EACAD,KAAK,GAAGA,KAAK,IAAI,SAAjB;;EACA,IAAIA,KAAK,KAAK,SAAV,IAAuBA,KAAK,KAAK,OAArC,EAA8C;IAC1C,MAAM,IAAIL,mBAAJ,CAAyB,uCAAsCK,KAAM,GAArE,CAAN;EACH;;EACD,OAAO,IAAIH,aAAJ,CAAkBP,GAAG,CAACoD,eAAJ,CAAoBtC,KAApB,EAA2BoC,IAA3B,EAAiCC,MAAjC,EAAyCzC,KAAzC,EAAgDqC,IAAhD,CAAlB,EAAyErC,KAAzE,EAAgFC,IAAhF,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAAS0C,oBAAT,CAA8BvC,KAA9B,EAAqCoC,IAAI,GAAG,GAA5C,EAAiDC,MAAM,GAAG,GAA1D,EAA+DzC,KAA/D,EAAsEqC,IAAtE,EAA4EpC,IAAI,GAAG,cAAnF,EAAmG;EACtGD,KAAK,GAAGA,KAAK,IAAI,SAAjB;;EACA,IAAIA,KAAK,KAAK,SAAV,IAAuBA,KAAK,KAAK,OAArC,EAA8C;IAC1C,MAAM,IAAIL,mBAAJ,CAAyB,+CAA8CK,KAAM,GAA7E,CAAN;EACH;;EACD,OAAO,IAAIH,aAAJ,CAAkBP,GAAG,CAACsD,YAAJ,CAAiBxC,KAAjB,EAAwBoC,IAAxB,EAA8BC,MAA9B,EAAsCzC,KAAtC,EAA6CqC,IAA7C,CAAlB,EAAsErC,KAAtE,EAA6EC,IAA7E,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAAS4C,MAAT,CAAgB1B,CAAhB,EAAmB2B,IAAnB,EAAyB;EAC5B,OAAO3B,CAAC,CAACR,KAAF,CAAQmC,IAAR,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,SAAT,CAAmB5B,CAAnB,EAAsB6B,SAAtB,EAAiC;EACpC,OAAO7B,CAAC,CAACR,KAAF,CAAQrB,GAAG,CAAC2D,GAAJ,CAAQ9B,CAAC,CAACV,IAAF,EAAR,EAAkBuC,SAAlB,CAAR,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASE,SAAT,CAAmB/B,CAAnB,EAAsBgC,SAAtB,EAAiC;EACpC,OAAOhC,CAAC,CAACR,KAAF,CAAQrB,GAAG,CAAC8D,GAAJ,CAAQjC,CAAC,CAACV,IAAF,EAAR,EAAkB0C,SAAlB,CAAR,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASE,aAAT,CAAuBC,EAAvB,EAA2B;EAC9B,OAAOA,EAAE,CAACC,GAAH,CAAOpC,CAAC,IAAIA,CAAC,CAACV,IAAF,EAAZ,CAAP;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAAS+C,aAAT,CAAuBC,kBAAvB,EAA2C;EAC9CA,kBAAkB,CAACC,OAAnB,CAA2BC,gBAAgB,IAAI;IAC3C,MAAMnD,QAAQ,GAAGmD,gBAAgB,CAAC,CAAD,CAAjC;IACAnD,QAAQ,CAACG,KAAT,CAAegD,gBAAgB,CAAC,CAAD,CAA/B;EACH,CAHD;AAIH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,SAAT,CAAmBC,MAAnB,EAA2BC,SAA3B,EAAsC;EACzC;EACA;EACA,MAAMC,YAAY,GAAGD,SAAS,CAACP,GAAV,CAAc/C,QAAQ,IAAIA,QAAQ,CAACC,IAAT,EAA1B,CAArB;EACA,MAAMuD,aAAa,GAAGzE,aAAa,CAACsE,MAAD,EAASE,YAAT,CAAnC;EACA,OAAOD,SAAS,CAACP,GAAV,CAAc/C,QAAQ,IAAIwD,aAAa,CAACC,KAAd,CAAoBzD,QAAQ,CAACP,IAA7B,CAA1B,CAAP;AACH"},"metadata":{},"sourceType":"module"}