{"ast":null,"code":"import _asyncToGenerator from \"C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { keep, tidy } from '../globals';\nimport { add } from '../ops/add';\nimport { mul } from '../ops/mul';\nimport { scalar } from '../ops/scalar';\nimport { registerClass } from '../serialization';\nimport { Optimizer } from './optimizer';\n/** @doclink Optimizer */\n\nexport class SGDOptimizer extends Optimizer {\n  constructor(learningRate) {\n    super();\n    this.learningRate = learningRate;\n    this.setLearningRate(learningRate);\n  }\n\n  applyGradients(variableGradients) {\n    const varNames = Array.isArray(variableGradients) ? variableGradients.map(v => v.name) : Object.keys(variableGradients);\n    varNames.forEach((name, i) => {\n      const gradient = Array.isArray(variableGradients) ? variableGradients[i].tensor : variableGradients[name];\n\n      if (gradient == null) {\n        return;\n      }\n\n      const value = ENGINE.registeredVariables[name];\n      tidy(() => {\n        const newValue = add(mul(this.c, gradient), value);\n        value.assign(newValue);\n      });\n    });\n    this.incrementIterations();\n  }\n  /**\n   * Sets the learning rate of the optimizer.\n   */\n\n\n  setLearningRate(learningRate) {\n    this.learningRate = learningRate;\n\n    if (this.c != null) {\n      this.c.dispose();\n    }\n\n    this.c = keep(scalar(-learningRate));\n  }\n\n  dispose() {\n    this.c.dispose();\n  }\n\n  getWeights() {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      return [yield _this.saveIterations()];\n    })();\n  }\n\n  setWeights(weightValues) {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      weightValues = yield _this2.extractIterations(weightValues);\n\n      if (weightValues.length !== 0) {\n        throw new Error('SGD optimizer does not have settable weights.');\n      }\n    })();\n  }\n\n  getConfig() {\n    return {\n      'learningRate': this.learningRate\n    };\n  }\n  /** @nocollapse */\n\n\n  static fromConfig(cls, config) {\n    return new cls(config['learningRate']);\n  }\n\n}\n/** @nocollapse */\n\nSGDOptimizer.className = 'SGD'; // Note: Name matters for Python compatibility.\n\nregisterClass(SGDOptimizer);","map":{"version":3,"names":["ENGINE","keep","tidy","add","mul","scalar","registerClass","Optimizer","SGDOptimizer","constructor","learningRate","setLearningRate","applyGradients","variableGradients","varNames","Array","isArray","map","v","name","Object","keys","forEach","i","gradient","tensor","value","registeredVariables","newValue","c","assign","incrementIterations","dispose","getWeights","saveIterations","setWeights","weightValues","extractIterations","length","Error","getConfig","fromConfig","cls","config","className"],"sources":["C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@tensorflow/tfjs-core/dist/optimizers/sgd_optimizer.js"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { keep, tidy } from '../globals';\nimport { add } from '../ops/add';\nimport { mul } from '../ops/mul';\nimport { scalar } from '../ops/scalar';\nimport { registerClass } from '../serialization';\nimport { Optimizer } from './optimizer';\n/** @doclink Optimizer */\nexport class SGDOptimizer extends Optimizer {\n    constructor(learningRate) {\n        super();\n        this.learningRate = learningRate;\n        this.setLearningRate(learningRate);\n    }\n    applyGradients(variableGradients) {\n        const varNames = Array.isArray(variableGradients) ?\n            variableGradients.map(v => v.name) :\n            Object.keys(variableGradients);\n        varNames.forEach((name, i) => {\n            const gradient = Array.isArray(variableGradients) ?\n                variableGradients[i].tensor :\n                variableGradients[name];\n            if (gradient == null) {\n                return;\n            }\n            const value = ENGINE.registeredVariables[name];\n            tidy(() => {\n                const newValue = add(mul(this.c, gradient), value);\n                value.assign(newValue);\n            });\n        });\n        this.incrementIterations();\n    }\n    /**\n     * Sets the learning rate of the optimizer.\n     */\n    setLearningRate(learningRate) {\n        this.learningRate = learningRate;\n        if (this.c != null) {\n            this.c.dispose();\n        }\n        this.c = keep(scalar(-learningRate));\n    }\n    dispose() {\n        this.c.dispose();\n    }\n    async getWeights() {\n        return [await this.saveIterations()];\n    }\n    async setWeights(weightValues) {\n        weightValues = await this.extractIterations(weightValues);\n        if (weightValues.length !== 0) {\n            throw new Error('SGD optimizer does not have settable weights.');\n        }\n    }\n    getConfig() {\n        return { 'learningRate': this.learningRate };\n    }\n    /** @nocollapse */\n    static fromConfig(cls, config) {\n        return new cls(config['learningRate']);\n    }\n}\n/** @nocollapse */\nSGDOptimizer.className = 'SGD'; // Note: Name matters for Python compatibility.\nregisterClass(SGDOptimizer);\n"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,MAAT,QAAuB,WAAvB;AACA,SAASC,IAAT,EAAeC,IAAf,QAA2B,YAA3B;AACA,SAASC,GAAT,QAAoB,YAApB;AACA,SAASC,GAAT,QAAoB,YAApB;AACA,SAASC,MAAT,QAAuB,eAAvB;AACA,SAASC,aAAT,QAA8B,kBAA9B;AACA,SAASC,SAAT,QAA0B,aAA1B;AACA;;AACA,OAAO,MAAMC,YAAN,SAA2BD,SAA3B,CAAqC;EACxCE,WAAW,CAACC,YAAD,EAAe;IACtB;IACA,KAAKA,YAAL,GAAoBA,YAApB;IACA,KAAKC,eAAL,CAAqBD,YAArB;EACH;;EACDE,cAAc,CAACC,iBAAD,EAAoB;IAC9B,MAAMC,QAAQ,GAAGC,KAAK,CAACC,OAAN,CAAcH,iBAAd,IACbA,iBAAiB,CAACI,GAAlB,CAAsBC,CAAC,IAAIA,CAAC,CAACC,IAA7B,CADa,GAEbC,MAAM,CAACC,IAAP,CAAYR,iBAAZ,CAFJ;IAGAC,QAAQ,CAACQ,OAAT,CAAiB,CAACH,IAAD,EAAOI,CAAP,KAAa;MAC1B,MAAMC,QAAQ,GAAGT,KAAK,CAACC,OAAN,CAAcH,iBAAd,IACbA,iBAAiB,CAACU,CAAD,CAAjB,CAAqBE,MADR,GAEbZ,iBAAiB,CAACM,IAAD,CAFrB;;MAGA,IAAIK,QAAQ,IAAI,IAAhB,EAAsB;QAClB;MACH;;MACD,MAAME,KAAK,GAAG1B,MAAM,CAAC2B,mBAAP,CAA2BR,IAA3B,CAAd;MACAjB,IAAI,CAAC,MAAM;QACP,MAAM0B,QAAQ,GAAGzB,GAAG,CAACC,GAAG,CAAC,KAAKyB,CAAN,EAASL,QAAT,CAAJ,EAAwBE,KAAxB,CAApB;QACAA,KAAK,CAACI,MAAN,CAAaF,QAAb;MACH,CAHG,CAAJ;IAIH,CAZD;IAaA,KAAKG,mBAAL;EACH;EACD;AACJ;AACA;;;EACIpB,eAAe,CAACD,YAAD,EAAe;IAC1B,KAAKA,YAAL,GAAoBA,YAApB;;IACA,IAAI,KAAKmB,CAAL,IAAU,IAAd,EAAoB;MAChB,KAAKA,CAAL,CAAOG,OAAP;IACH;;IACD,KAAKH,CAAL,GAAS5B,IAAI,CAACI,MAAM,CAAC,CAACK,YAAF,CAAP,CAAb;EACH;;EACDsB,OAAO,GAAG;IACN,KAAKH,CAAL,CAAOG,OAAP;EACH;;EACKC,UAAU,GAAG;IAAA;;IAAA;MACf,OAAO,OAAO,KAAI,CAACC,cAAL,EAAP,CAAP;IADe;EAElB;;EACKC,UAAU,CAACC,YAAD,EAAe;IAAA;;IAAA;MAC3BA,YAAY,SAAS,MAAI,CAACC,iBAAL,CAAuBD,YAAvB,CAArB;;MACA,IAAIA,YAAY,CAACE,MAAb,KAAwB,CAA5B,EAA+B;QAC3B,MAAM,IAAIC,KAAJ,CAAU,+CAAV,CAAN;MACH;IAJ0B;EAK9B;;EACDC,SAAS,GAAG;IACR,OAAO;MAAE,gBAAgB,KAAK9B;IAAvB,CAAP;EACH;EACD;;;EACiB,OAAV+B,UAAU,CAACC,GAAD,EAAMC,MAAN,EAAc;IAC3B,OAAO,IAAID,GAAJ,CAAQC,MAAM,CAAC,cAAD,CAAd,CAAP;EACH;;AArDuC;AAuD5C;;AACAnC,YAAY,CAACoC,SAAb,GAAyB,KAAzB,C,CAAgC;;AAChCtC,aAAa,CAACE,YAAD,CAAb"},"metadata":{},"sourceType":"module"}