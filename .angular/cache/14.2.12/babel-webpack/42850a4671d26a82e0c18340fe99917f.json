{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Basic Layers.\n */\nimport { any, cast, mul, notEqual, reshape, serialization, tidy, transpose, util } from '@tensorflow/tfjs-core';\nimport { getActivation, serializeActivation } from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { InputSpec, Layer } from '../engine/topology';\nimport { ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport { assertPositiveInteger, mapActivationToFusedKernel } from '../utils/generic_utils';\nimport { arrayProd, range } from '../utils/math_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nexport class Dropout extends Layer {\n  constructor(args) {\n    super(args);\n    this.rate = Math.max(Math.min(args.rate, 1), 0); // So that the scalar doesn't get tidied up between executions.\n\n    this.noiseShape = args.noiseShape;\n    this.seed = args.seed;\n    this.supportsMasking = true;\n  }\n\n  getNoiseShape(input) {\n    if (this.noiseShape == null) {\n      return this.noiseShape;\n    }\n\n    const inputShape = input.shape;\n    const noiseShape = [];\n\n    for (let i = 0; i < this.noiseShape.length; ++i) {\n      noiseShape.push(this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);\n    }\n\n    return noiseShape;\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n\n      if (0 < this.rate && this.rate < 1) {\n        const training = kwargs['training'] == null ? false : kwargs['training'];\n        const noiseShape = this.getNoiseShape(input);\n        const output = K.inTrainPhase(() => K.dropout(input, this.rate, noiseShape, this.seed), () => input, training);\n        return output;\n      }\n\n      return inputs;\n    });\n  }\n\n  getConfig() {\n    const config = {\n      rate: this.rate,\n      noiseShape: this.noiseShape,\n      seed: this.seed\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  dispose() {\n    return super.dispose();\n  }\n\n}\n/** @nocollapse */\n\nDropout.className = 'Dropout';\nserialization.registerClass(Dropout);\nexport class SpatialDropout1D extends Dropout {\n  constructor(args) {\n    super(args);\n    this.inputSpec = [{\n      ndim: 3\n    }];\n  }\n\n  getNoiseShape(input) {\n    const inputShape = input.shape;\n    return [inputShape[0], 1, inputShape[2]];\n  }\n\n}\n/** @nocollapse */\n\nSpatialDropout1D.className = 'SpatialDropout1D';\nserialization.registerClass(SpatialDropout1D);\nexport class Dense extends Layer {\n  constructor(args) {\n    super(args); // Default activation: Linear (none).\n\n    this.activation = null;\n    this.useBias = true;\n    this.kernel = null;\n    this.bias = null;\n    this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n    this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n\n    if (args.batchInputShape == null && args.inputShape == null && args.inputDim != null) {\n      // This logic is copied from Layer's constructor, since we can't\n      // do exactly what the Python constructor does for Dense().\n      let batchSize = null;\n\n      if (args.batchSize != null) {\n        batchSize = args.batchSize;\n      }\n\n      this.batchInputShape = [batchSize, args.inputDim];\n    }\n\n    this.units = args.units;\n    assertPositiveInteger(this.units, 'units');\n    this.activation = getActivation(args.activation);\n\n    if (args.useBias != null) {\n      this.useBias = args.useBias;\n    }\n\n    this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n    this.biasInitializer = getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n    this.kernelConstraint = getConstraint(args.kernelConstraint);\n    this.biasConstraint = getConstraint(args.biasConstraint);\n    this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    this.biasRegularizer = getRegularizer(args.biasRegularizer);\n    this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    this.supportsMasking = true;\n    this.inputSpec = [{\n      minNDim: 2\n    }];\n  }\n\n  build(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n    const inputLastDim = inputShape[inputShape.length - 1];\n\n    if (this.kernel == null) {\n      this.kernel = this.addWeight('kernel', [inputLastDim, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n\n      if (this.useBias) {\n        this.bias = this.addWeight('bias', [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n      }\n    }\n\n    this.inputSpec = [{\n      minNDim: 2,\n      axes: {\n        [-1]: inputLastDim\n      }\n    }];\n    this.built = true;\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    outputShape[outputShape.length - 1] = this.units;\n    return outputShape;\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs); // Dense layer accepts only a single input.\n\n      const input = getExactlyOneTensor(inputs);\n      const fusedActivationName = mapActivationToFusedKernel(this.activation.getClassName());\n      let output;\n\n      if (fusedActivationName != null) {\n        output = K.dot(input, this.kernel.read(), fusedActivationName, this.bias ? this.bias.read() : null);\n      } else {\n        output = K.dot(input, this.kernel.read());\n\n        if (this.bias != null) {\n          output = K.biasAdd(output, this.bias.read());\n        }\n\n        if (this.activation != null) {\n          output = this.activation.apply(output);\n        }\n      }\n\n      return output;\n    });\n  }\n\n  getConfig() {\n    const config = {\n      units: this.units,\n      activation: serializeActivation(this.activation),\n      useBias: this.useBias,\n      kernelInitializer: serializeInitializer(this.kernelInitializer),\n      biasInitializer: serializeInitializer(this.biasInitializer),\n      kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n      biasRegularizer: serializeRegularizer(this.biasRegularizer),\n      activityRegularizer: serializeRegularizer(this.activityRegularizer),\n      kernelConstraint: serializeConstraint(this.kernelConstraint),\n      biasConstraint: serializeConstraint(this.biasConstraint)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nDense.className = 'Dense';\nserialization.registerClass(Dense);\nexport class Flatten extends Layer {\n  constructor(args) {\n    args = args || {};\n    super(args);\n    this.inputSpec = [{\n      minNDim: 3\n    }];\n    this.dataFormat = args.dataFormat;\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n\n    for (const dim of inputShape.slice(1)) {\n      if (dim == null) {\n        throw new ValueError(`The shape of the input to \"Flatten\" is not fully defined ` + `(got ${inputShape.slice(1)}). Make sure to pass a complete ` + `\"input_shape\" or \"batch_input_shape\" argument to the first ` + `layer in your model.`);\n      }\n    }\n\n    return [inputShape[0], arrayProd(inputShape, 1)];\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      let input = getExactlyOneTensor(inputs);\n\n      if (this.dataFormat === 'channelsFirst' && input.rank > 1) {\n        const permutation = [0];\n\n        for (let i = 2; i < input.rank; ++i) {\n          permutation.push(i);\n        }\n\n        permutation.push(1);\n        input = transpose(input, permutation);\n      }\n\n      return K.batchFlatten(input);\n    });\n  }\n\n  getConfig() {\n    const config = {};\n\n    if (this.dataFormat != null) {\n      config['dataFormat'] = this.dataFormat;\n    }\n\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nFlatten.className = 'Flatten';\nserialization.registerClass(Flatten);\nexport class Activation extends Layer {\n  constructor(args) {\n    super(args);\n    this.supportsMasking = true;\n    this.activation = getActivation(args.activation);\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      return this.activation.apply(input);\n    });\n  }\n\n  getConfig() {\n    const config = {\n      activation: serializeActivation(this.activation)\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nActivation.className = 'Activation';\nserialization.registerClass(Activation);\nexport class RepeatVector extends Layer {\n  constructor(args) {\n    super(args);\n    this.n = args.n;\n    this.inputSpec = [{\n      ndim: 2\n    }];\n  }\n\n  computeOutputShape(inputShape) {\n    return [inputShape[0], this.n, inputShape[1]];\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      inputs = getExactlyOneTensor(inputs);\n      return K.repeat(inputs, this.n);\n    });\n  }\n\n  getConfig() {\n    const config = {\n      n: this.n\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nRepeatVector.className = 'RepeatVector';\nserialization.registerClass(RepeatVector);\nexport class Reshape extends Layer {\n  constructor(args) {\n    super(args);\n    this.targetShape = args.targetShape; // Make sure that all unknown dimensions are represented as `null`.\n\n    for (let i = 0; i < this.targetShape.length; ++i) {\n      if (this.isUnknown(this.targetShape[i])) {\n        this.targetShape[i] = null;\n      }\n    }\n  }\n\n  isUnknown(dim) {\n    return dim < 0 || dim == null;\n  }\n  /**\n   * Finds and replaces a missing dimension in output shape.\n   *\n   * This is a near direct port of the internal Numpy function\n   * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.\n   *\n   * @param inputShape: Original shape of array begin reshape.\n   * @param outputShape: Target shape of the array, with at most a single\n   * `null` or negative number, which indicates an underdetermined dimension\n   * that should be derived from `inputShape` and the known dimensions of\n   *   `outputShape`.\n   * @returns: The output shape with `null` replaced with its computed value.\n   * @throws: ValueError: If `inputShape` and `outputShape` do not match.\n   */\n\n\n  fixUnknownDimension(inputShape, outputShape) {\n    const errorMsg = 'Total size of new array must be unchanged.';\n    const finalShape = outputShape.slice();\n    let known = 1;\n    let unknown = null;\n\n    for (let i = 0; i < finalShape.length; ++i) {\n      const dim = finalShape[i];\n\n      if (this.isUnknown(dim)) {\n        if (unknown === null) {\n          unknown = i;\n        } else {\n          throw new ValueError('Can only specifiy one unknown dimension.');\n        }\n      } else {\n        known *= dim;\n      }\n    }\n\n    const originalSize = arrayProd(inputShape);\n\n    if (unknown !== null) {\n      if (known === 0 || originalSize % known !== 0) {\n        throw new ValueError(errorMsg);\n      }\n\n      finalShape[unknown] = originalSize / known;\n    } else if (originalSize !== known) {\n      throw new ValueError(errorMsg);\n    }\n\n    return finalShape;\n  }\n\n  computeOutputShape(inputShape) {\n    let anyUnknownDims = false;\n\n    for (let i = 0; i < inputShape.length; ++i) {\n      if (this.isUnknown(inputShape[i])) {\n        anyUnknownDims = true;\n        break;\n      }\n    }\n\n    if (anyUnknownDims) {\n      return inputShape.slice(0, 1).concat(this.targetShape);\n    } else {\n      return inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n    }\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const inputShape = input.shape;\n      const outputShape = inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n      return reshape(input, outputShape);\n    });\n  }\n\n  getConfig() {\n    const config = {\n      targetShape: this.targetShape\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nReshape.className = 'Reshape';\nserialization.registerClass(Reshape);\nexport class Permute extends Layer {\n  constructor(args) {\n    super(args);\n\n    if (args.dims == null) {\n      throw new Error('Required configuration field `dims` is missing during Permute ' + 'constructor call.');\n    }\n\n    if (!Array.isArray(args.dims)) {\n      throw new Error('Permute constructor requires `dims` to be an Array, but received ' + `${args.dims} instead.`);\n    } // Check the validity of the permutation indices.\n\n\n    const expectedSortedIndices = range(1, args.dims.length + 1);\n\n    if (!util.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {\n      throw new Error('Invalid permutation `dims`: ' + JSON.stringify(args.dims) + ' `dims` must contain consecutive integers starting from 1.');\n    }\n\n    this.dims = args.dims;\n    this.dimsIncludingBatch = [0].concat(this.dims);\n    this.inputSpec = [new InputSpec({\n      ndim: this.dims.length + 1\n    })];\n  }\n\n  computeOutputShape(inputShape) {\n    inputShape = getExactlyOneShape(inputShape);\n    const outputShape = inputShape.slice();\n    this.dims.forEach((dim, i) => {\n      outputShape[i + 1] = inputShape[dim];\n    });\n    return outputShape;\n  }\n\n  call(inputs, kwargs) {\n    return transpose(getExactlyOneTensor(inputs), this.dimsIncludingBatch);\n  }\n\n  getConfig() {\n    const config = {\n      dims: this.dims\n    };\n    const baseConfig = super.getConfig();\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n}\n/** @nocollapse */\n\nPermute.className = 'Permute';\nserialization.registerClass(Permute);\nexport class Masking extends Layer {\n  constructor(args) {\n    super(args == null ? {} : args);\n    this.supportsMasking = true;\n\n    if (args != null) {\n      this.maskValue = args.maskValue == null ? 0 : args.maskValue;\n    } else {\n      this.maskValue = 0;\n    }\n  }\n\n  computeOutputShape(inputShape) {\n    return inputShape;\n  }\n\n  getConfig() {\n    const baseConfig = super.getConfig();\n    const config = {\n      maskValue: this.maskValue\n    };\n    Object.assign(config, baseConfig);\n    return config;\n  }\n\n  computeMask(inputs, mask) {\n    const input = getExactlyOneTensor(inputs);\n    const axis = -1;\n    return any(notEqual(input, this.maskValue), axis);\n  }\n\n  call(inputs, kwargs) {\n    return tidy(() => {\n      this.invokeCallHook(inputs, kwargs);\n      const input = getExactlyOneTensor(inputs);\n      const axis = -1;\n      const keepDims = true;\n      const booleanMask = any(notEqual(input, this.maskValue), axis, keepDims);\n      const output = mul(input, cast(booleanMask, input.dtype));\n      return output;\n    });\n  }\n\n}\n/** @nocollapse */\n\nMasking.className = 'Masking';\nserialization.registerClass(Masking);","map":{"version":3,"names":["any","cast","mul","notEqual","reshape","serialization","tidy","transpose","util","getActivation","serializeActivation","K","getConstraint","serializeConstraint","InputSpec","Layer","ValueError","getInitializer","serializeInitializer","getRegularizer","serializeRegularizer","assertPositiveInteger","mapActivationToFusedKernel","arrayProd","range","getExactlyOneShape","getExactlyOneTensor","Dropout","constructor","args","rate","Math","max","min","noiseShape","seed","supportsMasking","getNoiseShape","input","inputShape","shape","i","length","push","call","inputs","kwargs","invokeCallHook","training","output","inTrainPhase","dropout","getConfig","config","baseConfig","Object","assign","dispose","className","registerClass","SpatialDropout1D","inputSpec","ndim","Dense","activation","useBias","kernel","bias","DEFAULT_KERNEL_INITIALIZER","DEFAULT_BIAS_INITIALIZER","batchInputShape","inputDim","batchSize","units","kernelInitializer","biasInitializer","kernelConstraint","biasConstraint","kernelRegularizer","biasRegularizer","activityRegularizer","minNDim","build","inputLastDim","addWeight","axes","built","computeOutputShape","outputShape","slice","fusedActivationName","getClassName","dot","read","biasAdd","apply","Flatten","dataFormat","dim","rank","permutation","batchFlatten","Activation","RepeatVector","n","repeat","Reshape","targetShape","isUnknown","fixUnknownDimension","errorMsg","finalShape","known","unknown","originalSize","anyUnknownDims","concat","Permute","dims","Error","Array","isArray","expectedSortedIndices","arraysEqual","sort","JSON","stringify","dimsIncludingBatch","forEach","Masking","maskValue","computeMask","mask","axis","keepDims","booleanMask","dtype"],"sources":["C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@tensorflow/tfjs-layers/dist/layers/core.js"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n/**\n * TensorFlow.js Layers: Basic Layers.\n */\nimport { any, cast, mul, notEqual, reshape, serialization, tidy, transpose, util } from '@tensorflow/tfjs-core';\nimport { getActivation, serializeActivation } from '../activations';\nimport * as K from '../backend/tfjs_backend';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { InputSpec, Layer } from '../engine/topology';\nimport { ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport { assertPositiveInteger, mapActivationToFusedKernel } from '../utils/generic_utils';\nimport { arrayProd, range } from '../utils/math_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\nexport class Dropout extends Layer {\n    constructor(args) {\n        super(args);\n        this.rate = Math.max(Math.min(args.rate, 1), 0);\n        // So that the scalar doesn't get tidied up between executions.\n        this.noiseShape = args.noiseShape;\n        this.seed = args.seed;\n        this.supportsMasking = true;\n    }\n    getNoiseShape(input) {\n        if (this.noiseShape == null) {\n            return this.noiseShape;\n        }\n        const inputShape = input.shape;\n        const noiseShape = [];\n        for (let i = 0; i < this.noiseShape.length; ++i) {\n            noiseShape.push(this.noiseShape[i] == null ? inputShape[i] : this.noiseShape[i]);\n        }\n        return noiseShape;\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            const input = getExactlyOneTensor(inputs);\n            if (0 < this.rate && this.rate < 1) {\n                const training = kwargs['training'] == null ? false : kwargs['training'];\n                const noiseShape = this.getNoiseShape(input);\n                const output = K.inTrainPhase(() => K.dropout(input, this.rate, noiseShape, this.seed), () => input, training);\n                return output;\n            }\n            return inputs;\n        });\n    }\n    getConfig() {\n        const config = {\n            rate: this.rate,\n            noiseShape: this.noiseShape,\n            seed: this.seed,\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n    dispose() {\n        return super.dispose();\n    }\n}\n/** @nocollapse */\nDropout.className = 'Dropout';\nserialization.registerClass(Dropout);\nexport class SpatialDropout1D extends Dropout {\n    constructor(args) {\n        super(args);\n        this.inputSpec = [{ ndim: 3 }];\n    }\n    getNoiseShape(input) {\n        const inputShape = input.shape;\n        return [inputShape[0], 1, inputShape[2]];\n    }\n}\n/** @nocollapse */\nSpatialDropout1D.className = 'SpatialDropout1D';\nserialization.registerClass(SpatialDropout1D);\nexport class Dense extends Layer {\n    constructor(args) {\n        super(args);\n        // Default activation: Linear (none).\n        this.activation = null;\n        this.useBias = true;\n        this.kernel = null;\n        this.bias = null;\n        this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n        this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n        if (args.batchInputShape == null && args.inputShape == null &&\n            args.inputDim != null) {\n            // This logic is copied from Layer's constructor, since we can't\n            // do exactly what the Python constructor does for Dense().\n            let batchSize = null;\n            if (args.batchSize != null) {\n                batchSize = args.batchSize;\n            }\n            this.batchInputShape = [batchSize, args.inputDim];\n        }\n        this.units = args.units;\n        assertPositiveInteger(this.units, 'units');\n        this.activation = getActivation(args.activation);\n        if (args.useBias != null) {\n            this.useBias = args.useBias;\n        }\n        this.kernelInitializer = getInitializer(args.kernelInitializer || this.DEFAULT_KERNEL_INITIALIZER);\n        this.biasInitializer =\n            getInitializer(args.biasInitializer || this.DEFAULT_BIAS_INITIALIZER);\n        this.kernelConstraint = getConstraint(args.kernelConstraint);\n        this.biasConstraint = getConstraint(args.biasConstraint);\n        this.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n        this.biasRegularizer = getRegularizer(args.biasRegularizer);\n        this.activityRegularizer = getRegularizer(args.activityRegularizer);\n        this.supportsMasking = true;\n        this.inputSpec = [{ minNDim: 2 }];\n    }\n    build(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const inputLastDim = inputShape[inputShape.length - 1];\n        if (this.kernel == null) {\n            this.kernel = this.addWeight('kernel', [inputLastDim, this.units], null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n            if (this.useBias) {\n                this.bias = this.addWeight('bias', [this.units], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n            }\n        }\n        this.inputSpec = [{ minNDim: 2, axes: { [-1]: inputLastDim } }];\n        this.built = true;\n    }\n    computeOutputShape(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const outputShape = inputShape.slice();\n        outputShape[outputShape.length - 1] = this.units;\n        return outputShape;\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            // Dense layer accepts only a single input.\n            const input = getExactlyOneTensor(inputs);\n            const fusedActivationName = mapActivationToFusedKernel(this.activation.getClassName());\n            let output;\n            if (fusedActivationName != null) {\n                output = K.dot(input, this.kernel.read(), fusedActivationName, this.bias ? this.bias.read() : null);\n            }\n            else {\n                output = K.dot(input, this.kernel.read());\n                if (this.bias != null) {\n                    output = K.biasAdd(output, this.bias.read());\n                }\n                if (this.activation != null) {\n                    output = this.activation.apply(output);\n                }\n            }\n            return output;\n        });\n    }\n    getConfig() {\n        const config = {\n            units: this.units,\n            activation: serializeActivation(this.activation),\n            useBias: this.useBias,\n            kernelInitializer: serializeInitializer(this.kernelInitializer),\n            biasInitializer: serializeInitializer(this.biasInitializer),\n            kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n            biasRegularizer: serializeRegularizer(this.biasRegularizer),\n            activityRegularizer: serializeRegularizer(this.activityRegularizer),\n            kernelConstraint: serializeConstraint(this.kernelConstraint),\n            biasConstraint: serializeConstraint(this.biasConstraint)\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nDense.className = 'Dense';\nserialization.registerClass(Dense);\nexport class Flatten extends Layer {\n    constructor(args) {\n        args = args || {};\n        super(args);\n        this.inputSpec = [{ minNDim: 3 }];\n        this.dataFormat = args.dataFormat;\n    }\n    computeOutputShape(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        for (const dim of inputShape.slice(1)) {\n            if (dim == null) {\n                throw new ValueError(`The shape of the input to \"Flatten\" is not fully defined ` +\n                    `(got ${inputShape.slice(1)}). Make sure to pass a complete ` +\n                    `\"input_shape\" or \"batch_input_shape\" argument to the first ` +\n                    `layer in your model.`);\n            }\n        }\n        return [inputShape[0], arrayProd(inputShape, 1)];\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            let input = getExactlyOneTensor(inputs);\n            if (this.dataFormat === 'channelsFirst' && input.rank > 1) {\n                const permutation = [0];\n                for (let i = 2; i < input.rank; ++i) {\n                    permutation.push(i);\n                }\n                permutation.push(1);\n                input = transpose(input, permutation);\n            }\n            return K.batchFlatten(input);\n        });\n    }\n    getConfig() {\n        const config = {};\n        if (this.dataFormat != null) {\n            config['dataFormat'] = this.dataFormat;\n        }\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nFlatten.className = 'Flatten';\nserialization.registerClass(Flatten);\nexport class Activation extends Layer {\n    constructor(args) {\n        super(args);\n        this.supportsMasking = true;\n        this.activation = getActivation(args.activation);\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            const input = getExactlyOneTensor(inputs);\n            return this.activation.apply(input);\n        });\n    }\n    getConfig() {\n        const config = { activation: serializeActivation(this.activation) };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nActivation.className = 'Activation';\nserialization.registerClass(Activation);\nexport class RepeatVector extends Layer {\n    constructor(args) {\n        super(args);\n        this.n = args.n;\n        this.inputSpec = [{ ndim: 2 }];\n    }\n    computeOutputShape(inputShape) {\n        return [inputShape[0], this.n, inputShape[1]];\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            inputs = getExactlyOneTensor(inputs);\n            return K.repeat(inputs, this.n);\n        });\n    }\n    getConfig() {\n        const config = {\n            n: this.n,\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nRepeatVector.className = 'RepeatVector';\nserialization.registerClass(RepeatVector);\nexport class Reshape extends Layer {\n    constructor(args) {\n        super(args);\n        this.targetShape = args.targetShape;\n        // Make sure that all unknown dimensions are represented as `null`.\n        for (let i = 0; i < this.targetShape.length; ++i) {\n            if (this.isUnknown(this.targetShape[i])) {\n                this.targetShape[i] = null;\n            }\n        }\n    }\n    isUnknown(dim) {\n        return dim < 0 || dim == null;\n    }\n    /**\n     * Finds and replaces a missing dimension in output shape.\n     *\n     * This is a near direct port of the internal Numpy function\n     * `_fix_unknown_dimension` in `numpy/core/src/multiarray/shape.c`.\n     *\n     * @param inputShape: Original shape of array begin reshape.\n     * @param outputShape: Target shape of the array, with at most a single\n     * `null` or negative number, which indicates an underdetermined dimension\n     * that should be derived from `inputShape` and the known dimensions of\n     *   `outputShape`.\n     * @returns: The output shape with `null` replaced with its computed value.\n     * @throws: ValueError: If `inputShape` and `outputShape` do not match.\n     */\n    fixUnknownDimension(inputShape, outputShape) {\n        const errorMsg = 'Total size of new array must be unchanged.';\n        const finalShape = outputShape.slice();\n        let known = 1;\n        let unknown = null;\n        for (let i = 0; i < finalShape.length; ++i) {\n            const dim = finalShape[i];\n            if (this.isUnknown(dim)) {\n                if (unknown === null) {\n                    unknown = i;\n                }\n                else {\n                    throw new ValueError('Can only specifiy one unknown dimension.');\n                }\n            }\n            else {\n                known *= dim;\n            }\n        }\n        const originalSize = arrayProd(inputShape);\n        if (unknown !== null) {\n            if (known === 0 || originalSize % known !== 0) {\n                throw new ValueError(errorMsg);\n            }\n            finalShape[unknown] = originalSize / known;\n        }\n        else if (originalSize !== known) {\n            throw new ValueError(errorMsg);\n        }\n        return finalShape;\n    }\n    computeOutputShape(inputShape) {\n        let anyUnknownDims = false;\n        for (let i = 0; i < inputShape.length; ++i) {\n            if (this.isUnknown(inputShape[i])) {\n                anyUnknownDims = true;\n                break;\n            }\n        }\n        if (anyUnknownDims) {\n            return inputShape.slice(0, 1).concat(this.targetShape);\n        }\n        else {\n            return inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n        }\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            const input = getExactlyOneTensor(inputs);\n            const inputShape = input.shape;\n            const outputShape = inputShape.slice(0, 1).concat(this.fixUnknownDimension(inputShape.slice(1), this.targetShape));\n            return reshape(input, outputShape);\n        });\n    }\n    getConfig() {\n        const config = {\n            targetShape: this.targetShape,\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nReshape.className = 'Reshape';\nserialization.registerClass(Reshape);\nexport class Permute extends Layer {\n    constructor(args) {\n        super(args);\n        if (args.dims == null) {\n            throw new Error('Required configuration field `dims` is missing during Permute ' +\n                'constructor call.');\n        }\n        if (!Array.isArray(args.dims)) {\n            throw new Error('Permute constructor requires `dims` to be an Array, but received ' +\n                `${args.dims} instead.`);\n        }\n        // Check the validity of the permutation indices.\n        const expectedSortedIndices = range(1, args.dims.length + 1);\n        if (!util.arraysEqual(args.dims.slice().sort(), expectedSortedIndices)) {\n            throw new Error('Invalid permutation `dims`: ' + JSON.stringify(args.dims) +\n                ' `dims` must contain consecutive integers starting from 1.');\n        }\n        this.dims = args.dims;\n        this.dimsIncludingBatch = [0].concat(this.dims);\n        this.inputSpec = [new InputSpec({ ndim: this.dims.length + 1 })];\n    }\n    computeOutputShape(inputShape) {\n        inputShape = getExactlyOneShape(inputShape);\n        const outputShape = inputShape.slice();\n        this.dims.forEach((dim, i) => {\n            outputShape[i + 1] = inputShape[dim];\n        });\n        return outputShape;\n    }\n    call(inputs, kwargs) {\n        return transpose(getExactlyOneTensor(inputs), this.dimsIncludingBatch);\n    }\n    getConfig() {\n        const config = {\n            dims: this.dims,\n        };\n        const baseConfig = super.getConfig();\n        Object.assign(config, baseConfig);\n        return config;\n    }\n}\n/** @nocollapse */\nPermute.className = 'Permute';\nserialization.registerClass(Permute);\nexport class Masking extends Layer {\n    constructor(args) {\n        super(args == null ? {} : args);\n        this.supportsMasking = true;\n        if (args != null) {\n            this.maskValue = args.maskValue == null ? 0 : args.maskValue;\n        }\n        else {\n            this.maskValue = 0;\n        }\n    }\n    computeOutputShape(inputShape) {\n        return inputShape;\n    }\n    getConfig() {\n        const baseConfig = super.getConfig();\n        const config = { maskValue: this.maskValue };\n        Object.assign(config, baseConfig);\n        return config;\n    }\n    computeMask(inputs, mask) {\n        const input = getExactlyOneTensor(inputs);\n        const axis = -1;\n        return any(notEqual(input, this.maskValue), axis);\n    }\n    call(inputs, kwargs) {\n        return tidy(() => {\n            this.invokeCallHook(inputs, kwargs);\n            const input = getExactlyOneTensor(inputs);\n            const axis = -1;\n            const keepDims = true;\n            const booleanMask = any(notEqual(input, this.maskValue), axis, keepDims);\n            const output = mul(input, cast(booleanMask, input.dtype));\n            return output;\n        });\n    }\n}\n/** @nocollapse */\nMasking.className = 'Masking';\nserialization.registerClass(Masking);\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA;AACA;AACA;AACA,SAASA,GAAT,EAAcC,IAAd,EAAoBC,GAApB,EAAyBC,QAAzB,EAAmCC,OAAnC,EAA4CC,aAA5C,EAA2DC,IAA3D,EAAiEC,SAAjE,EAA4EC,IAA5E,QAAwF,uBAAxF;AACA,SAASC,aAAT,EAAwBC,mBAAxB,QAAmD,gBAAnD;AACA,OAAO,KAAKC,CAAZ,MAAmB,yBAAnB;AACA,SAASC,aAAT,EAAwBC,mBAAxB,QAAmD,gBAAnD;AACA,SAASC,SAAT,EAAoBC,KAApB,QAAiC,oBAAjC;AACA,SAASC,UAAT,QAA2B,WAA3B;AACA,SAASC,cAAT,EAAyBC,oBAAzB,QAAqD,iBAArD;AACA,SAASC,cAAT,EAAyBC,oBAAzB,QAAqD,iBAArD;AACA,SAASC,qBAAT,EAAgCC,0BAAhC,QAAkE,wBAAlE;AACA,SAASC,SAAT,EAAoBC,KAApB,QAAiC,qBAAjC;AACA,SAASC,kBAAT,EAA6BC,mBAA7B,QAAwD,sBAAxD;AACA,OAAO,MAAMC,OAAN,SAAsBZ,KAAtB,CAA4B;EAC/Ba,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAN;IACA,KAAKC,IAAL,GAAYC,IAAI,CAACC,GAAL,CAASD,IAAI,CAACE,GAAL,CAASJ,IAAI,CAACC,IAAd,EAAoB,CAApB,CAAT,EAAiC,CAAjC,CAAZ,CAFc,CAGd;;IACA,KAAKI,UAAL,GAAkBL,IAAI,CAACK,UAAvB;IACA,KAAKC,IAAL,GAAYN,IAAI,CAACM,IAAjB;IACA,KAAKC,eAAL,GAAuB,IAAvB;EACH;;EACDC,aAAa,CAACC,KAAD,EAAQ;IACjB,IAAI,KAAKJ,UAAL,IAAmB,IAAvB,EAA6B;MACzB,OAAO,KAAKA,UAAZ;IACH;;IACD,MAAMK,UAAU,GAAGD,KAAK,CAACE,KAAzB;IACA,MAAMN,UAAU,GAAG,EAAnB;;IACA,KAAK,IAAIO,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKP,UAAL,CAAgBQ,MAApC,EAA4C,EAAED,CAA9C,EAAiD;MAC7CP,UAAU,CAACS,IAAX,CAAgB,KAAKT,UAAL,CAAgBO,CAAhB,KAAsB,IAAtB,GAA6BF,UAAU,CAACE,CAAD,CAAvC,GAA6C,KAAKP,UAAL,CAAgBO,CAAhB,CAA7D;IACH;;IACD,OAAOP,UAAP;EACH;;EACDU,IAAI,CAACC,MAAD,EAASC,MAAT,EAAiB;IACjB,OAAOxC,IAAI,CAAC,MAAM;MACd,KAAKyC,cAAL,CAAoBF,MAApB,EAA4BC,MAA5B;MACA,MAAMR,KAAK,GAAGZ,mBAAmB,CAACmB,MAAD,CAAjC;;MACA,IAAI,IAAI,KAAKf,IAAT,IAAiB,KAAKA,IAAL,GAAY,CAAjC,EAAoC;QAChC,MAAMkB,QAAQ,GAAGF,MAAM,CAAC,UAAD,CAAN,IAAsB,IAAtB,GAA6B,KAA7B,GAAqCA,MAAM,CAAC,UAAD,CAA5D;QACA,MAAMZ,UAAU,GAAG,KAAKG,aAAL,CAAmBC,KAAnB,CAAnB;QACA,MAAMW,MAAM,GAAGtC,CAAC,CAACuC,YAAF,CAAe,MAAMvC,CAAC,CAACwC,OAAF,CAAUb,KAAV,EAAiB,KAAKR,IAAtB,EAA4BI,UAA5B,EAAwC,KAAKC,IAA7C,CAArB,EAAyE,MAAMG,KAA/E,EAAsFU,QAAtF,CAAf;QACA,OAAOC,MAAP;MACH;;MACD,OAAOJ,MAAP;IACH,CAVU,CAAX;EAWH;;EACDO,SAAS,GAAG;IACR,MAAMC,MAAM,GAAG;MACXvB,IAAI,EAAE,KAAKA,IADA;MAEXI,UAAU,EAAE,KAAKA,UAFN;MAGXC,IAAI,EAAE,KAAKA;IAHA,CAAf;IAKA,MAAMmB,UAAU,GAAG,MAAMF,SAAN,EAAnB;IACAG,MAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;IACA,OAAOD,MAAP;EACH;;EACDI,OAAO,GAAG;IACN,OAAO,MAAMA,OAAN,EAAP;EACH;;AA7C8B;AA+CnC;;AACA9B,OAAO,CAAC+B,SAAR,GAAoB,SAApB;AACArD,aAAa,CAACsD,aAAd,CAA4BhC,OAA5B;AACA,OAAO,MAAMiC,gBAAN,SAA+BjC,OAA/B,CAAuC;EAC1CC,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAN;IACA,KAAKgC,SAAL,GAAiB,CAAC;MAAEC,IAAI,EAAE;IAAR,CAAD,CAAjB;EACH;;EACDzB,aAAa,CAACC,KAAD,EAAQ;IACjB,MAAMC,UAAU,GAAGD,KAAK,CAACE,KAAzB;IACA,OAAO,CAACD,UAAU,CAAC,CAAD,CAAX,EAAgB,CAAhB,EAAmBA,UAAU,CAAC,CAAD,CAA7B,CAAP;EACH;;AARyC;AAU9C;;AACAqB,gBAAgB,CAACF,SAAjB,GAA6B,kBAA7B;AACArD,aAAa,CAACsD,aAAd,CAA4BC,gBAA5B;AACA,OAAO,MAAMG,KAAN,SAAoBhD,KAApB,CAA0B;EAC7Ba,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAN,EADc,CAEd;;IACA,KAAKmC,UAAL,GAAkB,IAAlB;IACA,KAAKC,OAAL,GAAe,IAAf;IACA,KAAKC,MAAL,GAAc,IAAd;IACA,KAAKC,IAAL,GAAY,IAAZ;IACA,KAAKC,0BAAL,GAAkC,cAAlC;IACA,KAAKC,wBAAL,GAAgC,OAAhC;;IACA,IAAIxC,IAAI,CAACyC,eAAL,IAAwB,IAAxB,IAAgCzC,IAAI,CAACU,UAAL,IAAmB,IAAnD,IACAV,IAAI,CAAC0C,QAAL,IAAiB,IADrB,EAC2B;MACvB;MACA;MACA,IAAIC,SAAS,GAAG,IAAhB;;MACA,IAAI3C,IAAI,CAAC2C,SAAL,IAAkB,IAAtB,EAA4B;QACxBA,SAAS,GAAG3C,IAAI,CAAC2C,SAAjB;MACH;;MACD,KAAKF,eAAL,GAAuB,CAACE,SAAD,EAAY3C,IAAI,CAAC0C,QAAjB,CAAvB;IACH;;IACD,KAAKE,KAAL,GAAa5C,IAAI,CAAC4C,KAAlB;IACApD,qBAAqB,CAAC,KAAKoD,KAAN,EAAa,OAAb,CAArB;IACA,KAAKT,UAAL,GAAkBvD,aAAa,CAACoB,IAAI,CAACmC,UAAN,CAA/B;;IACA,IAAInC,IAAI,CAACoC,OAAL,IAAgB,IAApB,EAA0B;MACtB,KAAKA,OAAL,GAAepC,IAAI,CAACoC,OAApB;IACH;;IACD,KAAKS,iBAAL,GAAyBzD,cAAc,CAACY,IAAI,CAAC6C,iBAAL,IAA0B,KAAKN,0BAAhC,CAAvC;IACA,KAAKO,eAAL,GACI1D,cAAc,CAACY,IAAI,CAAC8C,eAAL,IAAwB,KAAKN,wBAA9B,CADlB;IAEA,KAAKO,gBAAL,GAAwBhE,aAAa,CAACiB,IAAI,CAAC+C,gBAAN,CAArC;IACA,KAAKC,cAAL,GAAsBjE,aAAa,CAACiB,IAAI,CAACgD,cAAN,CAAnC;IACA,KAAKC,iBAAL,GAAyB3D,cAAc,CAACU,IAAI,CAACiD,iBAAN,CAAvC;IACA,KAAKC,eAAL,GAAuB5D,cAAc,CAACU,IAAI,CAACkD,eAAN,CAArC;IACA,KAAKC,mBAAL,GAA2B7D,cAAc,CAACU,IAAI,CAACmD,mBAAN,CAAzC;IACA,KAAK5C,eAAL,GAAuB,IAAvB;IACA,KAAKyB,SAAL,GAAiB,CAAC;MAAEoB,OAAO,EAAE;IAAX,CAAD,CAAjB;EACH;;EACDC,KAAK,CAAC3C,UAAD,EAAa;IACdA,UAAU,GAAGd,kBAAkB,CAACc,UAAD,CAA/B;IACA,MAAM4C,YAAY,GAAG5C,UAAU,CAACA,UAAU,CAACG,MAAX,GAAoB,CAArB,CAA/B;;IACA,IAAI,KAAKwB,MAAL,IAAe,IAAnB,EAAyB;MACrB,KAAKA,MAAL,GAAc,KAAKkB,SAAL,CAAe,QAAf,EAAyB,CAACD,YAAD,EAAe,KAAKV,KAApB,CAAzB,EAAqD,IAArD,EAA2D,KAAKC,iBAAhE,EAAmF,KAAKI,iBAAxF,EAA2G,IAA3G,EAAiH,KAAKF,gBAAtH,CAAd;;MACA,IAAI,KAAKX,OAAT,EAAkB;QACd,KAAKE,IAAL,GAAY,KAAKiB,SAAL,CAAe,MAAf,EAAuB,CAAC,KAAKX,KAAN,CAAvB,EAAqC,IAArC,EAA2C,KAAKE,eAAhD,EAAiE,KAAKI,eAAtE,EAAuF,IAAvF,EAA6F,KAAKF,cAAlG,CAAZ;MACH;IACJ;;IACD,KAAKhB,SAAL,GAAiB,CAAC;MAAEoB,OAAO,EAAE,CAAX;MAAcI,IAAI,EAAE;QAAE,CAAC,CAAC,CAAF,GAAMF;MAAR;IAApB,CAAD,CAAjB;IACA,KAAKG,KAAL,GAAa,IAAb;EACH;;EACDC,kBAAkB,CAAChD,UAAD,EAAa;IAC3BA,UAAU,GAAGd,kBAAkB,CAACc,UAAD,CAA/B;IACA,MAAMiD,WAAW,GAAGjD,UAAU,CAACkD,KAAX,EAApB;IACAD,WAAW,CAACA,WAAW,CAAC9C,MAAZ,GAAqB,CAAtB,CAAX,GAAsC,KAAK+B,KAA3C;IACA,OAAOe,WAAP;EACH;;EACD5C,IAAI,CAACC,MAAD,EAASC,MAAT,EAAiB;IACjB,OAAOxC,IAAI,CAAC,MAAM;MACd,KAAKyC,cAAL,CAAoBF,MAApB,EAA4BC,MAA5B,EADc,CAEd;;MACA,MAAMR,KAAK,GAAGZ,mBAAmB,CAACmB,MAAD,CAAjC;MACA,MAAM6C,mBAAmB,GAAGpE,0BAA0B,CAAC,KAAK0C,UAAL,CAAgB2B,YAAhB,EAAD,CAAtD;MACA,IAAI1C,MAAJ;;MACA,IAAIyC,mBAAmB,IAAI,IAA3B,EAAiC;QAC7BzC,MAAM,GAAGtC,CAAC,CAACiF,GAAF,CAAMtD,KAAN,EAAa,KAAK4B,MAAL,CAAY2B,IAAZ,EAAb,EAAiCH,mBAAjC,EAAsD,KAAKvB,IAAL,GAAY,KAAKA,IAAL,CAAU0B,IAAV,EAAZ,GAA+B,IAArF,CAAT;MACH,CAFD,MAGK;QACD5C,MAAM,GAAGtC,CAAC,CAACiF,GAAF,CAAMtD,KAAN,EAAa,KAAK4B,MAAL,CAAY2B,IAAZ,EAAb,CAAT;;QACA,IAAI,KAAK1B,IAAL,IAAa,IAAjB,EAAuB;UACnBlB,MAAM,GAAGtC,CAAC,CAACmF,OAAF,CAAU7C,MAAV,EAAkB,KAAKkB,IAAL,CAAU0B,IAAV,EAAlB,CAAT;QACH;;QACD,IAAI,KAAK7B,UAAL,IAAmB,IAAvB,EAA6B;UACzBf,MAAM,GAAG,KAAKe,UAAL,CAAgB+B,KAAhB,CAAsB9C,MAAtB,CAAT;QACH;MACJ;;MACD,OAAOA,MAAP;IACH,CAnBU,CAAX;EAoBH;;EACDG,SAAS,GAAG;IACR,MAAMC,MAAM,GAAG;MACXoB,KAAK,EAAE,KAAKA,KADD;MAEXT,UAAU,EAAEtD,mBAAmB,CAAC,KAAKsD,UAAN,CAFpB;MAGXC,OAAO,EAAE,KAAKA,OAHH;MAIXS,iBAAiB,EAAExD,oBAAoB,CAAC,KAAKwD,iBAAN,CAJ5B;MAKXC,eAAe,EAAEzD,oBAAoB,CAAC,KAAKyD,eAAN,CAL1B;MAMXG,iBAAiB,EAAE1D,oBAAoB,CAAC,KAAK0D,iBAAN,CAN5B;MAOXC,eAAe,EAAE3D,oBAAoB,CAAC,KAAK2D,eAAN,CAP1B;MAQXC,mBAAmB,EAAE5D,oBAAoB,CAAC,KAAK4D,mBAAN,CAR9B;MASXJ,gBAAgB,EAAE/D,mBAAmB,CAAC,KAAK+D,gBAAN,CAT1B;MAUXC,cAAc,EAAEhE,mBAAmB,CAAC,KAAKgE,cAAN;IAVxB,CAAf;IAYA,MAAMvB,UAAU,GAAG,MAAMF,SAAN,EAAnB;IACAG,MAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;IACA,OAAOD,MAAP;EACH;;AA7F4B;AA+FjC;;AACAU,KAAK,CAACL,SAAN,GAAkB,OAAlB;AACArD,aAAa,CAACsD,aAAd,CAA4BI,KAA5B;AACA,OAAO,MAAMiC,OAAN,SAAsBjF,KAAtB,CAA4B;EAC/Ba,WAAW,CAACC,IAAD,EAAO;IACdA,IAAI,GAAGA,IAAI,IAAI,EAAf;IACA,MAAMA,IAAN;IACA,KAAKgC,SAAL,GAAiB,CAAC;MAAEoB,OAAO,EAAE;IAAX,CAAD,CAAjB;IACA,KAAKgB,UAAL,GAAkBpE,IAAI,CAACoE,UAAvB;EACH;;EACDV,kBAAkB,CAAChD,UAAD,EAAa;IAC3BA,UAAU,GAAGd,kBAAkB,CAACc,UAAD,CAA/B;;IACA,KAAK,MAAM2D,GAAX,IAAkB3D,UAAU,CAACkD,KAAX,CAAiB,CAAjB,CAAlB,EAAuC;MACnC,IAAIS,GAAG,IAAI,IAAX,EAAiB;QACb,MAAM,IAAIlF,UAAJ,CAAgB,2DAAD,GAChB,QAAOuB,UAAU,CAACkD,KAAX,CAAiB,CAAjB,CAAoB,kCADX,GAEhB,6DAFgB,GAGhB,sBAHC,CAAN;MAIH;IACJ;;IACD,OAAO,CAAClD,UAAU,CAAC,CAAD,CAAX,EAAgBhB,SAAS,CAACgB,UAAD,EAAa,CAAb,CAAzB,CAAP;EACH;;EACDK,IAAI,CAACC,MAAD,EAASC,MAAT,EAAiB;IACjB,OAAOxC,IAAI,CAAC,MAAM;MACd,KAAKyC,cAAL,CAAoBF,MAApB,EAA4BC,MAA5B;MACA,IAAIR,KAAK,GAAGZ,mBAAmB,CAACmB,MAAD,CAA/B;;MACA,IAAI,KAAKoD,UAAL,KAAoB,eAApB,IAAuC3D,KAAK,CAAC6D,IAAN,GAAa,CAAxD,EAA2D;QACvD,MAAMC,WAAW,GAAG,CAAC,CAAD,CAApB;;QACA,KAAK,IAAI3D,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGH,KAAK,CAAC6D,IAA1B,EAAgC,EAAE1D,CAAlC,EAAqC;UACjC2D,WAAW,CAACzD,IAAZ,CAAiBF,CAAjB;QACH;;QACD2D,WAAW,CAACzD,IAAZ,CAAiB,CAAjB;QACAL,KAAK,GAAG/B,SAAS,CAAC+B,KAAD,EAAQ8D,WAAR,CAAjB;MACH;;MACD,OAAOzF,CAAC,CAAC0F,YAAF,CAAe/D,KAAf,CAAP;IACH,CAZU,CAAX;EAaH;;EACDc,SAAS,GAAG;IACR,MAAMC,MAAM,GAAG,EAAf;;IACA,IAAI,KAAK4C,UAAL,IAAmB,IAAvB,EAA6B;MACzB5C,MAAM,CAAC,YAAD,CAAN,GAAuB,KAAK4C,UAA5B;IACH;;IACD,MAAM3C,UAAU,GAAG,MAAMF,SAAN,EAAnB;IACAG,MAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;IACA,OAAOD,MAAP;EACH;;AA1C8B;AA4CnC;;AACA2C,OAAO,CAACtC,SAAR,GAAoB,SAApB;AACArD,aAAa,CAACsD,aAAd,CAA4BqC,OAA5B;AACA,OAAO,MAAMM,UAAN,SAAyBvF,KAAzB,CAA+B;EAClCa,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAN;IACA,KAAKO,eAAL,GAAuB,IAAvB;IACA,KAAK4B,UAAL,GAAkBvD,aAAa,CAACoB,IAAI,CAACmC,UAAN,CAA/B;EACH;;EACDpB,IAAI,CAACC,MAAD,EAASC,MAAT,EAAiB;IACjB,OAAOxC,IAAI,CAAC,MAAM;MACd,KAAKyC,cAAL,CAAoBF,MAApB,EAA4BC,MAA5B;MACA,MAAMR,KAAK,GAAGZ,mBAAmB,CAACmB,MAAD,CAAjC;MACA,OAAO,KAAKmB,UAAL,CAAgB+B,KAAhB,CAAsBzD,KAAtB,CAAP;IACH,CAJU,CAAX;EAKH;;EACDc,SAAS,GAAG;IACR,MAAMC,MAAM,GAAG;MAAEW,UAAU,EAAEtD,mBAAmB,CAAC,KAAKsD,UAAN;IAAjC,CAAf;IACA,MAAMV,UAAU,GAAG,MAAMF,SAAN,EAAnB;IACAG,MAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;IACA,OAAOD,MAAP;EACH;;AAlBiC;AAoBtC;;AACAiD,UAAU,CAAC5C,SAAX,GAAuB,YAAvB;AACArD,aAAa,CAACsD,aAAd,CAA4B2C,UAA5B;AACA,OAAO,MAAMC,YAAN,SAA2BxF,KAA3B,CAAiC;EACpCa,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAN;IACA,KAAK2E,CAAL,GAAS3E,IAAI,CAAC2E,CAAd;IACA,KAAK3C,SAAL,GAAiB,CAAC;MAAEC,IAAI,EAAE;IAAR,CAAD,CAAjB;EACH;;EACDyB,kBAAkB,CAAChD,UAAD,EAAa;IAC3B,OAAO,CAACA,UAAU,CAAC,CAAD,CAAX,EAAgB,KAAKiE,CAArB,EAAwBjE,UAAU,CAAC,CAAD,CAAlC,CAAP;EACH;;EACDK,IAAI,CAACC,MAAD,EAASC,MAAT,EAAiB;IACjB,OAAOxC,IAAI,CAAC,MAAM;MACduC,MAAM,GAAGnB,mBAAmB,CAACmB,MAAD,CAA5B;MACA,OAAOlC,CAAC,CAAC8F,MAAF,CAAS5D,MAAT,EAAiB,KAAK2D,CAAtB,CAAP;IACH,CAHU,CAAX;EAIH;;EACDpD,SAAS,GAAG;IACR,MAAMC,MAAM,GAAG;MACXmD,CAAC,EAAE,KAAKA;IADG,CAAf;IAGA,MAAMlD,UAAU,GAAG,MAAMF,SAAN,EAAnB;IACAG,MAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;IACA,OAAOD,MAAP;EACH;;AAtBmC;AAwBxC;;AACAkD,YAAY,CAAC7C,SAAb,GAAyB,cAAzB;AACArD,aAAa,CAACsD,aAAd,CAA4B4C,YAA5B;AACA,OAAO,MAAMG,OAAN,SAAsB3F,KAAtB,CAA4B;EAC/Ba,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAN;IACA,KAAK8E,WAAL,GAAmB9E,IAAI,CAAC8E,WAAxB,CAFc,CAGd;;IACA,KAAK,IAAIlE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAG,KAAKkE,WAAL,CAAiBjE,MAArC,EAA6C,EAAED,CAA/C,EAAkD;MAC9C,IAAI,KAAKmE,SAAL,CAAe,KAAKD,WAAL,CAAiBlE,CAAjB,CAAf,CAAJ,EAAyC;QACrC,KAAKkE,WAAL,CAAiBlE,CAAjB,IAAsB,IAAtB;MACH;IACJ;EACJ;;EACDmE,SAAS,CAACV,GAAD,EAAM;IACX,OAAOA,GAAG,GAAG,CAAN,IAAWA,GAAG,IAAI,IAAzB;EACH;EACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACIW,mBAAmB,CAACtE,UAAD,EAAaiD,WAAb,EAA0B;IACzC,MAAMsB,QAAQ,GAAG,4CAAjB;IACA,MAAMC,UAAU,GAAGvB,WAAW,CAACC,KAAZ,EAAnB;IACA,IAAIuB,KAAK,GAAG,CAAZ;IACA,IAAIC,OAAO,GAAG,IAAd;;IACA,KAAK,IAAIxE,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGsE,UAAU,CAACrE,MAA/B,EAAuC,EAAED,CAAzC,EAA4C;MACxC,MAAMyD,GAAG,GAAGa,UAAU,CAACtE,CAAD,CAAtB;;MACA,IAAI,KAAKmE,SAAL,CAAeV,GAAf,CAAJ,EAAyB;QACrB,IAAIe,OAAO,KAAK,IAAhB,EAAsB;UAClBA,OAAO,GAAGxE,CAAV;QACH,CAFD,MAGK;UACD,MAAM,IAAIzB,UAAJ,CAAe,0CAAf,CAAN;QACH;MACJ,CAPD,MAQK;QACDgG,KAAK,IAAId,GAAT;MACH;IACJ;;IACD,MAAMgB,YAAY,GAAG3F,SAAS,CAACgB,UAAD,CAA9B;;IACA,IAAI0E,OAAO,KAAK,IAAhB,EAAsB;MAClB,IAAID,KAAK,KAAK,CAAV,IAAeE,YAAY,GAAGF,KAAf,KAAyB,CAA5C,EAA+C;QAC3C,MAAM,IAAIhG,UAAJ,CAAe8F,QAAf,CAAN;MACH;;MACDC,UAAU,CAACE,OAAD,CAAV,GAAsBC,YAAY,GAAGF,KAArC;IACH,CALD,MAMK,IAAIE,YAAY,KAAKF,KAArB,EAA4B;MAC7B,MAAM,IAAIhG,UAAJ,CAAe8F,QAAf,CAAN;IACH;;IACD,OAAOC,UAAP;EACH;;EACDxB,kBAAkB,CAAChD,UAAD,EAAa;IAC3B,IAAI4E,cAAc,GAAG,KAArB;;IACA,KAAK,IAAI1E,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGF,UAAU,CAACG,MAA/B,EAAuC,EAAED,CAAzC,EAA4C;MACxC,IAAI,KAAKmE,SAAL,CAAerE,UAAU,CAACE,CAAD,CAAzB,CAAJ,EAAmC;QAC/B0E,cAAc,GAAG,IAAjB;QACA;MACH;IACJ;;IACD,IAAIA,cAAJ,EAAoB;MAChB,OAAO5E,UAAU,CAACkD,KAAX,CAAiB,CAAjB,EAAoB,CAApB,EAAuB2B,MAAvB,CAA8B,KAAKT,WAAnC,CAAP;IACH,CAFD,MAGK;MACD,OAAOpE,UAAU,CAACkD,KAAX,CAAiB,CAAjB,EAAoB,CAApB,EAAuB2B,MAAvB,CAA8B,KAAKP,mBAAL,CAAyBtE,UAAU,CAACkD,KAAX,CAAiB,CAAjB,CAAzB,EAA8C,KAAKkB,WAAnD,CAA9B,CAAP;IACH;EACJ;;EACD/D,IAAI,CAACC,MAAD,EAASC,MAAT,EAAiB;IACjB,OAAOxC,IAAI,CAAC,MAAM;MACd,KAAKyC,cAAL,CAAoBF,MAApB,EAA4BC,MAA5B;MACA,MAAMR,KAAK,GAAGZ,mBAAmB,CAACmB,MAAD,CAAjC;MACA,MAAMN,UAAU,GAAGD,KAAK,CAACE,KAAzB;MACA,MAAMgD,WAAW,GAAGjD,UAAU,CAACkD,KAAX,CAAiB,CAAjB,EAAoB,CAApB,EAAuB2B,MAAvB,CAA8B,KAAKP,mBAAL,CAAyBtE,UAAU,CAACkD,KAAX,CAAiB,CAAjB,CAAzB,EAA8C,KAAKkB,WAAnD,CAA9B,CAApB;MACA,OAAOvG,OAAO,CAACkC,KAAD,EAAQkD,WAAR,CAAd;IACH,CANU,CAAX;EAOH;;EACDpC,SAAS,GAAG;IACR,MAAMC,MAAM,GAAG;MACXsD,WAAW,EAAE,KAAKA;IADP,CAAf;IAGA,MAAMrD,UAAU,GAAG,MAAMF,SAAN,EAAnB;IACAG,MAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;IACA,OAAOD,MAAP;EACH;;AA1F8B;AA4FnC;;AACAqD,OAAO,CAAChD,SAAR,GAAoB,SAApB;AACArD,aAAa,CAACsD,aAAd,CAA4B+C,OAA5B;AACA,OAAO,MAAMW,OAAN,SAAsBtG,KAAtB,CAA4B;EAC/Ba,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAN;;IACA,IAAIA,IAAI,CAACyF,IAAL,IAAa,IAAjB,EAAuB;MACnB,MAAM,IAAIC,KAAJ,CAAU,mEACZ,mBADE,CAAN;IAEH;;IACD,IAAI,CAACC,KAAK,CAACC,OAAN,CAAc5F,IAAI,CAACyF,IAAnB,CAAL,EAA+B;MAC3B,MAAM,IAAIC,KAAJ,CAAU,sEACX,GAAE1F,IAAI,CAACyF,IAAK,WADX,CAAN;IAEH,CATa,CAUd;;;IACA,MAAMI,qBAAqB,GAAGlG,KAAK,CAAC,CAAD,EAAIK,IAAI,CAACyF,IAAL,CAAU5E,MAAV,GAAmB,CAAvB,CAAnC;;IACA,IAAI,CAAClC,IAAI,CAACmH,WAAL,CAAiB9F,IAAI,CAACyF,IAAL,CAAU7B,KAAV,GAAkBmC,IAAlB,EAAjB,EAA2CF,qBAA3C,CAAL,EAAwE;MACpE,MAAM,IAAIH,KAAJ,CAAU,iCAAiCM,IAAI,CAACC,SAAL,CAAejG,IAAI,CAACyF,IAApB,CAAjC,GACZ,4DADE,CAAN;IAEH;;IACD,KAAKA,IAAL,GAAYzF,IAAI,CAACyF,IAAjB;IACA,KAAKS,kBAAL,GAA0B,CAAC,CAAD,EAAIX,MAAJ,CAAW,KAAKE,IAAhB,CAA1B;IACA,KAAKzD,SAAL,GAAiB,CAAC,IAAI/C,SAAJ,CAAc;MAAEgD,IAAI,EAAE,KAAKwD,IAAL,CAAU5E,MAAV,GAAmB;IAA3B,CAAd,CAAD,CAAjB;EACH;;EACD6C,kBAAkB,CAAChD,UAAD,EAAa;IAC3BA,UAAU,GAAGd,kBAAkB,CAACc,UAAD,CAA/B;IACA,MAAMiD,WAAW,GAAGjD,UAAU,CAACkD,KAAX,EAApB;IACA,KAAK6B,IAAL,CAAUU,OAAV,CAAkB,CAAC9B,GAAD,EAAMzD,CAAN,KAAY;MAC1B+C,WAAW,CAAC/C,CAAC,GAAG,CAAL,CAAX,GAAqBF,UAAU,CAAC2D,GAAD,CAA/B;IACH,CAFD;IAGA,OAAOV,WAAP;EACH;;EACD5C,IAAI,CAACC,MAAD,EAASC,MAAT,EAAiB;IACjB,OAAOvC,SAAS,CAACmB,mBAAmB,CAACmB,MAAD,CAApB,EAA8B,KAAKkF,kBAAnC,CAAhB;EACH;;EACD3E,SAAS,GAAG;IACR,MAAMC,MAAM,GAAG;MACXiE,IAAI,EAAE,KAAKA;IADA,CAAf;IAGA,MAAMhE,UAAU,GAAG,MAAMF,SAAN,EAAnB;IACAG,MAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;IACA,OAAOD,MAAP;EACH;;AAvC8B;AAyCnC;;AACAgE,OAAO,CAAC3D,SAAR,GAAoB,SAApB;AACArD,aAAa,CAACsD,aAAd,CAA4B0D,OAA5B;AACA,OAAO,MAAMY,OAAN,SAAsBlH,KAAtB,CAA4B;EAC/Ba,WAAW,CAACC,IAAD,EAAO;IACd,MAAMA,IAAI,IAAI,IAAR,GAAe,EAAf,GAAoBA,IAA1B;IACA,KAAKO,eAAL,GAAuB,IAAvB;;IACA,IAAIP,IAAI,IAAI,IAAZ,EAAkB;MACd,KAAKqG,SAAL,GAAiBrG,IAAI,CAACqG,SAAL,IAAkB,IAAlB,GAAyB,CAAzB,GAA6BrG,IAAI,CAACqG,SAAnD;IACH,CAFD,MAGK;MACD,KAAKA,SAAL,GAAiB,CAAjB;IACH;EACJ;;EACD3C,kBAAkB,CAAChD,UAAD,EAAa;IAC3B,OAAOA,UAAP;EACH;;EACDa,SAAS,GAAG;IACR,MAAME,UAAU,GAAG,MAAMF,SAAN,EAAnB;IACA,MAAMC,MAAM,GAAG;MAAE6E,SAAS,EAAE,KAAKA;IAAlB,CAAf;IACA3E,MAAM,CAACC,MAAP,CAAcH,MAAd,EAAsBC,UAAtB;IACA,OAAOD,MAAP;EACH;;EACD8E,WAAW,CAACtF,MAAD,EAASuF,IAAT,EAAe;IACtB,MAAM9F,KAAK,GAAGZ,mBAAmB,CAACmB,MAAD,CAAjC;IACA,MAAMwF,IAAI,GAAG,CAAC,CAAd;IACA,OAAOrI,GAAG,CAACG,QAAQ,CAACmC,KAAD,EAAQ,KAAK4F,SAAb,CAAT,EAAkCG,IAAlC,CAAV;EACH;;EACDzF,IAAI,CAACC,MAAD,EAASC,MAAT,EAAiB;IACjB,OAAOxC,IAAI,CAAC,MAAM;MACd,KAAKyC,cAAL,CAAoBF,MAApB,EAA4BC,MAA5B;MACA,MAAMR,KAAK,GAAGZ,mBAAmB,CAACmB,MAAD,CAAjC;MACA,MAAMwF,IAAI,GAAG,CAAC,CAAd;MACA,MAAMC,QAAQ,GAAG,IAAjB;MACA,MAAMC,WAAW,GAAGvI,GAAG,CAACG,QAAQ,CAACmC,KAAD,EAAQ,KAAK4F,SAAb,CAAT,EAAkCG,IAAlC,EAAwCC,QAAxC,CAAvB;MACA,MAAMrF,MAAM,GAAG/C,GAAG,CAACoC,KAAD,EAAQrC,IAAI,CAACsI,WAAD,EAAcjG,KAAK,CAACkG,KAApB,CAAZ,CAAlB;MACA,OAAOvF,MAAP;IACH,CARU,CAAX;EASH;;AAnC8B;AAqCnC;;AACAgF,OAAO,CAACvE,SAAR,GAAoB,SAApB;AACArD,aAAa,CAACsD,aAAd,CAA4BsE,OAA5B"},"metadata":{},"sourceType":"module"}