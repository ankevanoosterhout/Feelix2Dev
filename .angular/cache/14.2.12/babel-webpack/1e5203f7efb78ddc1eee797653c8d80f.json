{"ast":null,"code":"/**\n * @license\n * Copyright 2022 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util } from '../base';\nimport { Prod } from '../kernel_names';\nimport { cumprod } from '../ops/cumprod';\nimport { mul } from '../ops/mul';\nimport { reshape } from '../ops/reshape';\nimport { transpose } from '../ops/transpose'; // Gradient for product operation on a single axis.\n\nfunction prodGradFn_(x, dy, axis) {\n  // The gradient tensor (dy) has a set of axes removed, so we create re-shaped\n  // versions (of size 1) for the removed axis; this supports broadcasting over\n  // those dimensions.\n  const expandedYShape = x.shape.slice();\n  expandedYShape[axis] = 1; // The actual gradient computation.\n\n  const expandedDy = reshape(dy, expandedYShape);\n  const xCumProd = cumprod(x, axis, true, false);\n  const xCumRevProd = cumprod(x, axis, true, true);\n  const dx = mul(xCumProd, xCumRevProd);\n  return mul(expandedDy, dx);\n} // Support gradients when the product is done on many axes at once.\n// This done py pushing all the axes on which the product is applied into a\n// single axis.\n\n\nfunction prodsGradFn_(x, dy, axis) {\n  // Move all axes for doing prod over to the end of the tensor.\n  const xRank = x.shape.length;\n  const finalProdAxis = xRank - axis.length;\n  const xPermutation = backend_util.getAxesPermutation(axis, xRank);\n  let permutedX = x;\n\n  if (xPermutation != null) {\n    permutedX = transpose(x, xPermutation);\n  } // Reshape all the prod dimensions into a single one, and do compute prod\n  // gradients on that.\n\n\n  const newShape = permutedX.shape.slice();\n  const removedShape = newShape.splice(xRank - axis.length, axis.length);\n  const endPartShape = removedShape.reduce((p, c) => p * c, 1);\n  newShape.push(endPartShape);\n  const reshapedPermutedX = permutedX.reshape(newShape);\n  let prodGrad = prodGradFn_(reshapedPermutedX, dy, finalProdAxis); // Undo the re-shaping now we have the dx vector, and permute back to\n  // original axes order.\n\n  prodGrad = prodGrad.reshape(permutedX.shape);\n\n  if (xPermutation != null) {\n    const undoPermutation = backend_util.getUndoAxesPermutation(xPermutation);\n    prodGrad = transpose(prodGrad, undoPermutation);\n  }\n\n  return prodGrad;\n} // Running example:\n// [\n//   [\n//     [3.0, 4.0],\n//     [5.0, 6.0],\n//     [7.0, 8.0]\n//   ],\n//   [\n//     [3.0, 5.0],\n//     [0.0, 6.0],\n//     [5.0, 6.0]\n//   ]\n// ]\n//\n\n\nexport const prodGradConfig = {\n  kernelName: Prod,\n  inputsToSave: ['x'],\n  gradFunc: (dy, saved, attrs) => {\n    const [x] = saved;\n    const {\n      axis\n    } = attrs;\n    let axisArr = [];\n\n    if (axis === undefined || axis === null) {\n      axisArr = x.shape.map((_, i) => i);\n    } else if (typeof axis === 'number') {\n      axisArr = [axis];\n    } else {\n      axisArr = axis;\n    }\n\n    return {\n      x: () => prodsGradFn_(x, dy, axisArr)\n    };\n  }\n};","map":{"version":3,"names":["backend_util","Prod","cumprod","mul","reshape","transpose","prodGradFn_","x","dy","axis","expandedYShape","shape","slice","expandedDy","xCumProd","xCumRevProd","dx","prodsGradFn_","xRank","length","finalProdAxis","xPermutation","getAxesPermutation","permutedX","newShape","removedShape","splice","endPartShape","reduce","p","c","push","reshapedPermutedX","prodGrad","undoPermutation","getUndoAxesPermutation","prodGradConfig","kernelName","inputsToSave","gradFunc","saved","attrs","axisArr","undefined","map","_","i"],"sources":["C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@tensorflow/tfjs-core/dist/gradients/Prod_grad.js"],"sourcesContent":["/**\n * @license\n * Copyright 2022 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util } from '../base';\nimport { Prod } from '../kernel_names';\nimport { cumprod } from '../ops/cumprod';\nimport { mul } from '../ops/mul';\nimport { reshape } from '../ops/reshape';\nimport { transpose } from '../ops/transpose';\n// Gradient for product operation on a single axis.\nfunction prodGradFn_(x, dy, axis) {\n    // The gradient tensor (dy) has a set of axes removed, so we create re-shaped\n    // versions (of size 1) for the removed axis; this supports broadcasting over\n    // those dimensions.\n    const expandedYShape = x.shape.slice();\n    expandedYShape[axis] = 1;\n    // The actual gradient computation.\n    const expandedDy = reshape(dy, expandedYShape);\n    const xCumProd = cumprod(x, axis, true, false);\n    const xCumRevProd = cumprod(x, axis, true, true);\n    const dx = mul(xCumProd, xCumRevProd);\n    return mul(expandedDy, dx);\n}\n// Support gradients when the product is done on many axes at once.\n// This done py pushing all the axes on which the product is applied into a\n// single axis.\nfunction prodsGradFn_(x, dy, axis) {\n    // Move all axes for doing prod over to the end of the tensor.\n    const xRank = x.shape.length;\n    const finalProdAxis = xRank - axis.length;\n    const xPermutation = backend_util.getAxesPermutation(axis, xRank);\n    let permutedX = x;\n    if (xPermutation != null) {\n        permutedX = transpose(x, xPermutation);\n    }\n    // Reshape all the prod dimensions into a single one, and do compute prod\n    // gradients on that.\n    const newShape = permutedX.shape.slice();\n    const removedShape = newShape.splice(xRank - axis.length, axis.length);\n    const endPartShape = removedShape.reduce((p, c) => p * c, 1);\n    newShape.push(endPartShape);\n    const reshapedPermutedX = permutedX.reshape(newShape);\n    let prodGrad = prodGradFn_(reshapedPermutedX, dy, finalProdAxis);\n    // Undo the re-shaping now we have the dx vector, and permute back to\n    // original axes order.\n    prodGrad = prodGrad.reshape(permutedX.shape);\n    if (xPermutation != null) {\n        const undoPermutation = backend_util.getUndoAxesPermutation(xPermutation);\n        prodGrad = transpose(prodGrad, undoPermutation);\n    }\n    return prodGrad;\n}\n// Running example:\n// [\n//   [\n//     [3.0, 4.0],\n//     [5.0, 6.0],\n//     [7.0, 8.0]\n//   ],\n//   [\n//     [3.0, 5.0],\n//     [0.0, 6.0],\n//     [5.0, 6.0]\n//   ]\n// ]\n//\nexport const prodGradConfig = {\n    kernelName: Prod,\n    inputsToSave: ['x'],\n    gradFunc: (dy, saved, attrs) => {\n        const [x] = saved;\n        const { axis } = attrs;\n        let axisArr = [];\n        if (axis === undefined || axis === null) {\n            axisArr = x.shape.map((_, i) => i);\n        }\n        else if (typeof axis === 'number') {\n            axisArr = [axis];\n        }\n        else {\n            axisArr = axis;\n        }\n        return { x: () => prodsGradFn_(x, dy, axisArr) };\n    }\n};\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,YAAT,QAA6B,SAA7B;AACA,SAASC,IAAT,QAAqB,iBAArB;AACA,SAASC,OAAT,QAAwB,gBAAxB;AACA,SAASC,GAAT,QAAoB,YAApB;AACA,SAASC,OAAT,QAAwB,gBAAxB;AACA,SAASC,SAAT,QAA0B,kBAA1B,C,CACA;;AACA,SAASC,WAAT,CAAqBC,CAArB,EAAwBC,EAAxB,EAA4BC,IAA5B,EAAkC;EAC9B;EACA;EACA;EACA,MAAMC,cAAc,GAAGH,CAAC,CAACI,KAAF,CAAQC,KAAR,EAAvB;EACAF,cAAc,CAACD,IAAD,CAAd,GAAuB,CAAvB,CAL8B,CAM9B;;EACA,MAAMI,UAAU,GAAGT,OAAO,CAACI,EAAD,EAAKE,cAAL,CAA1B;EACA,MAAMI,QAAQ,GAAGZ,OAAO,CAACK,CAAD,EAAIE,IAAJ,EAAU,IAAV,EAAgB,KAAhB,CAAxB;EACA,MAAMM,WAAW,GAAGb,OAAO,CAACK,CAAD,EAAIE,IAAJ,EAAU,IAAV,EAAgB,IAAhB,CAA3B;EACA,MAAMO,EAAE,GAAGb,GAAG,CAACW,QAAD,EAAWC,WAAX,CAAd;EACA,OAAOZ,GAAG,CAACU,UAAD,EAAaG,EAAb,CAAV;AACH,C,CACD;AACA;AACA;;;AACA,SAASC,YAAT,CAAsBV,CAAtB,EAAyBC,EAAzB,EAA6BC,IAA7B,EAAmC;EAC/B;EACA,MAAMS,KAAK,GAAGX,CAAC,CAACI,KAAF,CAAQQ,MAAtB;EACA,MAAMC,aAAa,GAAGF,KAAK,GAAGT,IAAI,CAACU,MAAnC;EACA,MAAME,YAAY,GAAGrB,YAAY,CAACsB,kBAAb,CAAgCb,IAAhC,EAAsCS,KAAtC,CAArB;EACA,IAAIK,SAAS,GAAGhB,CAAhB;;EACA,IAAIc,YAAY,IAAI,IAApB,EAA0B;IACtBE,SAAS,GAAGlB,SAAS,CAACE,CAAD,EAAIc,YAAJ,CAArB;EACH,CAR8B,CAS/B;EACA;;;EACA,MAAMG,QAAQ,GAAGD,SAAS,CAACZ,KAAV,CAAgBC,KAAhB,EAAjB;EACA,MAAMa,YAAY,GAAGD,QAAQ,CAACE,MAAT,CAAgBR,KAAK,GAAGT,IAAI,CAACU,MAA7B,EAAqCV,IAAI,CAACU,MAA1C,CAArB;EACA,MAAMQ,YAAY,GAAGF,YAAY,CAACG,MAAb,CAAoB,CAACC,CAAD,EAAIC,CAAJ,KAAUD,CAAC,GAAGC,CAAlC,EAAqC,CAArC,CAArB;EACAN,QAAQ,CAACO,IAAT,CAAcJ,YAAd;EACA,MAAMK,iBAAiB,GAAGT,SAAS,CAACnB,OAAV,CAAkBoB,QAAlB,CAA1B;EACA,IAAIS,QAAQ,GAAG3B,WAAW,CAAC0B,iBAAD,EAAoBxB,EAApB,EAAwBY,aAAxB,CAA1B,CAhB+B,CAiB/B;EACA;;EACAa,QAAQ,GAAGA,QAAQ,CAAC7B,OAAT,CAAiBmB,SAAS,CAACZ,KAA3B,CAAX;;EACA,IAAIU,YAAY,IAAI,IAApB,EAA0B;IACtB,MAAMa,eAAe,GAAGlC,YAAY,CAACmC,sBAAb,CAAoCd,YAApC,CAAxB;IACAY,QAAQ,GAAG5B,SAAS,CAAC4B,QAAD,EAAWC,eAAX,CAApB;EACH;;EACD,OAAOD,QAAP;AACH,C,CACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,OAAO,MAAMG,cAAc,GAAG;EAC1BC,UAAU,EAAEpC,IADc;EAE1BqC,YAAY,EAAE,CAAC,GAAD,CAFY;EAG1BC,QAAQ,EAAE,CAAC/B,EAAD,EAAKgC,KAAL,EAAYC,KAAZ,KAAsB;IAC5B,MAAM,CAAClC,CAAD,IAAMiC,KAAZ;IACA,MAAM;MAAE/B;IAAF,IAAWgC,KAAjB;IACA,IAAIC,OAAO,GAAG,EAAd;;IACA,IAAIjC,IAAI,KAAKkC,SAAT,IAAsBlC,IAAI,KAAK,IAAnC,EAAyC;MACrCiC,OAAO,GAAGnC,CAAC,CAACI,KAAF,CAAQiC,GAAR,CAAY,CAACC,CAAD,EAAIC,CAAJ,KAAUA,CAAtB,CAAV;IACH,CAFD,MAGK,IAAI,OAAOrC,IAAP,KAAgB,QAApB,EAA8B;MAC/BiC,OAAO,GAAG,CAACjC,IAAD,CAAV;IACH,CAFI,MAGA;MACDiC,OAAO,GAAGjC,IAAV;IACH;;IACD,OAAO;MAAEF,CAAC,EAAE,MAAMU,YAAY,CAACV,CAAD,EAAIC,EAAJ,EAAQkC,OAAR;IAAvB,CAAP;EACH;AAjByB,CAAvB"},"metadata":{},"sourceType":"module"}