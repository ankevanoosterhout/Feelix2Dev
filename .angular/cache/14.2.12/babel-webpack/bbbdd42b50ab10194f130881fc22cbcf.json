{"ast":null,"code":"import _asyncToGenerator from \"C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\n\n/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Workaround for: https://github.com/bazelbuild/rules_nodejs/issues/1265\n/// <reference types=\"@webgpu/types/dist\" />\nimport { getGlobal } from './global_util';\nimport { tensorToString } from './tensor_format';\nimport * as util from './util';\nimport { computeStrides, toNestedArray } from './util';\n/**\n * A mutable object, similar to `tf.Tensor`, that allows users to set values\n * at locations before converting to an immutable `tf.Tensor`.\n *\n * See `tf.buffer` for creating a tensor buffer.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\n\nexport class TensorBuffer {\n  constructor(shape, dtype, values) {\n    this.dtype = dtype;\n    this.shape = shape.slice();\n    this.size = util.sizeFromShape(shape);\n\n    if (values != null) {\n      const n = values.length;\n      util.assert(n === this.size, () => `Length of values '${n}' does not match the size ` + `inferred by the shape '${this.size}'.`);\n    }\n\n    if (dtype === 'complex64') {\n      throw new Error(`complex64 dtype TensorBuffers are not supported. Please create ` + `a TensorBuffer for the real and imaginary parts separately and ` + `call tf.complex(real, imag).`);\n    }\n\n    this.values = values || util.getArrayFromDType(dtype, this.size);\n    this.strides = computeStrides(shape);\n  }\n  /**\n   * Sets a value in the buffer at a given location.\n   *\n   * @param value The value to set.\n   * @param locs  The location indices.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n\n\n  set(value, ...locs) {\n    if (locs.length === 0) {\n      locs = [0];\n    }\n\n    util.assert(locs.length === this.rank, () => `The number of provided coordinates (${locs.length}) must ` + `match the rank (${this.rank})`);\n    const index = this.locToIndex(locs);\n    this.values[index] = value;\n  }\n  /**\n   * Returns the value in the buffer at the provided location.\n   *\n   * @param locs The location indices.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n\n\n  get(...locs) {\n    if (locs.length === 0) {\n      locs = [0];\n    }\n\n    let i = 0;\n\n    for (const loc of locs) {\n      if (loc < 0 || loc >= this.shape[i]) {\n        const msg = `Requested out of range element at ${locs}. ` + `  Buffer shape=${this.shape}`;\n        throw new Error(msg);\n      }\n\n      i++;\n    }\n\n    let index = locs[locs.length - 1];\n\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n\n    return this.values[index];\n  }\n\n  locToIndex(locs) {\n    if (this.rank === 0) {\n      return 0;\n    } else if (this.rank === 1) {\n      return locs[0];\n    }\n\n    let index = locs[locs.length - 1];\n\n    for (let i = 0; i < locs.length - 1; ++i) {\n      index += this.strides[i] * locs[i];\n    }\n\n    return index;\n  }\n\n  indexToLoc(index) {\n    if (this.rank === 0) {\n      return [];\n    } else if (this.rank === 1) {\n      return [index];\n    }\n\n    const locs = new Array(this.shape.length);\n\n    for (let i = 0; i < locs.length - 1; ++i) {\n      locs[i] = Math.floor(index / this.strides[i]);\n      index -= locs[i] * this.strides[i];\n    }\n\n    locs[locs.length - 1] = index;\n    return locs;\n  }\n\n  get rank() {\n    return this.shape.length;\n  }\n  /**\n   * Creates an immutable `tf.Tensor` object from the buffer.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Creation'}\n   */\n\n\n  toTensor() {\n    return trackerFn().makeTensor(this.values, this.shape, this.dtype);\n  }\n\n} // For tracking tensor creation and disposal.\n\nlet trackerFn = null; // Used by chaining methods to call into ops.\n\nlet opHandler = null; // Used to warn about deprecated methods.\n\nlet deprecationWarningFn = null; // This here so that we can use this method on dev branches and keep the\n// functionality at master.\n// tslint:disable-next-line:no-unused-expression\n\n[deprecationWarningFn];\n/**\n * An external consumer can register itself as the tensor tracker. This way\n * the Tensor class can notify the tracker for every tensor created and\n * disposed.\n */\n\nexport function setTensorTracker(fn) {\n  trackerFn = fn;\n}\n/**\n * An external consumer can register itself as the op handler. This way the\n * Tensor class can have chaining methods that call into ops via the op\n * handler.\n */\n\nexport function setOpHandler(handler) {\n  opHandler = handler;\n}\n/**\n * Sets the deprecation warning function to be used by this file. This way the\n * Tensor class can be a leaf but still use the environment.\n */\n\nexport function setDeprecationWarningFn(fn) {\n  deprecationWarningFn = fn;\n}\n/**\n * A `tf.Tensor` object represents an immutable, multidimensional array of\n * numbers that has a shape and a data type.\n *\n * For performance reasons, functions that create tensors do not necessarily\n * perform a copy of the data passed to them (e.g. if the data is passed as a\n * `Float32Array`), and changes to the data will change the tensor. This is not\n * a feature and is not supported. To avoid this behavior, use the tensor before\n * changing the input data or create a copy with `copy = tf.add(yourTensor, 0)`.\n *\n * See `tf.tensor` for details on how to create a `tf.Tensor`.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\n\nexport class Tensor {\n  constructor(shape, dtype, dataId, id) {\n    /** Whether this tensor has been globally kept. */\n    this.kept = false;\n    this.isDisposedInternal = false;\n    this.shape = shape.slice();\n    this.dtype = dtype || 'float32';\n    this.size = util.sizeFromShape(shape);\n    this.strides = computeStrides(shape);\n    this.dataId = dataId;\n    this.id = id;\n    this.rankType = this.rank < 5 ? this.rank.toString() : 'higher';\n  }\n\n  get rank() {\n    return this.shape.length;\n  }\n  /**\n   * Returns a promise of `tf.TensorBuffer` that holds the underlying data.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  buffer() {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      const vals = yield _this.data();\n      return opHandler.buffer(_this.shape, _this.dtype, vals);\n    })();\n  }\n  /**\n   * Returns a `tf.TensorBuffer` that holds the underlying data.\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  bufferSync() {\n    return opHandler.buffer(this.shape, this.dtype, this.dataSync());\n  }\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * asynchronously.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  array() {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      const vals = yield _this2.data();\n      return toNestedArray(_this2.shape, vals, _this2.dtype === 'complex64');\n    })();\n  }\n  /**\n   * Returns the tensor data as a nested array. The transfer of data is done\n   * synchronously.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  arraySync() {\n    return toNestedArray(this.shape, this.dataSync(), this.dtype === 'complex64');\n  }\n  /**\n   * Asynchronously downloads the values from the `tf.Tensor`. Returns a\n   * promise of `TypedArray` that resolves when the computation has finished.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  data() {\n    var _this3 = this;\n\n    return _asyncToGenerator(function* () {\n      _this3.throwIfDisposed();\n\n      const data = trackerFn().read(_this3.dataId);\n\n      if (_this3.dtype === 'string') {\n        const bytes = yield data;\n\n        try {\n          return bytes.map(b => util.decodeString(b));\n        } catch (_a) {\n          throw new Error('Failed to decode the string bytes into utf-8. ' + 'To get the original bytes, call tensor.bytes().');\n        }\n      }\n\n      return data;\n    })();\n  }\n  /**\n   * Copy the tensor's data to a new GPU resource. Comparing to the `dataSync()`\n   * and `data()`, this method prevents data from being downloaded to CPU.\n   *\n   * For WebGL backend, the data will be stored on a densely packed texture.\n   * This means that the texture will use the RGBA channels to store value.\n   *\n   * For WebGPU backend, the data will be stored on a buffer. There is no\n   * parameter, so can not use a user-defined size to create the buffer.\n   *\n   * @param options:\n   *     For WebGL,\n   *         - customTexShape: Optional. If set, will use the user defined\n   *     texture shape to create the texture.\n   *\n   * @returns For WebGL backend, a GPUData contains the new texture and\n   *     its information.\n   *     {\n   *        tensorRef: The tensor that is associated with this texture,\n   *        texture: WebGLTexture,\n   *        texShape: [number, number] // [height, width]\n   *     }\n   *\n   *     For WebGPU backend, a GPUData contains the new buffer and\n   *     its information.\n   *     {\n   *        tensorRef: The tensor that is associated with this buffer,\n   *        buffer: GPUBuffer,\n   *        bufSize: number\n   *     }\n   *\n   *     Remember to dispose the GPUData after it is used by\n   *     `res.tensorRef.dispose()`.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  dataToGPU(options) {\n    this.throwIfDisposed();\n    return trackerFn().readToGPU(this.dataId, options);\n  }\n  /**\n   * Synchronously downloads the values from the `tf.Tensor`. This blocks the\n   * UI thread until the values are ready, which can cause performance issues.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  dataSync() {\n    this.throwIfDisposed();\n    const data = trackerFn().readSync(this.dataId);\n\n    if (this.dtype === 'string') {\n      try {\n        return data.map(b => util.decodeString(b));\n      } catch (_a) {\n        throw new Error('Failed to decode the string bytes into utf-8. ' + 'To get the original bytes, call tensor.bytes().');\n      }\n    }\n\n    return data;\n  }\n  /** Returns the underlying bytes of the tensor's data. */\n\n\n  bytes() {\n    var _this4 = this;\n\n    return _asyncToGenerator(function* () {\n      _this4.throwIfDisposed();\n\n      const data = yield trackerFn().read(_this4.dataId);\n\n      if (_this4.dtype === 'string') {\n        return data;\n      } else {\n        return new Uint8Array(data.buffer);\n      }\n    })();\n  }\n  /**\n   * Disposes `tf.Tensor` from memory.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  dispose() {\n    if (this.isDisposed) {\n      return;\n    }\n\n    trackerFn().disposeTensor(this);\n    this.isDisposedInternal = true;\n  }\n\n  get isDisposed() {\n    return this.isDisposedInternal;\n  }\n\n  throwIfDisposed() {\n    if (this.isDisposed) {\n      throw new Error(`Tensor is disposed.`);\n    }\n  }\n  /**\n   * Prints the `tf.Tensor`. See `tf.print` for details.\n   *\n   * @param verbose Whether to print verbose information about the tensor,\n   *    including dtype and size.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  print(verbose = false) {\n    return opHandler.print(this, verbose);\n  }\n  /**\n   * Returns a copy of the tensor. See `tf.clone` for details.\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  clone() {\n    this.throwIfDisposed();\n    return opHandler.clone(this);\n  }\n  /**\n   * Returns a human-readable description of the tensor. Useful for logging.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  toString(verbose = false) {\n    const vals = this.dataSync();\n    return tensorToString(vals, this.shape, this.dtype, verbose);\n  }\n\n  cast(dtype) {\n    this.throwIfDisposed();\n    return opHandler.cast(this, dtype);\n  }\n\n  variable(trainable = true, name, dtype) {\n    this.throwIfDisposed();\n    return trackerFn().makeVariable(this, trainable, name, dtype);\n  }\n\n}\nObject.defineProperty(Tensor, Symbol.hasInstance, {\n  value: instance => {\n    // Implementation note: we should use properties of the object that will be\n    // defined before the constructor body has finished executing (methods).\n    // This is because when this code is transpiled by babel, babel will call\n    // classCallCheck before the constructor body is run.\n    // See https://github.com/tensorflow/tfjs/issues/3384 for backstory.\n    return !!instance && instance.data != null && instance.dataSync != null && instance.throwIfDisposed != null;\n  }\n});\nexport function getGlobalTensorClass() {\n  // Use getGlobal so that we can augment the Tensor class across package\n  // boundaries becase the node resolution alg may result in different modules\n  // being returned for this file depending on the path they are loaded from.\n  return getGlobal('Tensor', () => {\n    return Tensor;\n  });\n} // Global side effect. Cache global reference to Tensor class\n\ngetGlobalTensorClass();\n/**\n * A mutable `tf.Tensor`, useful for persisting state, e.g. for training.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\n\nexport class Variable extends Tensor {\n  constructor(initialValue, trainable, name, tensorId) {\n    super(initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);\n    this.trainable = trainable;\n    this.name = name;\n  }\n  /**\n   * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have\n   * the same shape and dtype as the old `tf.Tensor`.\n   *\n   * @param newValue New tensor to be assigned to this variable.\n   *\n   * @doc {heading: 'Tensors', subheading: 'Classes'}\n   */\n\n\n  assign(newValue) {\n    if (newValue.dtype !== this.dtype) {\n      throw new Error(`dtype of the new value (${newValue.dtype}) and ` + `previous value (${this.dtype}) must match`);\n    }\n\n    if (!util.arraysEqual(newValue.shape, this.shape)) {\n      throw new Error(`shape of the new value (${newValue.shape}) and ` + `previous value (${this.shape}) must match`);\n    }\n\n    trackerFn().disposeTensor(this);\n    this.dataId = newValue.dataId;\n    trackerFn().incRef(this, null\n    /* backend */\n    );\n  }\n\n  dispose() {\n    trackerFn().disposeVariable(this);\n    this.isDisposedInternal = true;\n  }\n\n}\nObject.defineProperty(Variable, Symbol.hasInstance, {\n  value: instance => {\n    return instance instanceof Tensor && instance.assign != null && instance.assign instanceof Function;\n  }\n});","map":{"version":3,"names":["getGlobal","tensorToString","util","computeStrides","toNestedArray","TensorBuffer","constructor","shape","dtype","values","slice","size","sizeFromShape","n","length","assert","Error","getArrayFromDType","strides","set","value","locs","rank","index","locToIndex","get","i","loc","msg","indexToLoc","Array","Math","floor","toTensor","trackerFn","makeTensor","opHandler","deprecationWarningFn","setTensorTracker","fn","setOpHandler","handler","setDeprecationWarningFn","Tensor","dataId","id","kept","isDisposedInternal","rankType","toString","buffer","vals","data","bufferSync","dataSync","array","arraySync","throwIfDisposed","read","bytes","map","b","decodeString","_a","dataToGPU","options","readToGPU","readSync","Uint8Array","dispose","isDisposed","disposeTensor","print","verbose","clone","cast","variable","trainable","name","makeVariable","Object","defineProperty","Symbol","hasInstance","instance","getGlobalTensorClass","Variable","initialValue","tensorId","assign","newValue","arraysEqual","incRef","disposeVariable","Function"],"sources":["C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@tensorflow/tfjs-core/dist/tensor.js"],"sourcesContent":["/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Workaround for: https://github.com/bazelbuild/rules_nodejs/issues/1265\n/// <reference types=\"@webgpu/types/dist\" />\nimport { getGlobal } from './global_util';\nimport { tensorToString } from './tensor_format';\nimport * as util from './util';\nimport { computeStrides, toNestedArray } from './util';\n/**\n * A mutable object, similar to `tf.Tensor`, that allows users to set values\n * at locations before converting to an immutable `tf.Tensor`.\n *\n * See `tf.buffer` for creating a tensor buffer.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class TensorBuffer {\n    constructor(shape, dtype, values) {\n        this.dtype = dtype;\n        this.shape = shape.slice();\n        this.size = util.sizeFromShape(shape);\n        if (values != null) {\n            const n = values.length;\n            util.assert(n === this.size, () => `Length of values '${n}' does not match the size ` +\n                `inferred by the shape '${this.size}'.`);\n        }\n        if (dtype === 'complex64') {\n            throw new Error(`complex64 dtype TensorBuffers are not supported. Please create ` +\n                `a TensorBuffer for the real and imaginary parts separately and ` +\n                `call tf.complex(real, imag).`);\n        }\n        this.values = values || util.getArrayFromDType(dtype, this.size);\n        this.strides = computeStrides(shape);\n    }\n    /**\n     * Sets a value in the buffer at a given location.\n     *\n     * @param value The value to set.\n     * @param locs  The location indices.\n     *\n     * @doc {heading: 'Tensors', subheading: 'Creation'}\n     */\n    set(value, ...locs) {\n        if (locs.length === 0) {\n            locs = [0];\n        }\n        util.assert(locs.length === this.rank, () => `The number of provided coordinates (${locs.length}) must ` +\n            `match the rank (${this.rank})`);\n        const index = this.locToIndex(locs);\n        this.values[index] = value;\n    }\n    /**\n     * Returns the value in the buffer at the provided location.\n     *\n     * @param locs The location indices.\n     *\n     * @doc {heading: 'Tensors', subheading: 'Creation'}\n     */\n    get(...locs) {\n        if (locs.length === 0) {\n            locs = [0];\n        }\n        let i = 0;\n        for (const loc of locs) {\n            if (loc < 0 || loc >= this.shape[i]) {\n                const msg = `Requested out of range element at ${locs}. ` +\n                    `  Buffer shape=${this.shape}`;\n                throw new Error(msg);\n            }\n            i++;\n        }\n        let index = locs[locs.length - 1];\n        for (let i = 0; i < locs.length - 1; ++i) {\n            index += this.strides[i] * locs[i];\n        }\n        return this.values[index];\n    }\n    locToIndex(locs) {\n        if (this.rank === 0) {\n            return 0;\n        }\n        else if (this.rank === 1) {\n            return locs[0];\n        }\n        let index = locs[locs.length - 1];\n        for (let i = 0; i < locs.length - 1; ++i) {\n            index += this.strides[i] * locs[i];\n        }\n        return index;\n    }\n    indexToLoc(index) {\n        if (this.rank === 0) {\n            return [];\n        }\n        else if (this.rank === 1) {\n            return [index];\n        }\n        const locs = new Array(this.shape.length);\n        for (let i = 0; i < locs.length - 1; ++i) {\n            locs[i] = Math.floor(index / this.strides[i]);\n            index -= locs[i] * this.strides[i];\n        }\n        locs[locs.length - 1] = index;\n        return locs;\n    }\n    get rank() {\n        return this.shape.length;\n    }\n    /**\n     * Creates an immutable `tf.Tensor` object from the buffer.\n     *\n     * @doc {heading: 'Tensors', subheading: 'Creation'}\n     */\n    toTensor() {\n        return trackerFn().makeTensor(this.values, this.shape, this.dtype);\n    }\n}\n// For tracking tensor creation and disposal.\nlet trackerFn = null;\n// Used by chaining methods to call into ops.\nlet opHandler = null;\n// Used to warn about deprecated methods.\nlet deprecationWarningFn = null;\n// This here so that we can use this method on dev branches and keep the\n// functionality at master.\n// tslint:disable-next-line:no-unused-expression\n[deprecationWarningFn];\n/**\n * An external consumer can register itself as the tensor tracker. This way\n * the Tensor class can notify the tracker for every tensor created and\n * disposed.\n */\nexport function setTensorTracker(fn) {\n    trackerFn = fn;\n}\n/**\n * An external consumer can register itself as the op handler. This way the\n * Tensor class can have chaining methods that call into ops via the op\n * handler.\n */\nexport function setOpHandler(handler) {\n    opHandler = handler;\n}\n/**\n * Sets the deprecation warning function to be used by this file. This way the\n * Tensor class can be a leaf but still use the environment.\n */\nexport function setDeprecationWarningFn(fn) {\n    deprecationWarningFn = fn;\n}\n/**\n * A `tf.Tensor` object represents an immutable, multidimensional array of\n * numbers that has a shape and a data type.\n *\n * For performance reasons, functions that create tensors do not necessarily\n * perform a copy of the data passed to them (e.g. if the data is passed as a\n * `Float32Array`), and changes to the data will change the tensor. This is not\n * a feature and is not supported. To avoid this behavior, use the tensor before\n * changing the input data or create a copy with `copy = tf.add(yourTensor, 0)`.\n *\n * See `tf.tensor` for details on how to create a `tf.Tensor`.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class Tensor {\n    constructor(shape, dtype, dataId, id) {\n        /** Whether this tensor has been globally kept. */\n        this.kept = false;\n        this.isDisposedInternal = false;\n        this.shape = shape.slice();\n        this.dtype = dtype || 'float32';\n        this.size = util.sizeFromShape(shape);\n        this.strides = computeStrides(shape);\n        this.dataId = dataId;\n        this.id = id;\n        this.rankType = (this.rank < 5 ? this.rank.toString() : 'higher');\n    }\n    get rank() {\n        return this.shape.length;\n    }\n    /**\n     * Returns a promise of `tf.TensorBuffer` that holds the underlying data.\n     *\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\n     */\n    async buffer() {\n        const vals = await this.data();\n        return opHandler.buffer(this.shape, this.dtype, vals);\n    }\n    /**\n     * Returns a `tf.TensorBuffer` that holds the underlying data.\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\n     */\n    bufferSync() {\n        return opHandler.buffer(this.shape, this.dtype, this.dataSync());\n    }\n    /**\n     * Returns the tensor data as a nested array. The transfer of data is done\n     * asynchronously.\n     *\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\n     */\n    async array() {\n        const vals = await this.data();\n        return toNestedArray(this.shape, vals, this.dtype === 'complex64');\n    }\n    /**\n     * Returns the tensor data as a nested array. The transfer of data is done\n     * synchronously.\n     *\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\n     */\n    arraySync() {\n        return toNestedArray(this.shape, this.dataSync(), this.dtype === 'complex64');\n    }\n    /**\n     * Asynchronously downloads the values from the `tf.Tensor`. Returns a\n     * promise of `TypedArray` that resolves when the computation has finished.\n     *\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\n     */\n    async data() {\n        this.throwIfDisposed();\n        const data = trackerFn().read(this.dataId);\n        if (this.dtype === 'string') {\n            const bytes = await data;\n            try {\n                return bytes.map(b => util.decodeString(b));\n            }\n            catch (_a) {\n                throw new Error('Failed to decode the string bytes into utf-8. ' +\n                    'To get the original bytes, call tensor.bytes().');\n            }\n        }\n        return data;\n    }\n    /**\n     * Copy the tensor's data to a new GPU resource. Comparing to the `dataSync()`\n     * and `data()`, this method prevents data from being downloaded to CPU.\n     *\n     * For WebGL backend, the data will be stored on a densely packed texture.\n     * This means that the texture will use the RGBA channels to store value.\n     *\n     * For WebGPU backend, the data will be stored on a buffer. There is no\n     * parameter, so can not use a user-defined size to create the buffer.\n     *\n     * @param options:\n     *     For WebGL,\n     *         - customTexShape: Optional. If set, will use the user defined\n     *     texture shape to create the texture.\n     *\n     * @returns For WebGL backend, a GPUData contains the new texture and\n     *     its information.\n     *     {\n     *        tensorRef: The tensor that is associated with this texture,\n     *        texture: WebGLTexture,\n     *        texShape: [number, number] // [height, width]\n     *     }\n     *\n     *     For WebGPU backend, a GPUData contains the new buffer and\n     *     its information.\n     *     {\n     *        tensorRef: The tensor that is associated with this buffer,\n     *        buffer: GPUBuffer,\n     *        bufSize: number\n     *     }\n     *\n     *     Remember to dispose the GPUData after it is used by\n     *     `res.tensorRef.dispose()`.\n     *\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\n     */\n    dataToGPU(options) {\n        this.throwIfDisposed();\n        return trackerFn().readToGPU(this.dataId, options);\n    }\n    /**\n     * Synchronously downloads the values from the `tf.Tensor`. This blocks the\n     * UI thread until the values are ready, which can cause performance issues.\n     *\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\n     */\n    dataSync() {\n        this.throwIfDisposed();\n        const data = trackerFn().readSync(this.dataId);\n        if (this.dtype === 'string') {\n            try {\n                return data.map(b => util.decodeString(b));\n            }\n            catch (_a) {\n                throw new Error('Failed to decode the string bytes into utf-8. ' +\n                    'To get the original bytes, call tensor.bytes().');\n            }\n        }\n        return data;\n    }\n    /** Returns the underlying bytes of the tensor's data. */\n    async bytes() {\n        this.throwIfDisposed();\n        const data = await trackerFn().read(this.dataId);\n        if (this.dtype === 'string') {\n            return data;\n        }\n        else {\n            return new Uint8Array(data.buffer);\n        }\n    }\n    /**\n     * Disposes `tf.Tensor` from memory.\n     *\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\n     */\n    dispose() {\n        if (this.isDisposed) {\n            return;\n        }\n        trackerFn().disposeTensor(this);\n        this.isDisposedInternal = true;\n    }\n    get isDisposed() {\n        return this.isDisposedInternal;\n    }\n    throwIfDisposed() {\n        if (this.isDisposed) {\n            throw new Error(`Tensor is disposed.`);\n        }\n    }\n    /**\n     * Prints the `tf.Tensor`. See `tf.print` for details.\n     *\n     * @param verbose Whether to print verbose information about the tensor,\n     *    including dtype and size.\n     *\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\n     */\n    print(verbose = false) {\n        return opHandler.print(this, verbose);\n    }\n    /**\n     * Returns a copy of the tensor. See `tf.clone` for details.\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\n     */\n    clone() {\n        this.throwIfDisposed();\n        return opHandler.clone(this);\n    }\n    /**\n     * Returns a human-readable description of the tensor. Useful for logging.\n     *\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\n     */\n    toString(verbose = false) {\n        const vals = this.dataSync();\n        return tensorToString(vals, this.shape, this.dtype, verbose);\n    }\n    cast(dtype) {\n        this.throwIfDisposed();\n        return opHandler.cast(this, dtype);\n    }\n    variable(trainable = true, name, dtype) {\n        this.throwIfDisposed();\n        return trackerFn().makeVariable(this, trainable, name, dtype);\n    }\n}\nObject.defineProperty(Tensor, Symbol.hasInstance, {\n    value: (instance) => {\n        // Implementation note: we should use properties of the object that will be\n        // defined before the constructor body has finished executing (methods).\n        // This is because when this code is transpiled by babel, babel will call\n        // classCallCheck before the constructor body is run.\n        // See https://github.com/tensorflow/tfjs/issues/3384 for backstory.\n        return !!instance && instance.data != null && instance.dataSync != null &&\n            instance.throwIfDisposed != null;\n    }\n});\nexport function getGlobalTensorClass() {\n    // Use getGlobal so that we can augment the Tensor class across package\n    // boundaries becase the node resolution alg may result in different modules\n    // being returned for this file depending on the path they are loaded from.\n    return getGlobal('Tensor', () => {\n        return Tensor;\n    });\n}\n// Global side effect. Cache global reference to Tensor class\ngetGlobalTensorClass();\n/**\n * A mutable `tf.Tensor`, useful for persisting state, e.g. for training.\n *\n * @doc {heading: 'Tensors', subheading: 'Classes'}\n */\nexport class Variable extends Tensor {\n    constructor(initialValue, trainable, name, tensorId) {\n        super(initialValue.shape, initialValue.dtype, initialValue.dataId, tensorId);\n        this.trainable = trainable;\n        this.name = name;\n    }\n    /**\n     * Assign a new `tf.Tensor` to this variable. The new `tf.Tensor` must have\n     * the same shape and dtype as the old `tf.Tensor`.\n     *\n     * @param newValue New tensor to be assigned to this variable.\n     *\n     * @doc {heading: 'Tensors', subheading: 'Classes'}\n     */\n    assign(newValue) {\n        if (newValue.dtype !== this.dtype) {\n            throw new Error(`dtype of the new value (${newValue.dtype}) and ` +\n                `previous value (${this.dtype}) must match`);\n        }\n        if (!util.arraysEqual(newValue.shape, this.shape)) {\n            throw new Error(`shape of the new value (${newValue.shape}) and ` +\n                `previous value (${this.shape}) must match`);\n        }\n        trackerFn().disposeTensor(this);\n        this.dataId = newValue.dataId;\n        trackerFn().incRef(this, null /* backend */);\n    }\n    dispose() {\n        trackerFn().disposeVariable(this);\n        this.isDisposedInternal = true;\n    }\n}\nObject.defineProperty(Variable, Symbol.hasInstance, {\n    value: (instance) => {\n        return instance instanceof Tensor && instance.assign != null &&\n            instance.assign instanceof Function;\n    }\n});\n"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,SAAT,QAA0B,eAA1B;AACA,SAASC,cAAT,QAA+B,iBAA/B;AACA,OAAO,KAAKC,IAAZ,MAAsB,QAAtB;AACA,SAASC,cAAT,EAAyBC,aAAzB,QAA8C,QAA9C;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,MAAMC,YAAN,CAAmB;EACtBC,WAAW,CAACC,KAAD,EAAQC,KAAR,EAAeC,MAAf,EAAuB;IAC9B,KAAKD,KAAL,GAAaA,KAAb;IACA,KAAKD,KAAL,GAAaA,KAAK,CAACG,KAAN,EAAb;IACA,KAAKC,IAAL,GAAYT,IAAI,CAACU,aAAL,CAAmBL,KAAnB,CAAZ;;IACA,IAAIE,MAAM,IAAI,IAAd,EAAoB;MAChB,MAAMI,CAAC,GAAGJ,MAAM,CAACK,MAAjB;MACAZ,IAAI,CAACa,MAAL,CAAYF,CAAC,KAAK,KAAKF,IAAvB,EAA6B,MAAO,qBAAoBE,CAAE,4BAAvB,GAC9B,0BAAyB,KAAKF,IAAK,IADxC;IAEH;;IACD,IAAIH,KAAK,KAAK,WAAd,EAA2B;MACvB,MAAM,IAAIQ,KAAJ,CAAW,iEAAD,GACX,iEADW,GAEX,8BAFC,CAAN;IAGH;;IACD,KAAKP,MAAL,GAAcA,MAAM,IAAIP,IAAI,CAACe,iBAAL,CAAuBT,KAAvB,EAA8B,KAAKG,IAAnC,CAAxB;IACA,KAAKO,OAAL,GAAef,cAAc,CAACI,KAAD,CAA7B;EACH;EACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;EACIY,GAAG,CAACC,KAAD,EAAQ,GAAGC,IAAX,EAAiB;IAChB,IAAIA,IAAI,CAACP,MAAL,KAAgB,CAApB,EAAuB;MACnBO,IAAI,GAAG,CAAC,CAAD,CAAP;IACH;;IACDnB,IAAI,CAACa,MAAL,CAAYM,IAAI,CAACP,MAAL,KAAgB,KAAKQ,IAAjC,EAAuC,MAAO,uCAAsCD,IAAI,CAACP,MAAO,SAAnD,GACxC,mBAAkB,KAAKQ,IAAK,GADjC;IAEA,MAAMC,KAAK,GAAG,KAAKC,UAAL,CAAgBH,IAAhB,CAAd;IACA,KAAKZ,MAAL,CAAYc,KAAZ,IAAqBH,KAArB;EACH;EACD;AACJ;AACA;AACA;AACA;AACA;AACA;;;EACIK,GAAG,CAAC,GAAGJ,IAAJ,EAAU;IACT,IAAIA,IAAI,CAACP,MAAL,KAAgB,CAApB,EAAuB;MACnBO,IAAI,GAAG,CAAC,CAAD,CAAP;IACH;;IACD,IAAIK,CAAC,GAAG,CAAR;;IACA,KAAK,MAAMC,GAAX,IAAkBN,IAAlB,EAAwB;MACpB,IAAIM,GAAG,GAAG,CAAN,IAAWA,GAAG,IAAI,KAAKpB,KAAL,CAAWmB,CAAX,CAAtB,EAAqC;QACjC,MAAME,GAAG,GAAI,qCAAoCP,IAAK,IAA1C,GACP,kBAAiB,KAAKd,KAAM,EADjC;QAEA,MAAM,IAAIS,KAAJ,CAAUY,GAAV,CAAN;MACH;;MACDF,CAAC;IACJ;;IACD,IAAIH,KAAK,GAAGF,IAAI,CAACA,IAAI,CAACP,MAAL,GAAc,CAAf,CAAhB;;IACA,KAAK,IAAIY,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGL,IAAI,CAACP,MAAL,GAAc,CAAlC,EAAqC,EAAEY,CAAvC,EAA0C;MACtCH,KAAK,IAAI,KAAKL,OAAL,CAAaQ,CAAb,IAAkBL,IAAI,CAACK,CAAD,CAA/B;IACH;;IACD,OAAO,KAAKjB,MAAL,CAAYc,KAAZ,CAAP;EACH;;EACDC,UAAU,CAACH,IAAD,EAAO;IACb,IAAI,KAAKC,IAAL,KAAc,CAAlB,EAAqB;MACjB,OAAO,CAAP;IACH,CAFD,MAGK,IAAI,KAAKA,IAAL,KAAc,CAAlB,EAAqB;MACtB,OAAOD,IAAI,CAAC,CAAD,CAAX;IACH;;IACD,IAAIE,KAAK,GAAGF,IAAI,CAACA,IAAI,CAACP,MAAL,GAAc,CAAf,CAAhB;;IACA,KAAK,IAAIY,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGL,IAAI,CAACP,MAAL,GAAc,CAAlC,EAAqC,EAAEY,CAAvC,EAA0C;MACtCH,KAAK,IAAI,KAAKL,OAAL,CAAaQ,CAAb,IAAkBL,IAAI,CAACK,CAAD,CAA/B;IACH;;IACD,OAAOH,KAAP;EACH;;EACDM,UAAU,CAACN,KAAD,EAAQ;IACd,IAAI,KAAKD,IAAL,KAAc,CAAlB,EAAqB;MACjB,OAAO,EAAP;IACH,CAFD,MAGK,IAAI,KAAKA,IAAL,KAAc,CAAlB,EAAqB;MACtB,OAAO,CAACC,KAAD,CAAP;IACH;;IACD,MAAMF,IAAI,GAAG,IAAIS,KAAJ,CAAU,KAAKvB,KAAL,CAAWO,MAArB,CAAb;;IACA,KAAK,IAAIY,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGL,IAAI,CAACP,MAAL,GAAc,CAAlC,EAAqC,EAAEY,CAAvC,EAA0C;MACtCL,IAAI,CAACK,CAAD,CAAJ,GAAUK,IAAI,CAACC,KAAL,CAAWT,KAAK,GAAG,KAAKL,OAAL,CAAaQ,CAAb,CAAnB,CAAV;MACAH,KAAK,IAAIF,IAAI,CAACK,CAAD,CAAJ,GAAU,KAAKR,OAAL,CAAaQ,CAAb,CAAnB;IACH;;IACDL,IAAI,CAACA,IAAI,CAACP,MAAL,GAAc,CAAf,CAAJ,GAAwBS,KAAxB;IACA,OAAOF,IAAP;EACH;;EACO,IAAJC,IAAI,GAAG;IACP,OAAO,KAAKf,KAAL,CAAWO,MAAlB;EACH;EACD;AACJ;AACA;AACA;AACA;;;EACImB,QAAQ,GAAG;IACP,OAAOC,SAAS,GAAGC,UAAZ,CAAuB,KAAK1B,MAA5B,EAAoC,KAAKF,KAAzC,EAAgD,KAAKC,KAArD,CAAP;EACH;;AAnGqB,C,CAqG1B;;AACA,IAAI0B,SAAS,GAAG,IAAhB,C,CACA;;AACA,IAAIE,SAAS,GAAG,IAAhB,C,CACA;;AACA,IAAIC,oBAAoB,GAAG,IAA3B,C,CACA;AACA;AACA;;AACA,CAACA,oBAAD;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,gBAAT,CAA0BC,EAA1B,EAA8B;EACjCL,SAAS,GAAGK,EAAZ;AACH;AACD;AACA;AACA;AACA;AACA;;AACA,OAAO,SAASC,YAAT,CAAsBC,OAAtB,EAA+B;EAClCL,SAAS,GAAGK,OAAZ;AACH;AACD;AACA;AACA;AACA;;AACA,OAAO,SAASC,uBAAT,CAAiCH,EAAjC,EAAqC;EACxCF,oBAAoB,GAAGE,EAAvB;AACH;AACD;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AACA,OAAO,MAAMI,MAAN,CAAa;EAChBrC,WAAW,CAACC,KAAD,EAAQC,KAAR,EAAeoC,MAAf,EAAuBC,EAAvB,EAA2B;IAClC;IACA,KAAKC,IAAL,GAAY,KAAZ;IACA,KAAKC,kBAAL,GAA0B,KAA1B;IACA,KAAKxC,KAAL,GAAaA,KAAK,CAACG,KAAN,EAAb;IACA,KAAKF,KAAL,GAAaA,KAAK,IAAI,SAAtB;IACA,KAAKG,IAAL,GAAYT,IAAI,CAACU,aAAL,CAAmBL,KAAnB,CAAZ;IACA,KAAKW,OAAL,GAAef,cAAc,CAACI,KAAD,CAA7B;IACA,KAAKqC,MAAL,GAAcA,MAAd;IACA,KAAKC,EAAL,GAAUA,EAAV;IACA,KAAKG,QAAL,GAAiB,KAAK1B,IAAL,GAAY,CAAZ,GAAgB,KAAKA,IAAL,CAAU2B,QAAV,EAAhB,GAAuC,QAAxD;EACH;;EACO,IAAJ3B,IAAI,GAAG;IACP,OAAO,KAAKf,KAAL,CAAWO,MAAlB;EACH;EACD;AACJ;AACA;AACA;AACA;;;EACUoC,MAAM,GAAG;IAAA;;IAAA;MACX,MAAMC,IAAI,SAAS,KAAI,CAACC,IAAL,EAAnB;MACA,OAAOhB,SAAS,CAACc,MAAV,CAAiB,KAAI,CAAC3C,KAAtB,EAA6B,KAAI,CAACC,KAAlC,EAAyC2C,IAAzC,CAAP;IAFW;EAGd;EACD;AACJ;AACA;AACA;;;EACIE,UAAU,GAAG;IACT,OAAOjB,SAAS,CAACc,MAAV,CAAiB,KAAK3C,KAAtB,EAA6B,KAAKC,KAAlC,EAAyC,KAAK8C,QAAL,EAAzC,CAAP;EACH;EACD;AACJ;AACA;AACA;AACA;AACA;;;EACUC,KAAK,GAAG;IAAA;;IAAA;MACV,MAAMJ,IAAI,SAAS,MAAI,CAACC,IAAL,EAAnB;MACA,OAAOhD,aAAa,CAAC,MAAI,CAACG,KAAN,EAAa4C,IAAb,EAAmB,MAAI,CAAC3C,KAAL,KAAe,WAAlC,CAApB;IAFU;EAGb;EACD;AACJ;AACA;AACA;AACA;AACA;;;EACIgD,SAAS,GAAG;IACR,OAAOpD,aAAa,CAAC,KAAKG,KAAN,EAAa,KAAK+C,QAAL,EAAb,EAA8B,KAAK9C,KAAL,KAAe,WAA7C,CAApB;EACH;EACD;AACJ;AACA;AACA;AACA;AACA;;;EACU4C,IAAI,GAAG;IAAA;;IAAA;MACT,MAAI,CAACK,eAAL;;MACA,MAAML,IAAI,GAAGlB,SAAS,GAAGwB,IAAZ,CAAiB,MAAI,CAACd,MAAtB,CAAb;;MACA,IAAI,MAAI,CAACpC,KAAL,KAAe,QAAnB,EAA6B;QACzB,MAAMmD,KAAK,SAASP,IAApB;;QACA,IAAI;UACA,OAAOO,KAAK,CAACC,GAAN,CAAUC,CAAC,IAAI3D,IAAI,CAAC4D,YAAL,CAAkBD,CAAlB,CAAf,CAAP;QACH,CAFD,CAGA,OAAOE,EAAP,EAAW;UACP,MAAM,IAAI/C,KAAJ,CAAU,mDACZ,iDADE,CAAN;QAEH;MACJ;;MACD,OAAOoC,IAAP;IAbS;EAcZ;EACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACIY,SAAS,CAACC,OAAD,EAAU;IACf,KAAKR,eAAL;IACA,OAAOvB,SAAS,GAAGgC,SAAZ,CAAsB,KAAKtB,MAA3B,EAAmCqB,OAAnC,CAAP;EACH;EACD;AACJ;AACA;AACA;AACA;AACA;;;EACIX,QAAQ,GAAG;IACP,KAAKG,eAAL;IACA,MAAML,IAAI,GAAGlB,SAAS,GAAGiC,QAAZ,CAAqB,KAAKvB,MAA1B,CAAb;;IACA,IAAI,KAAKpC,KAAL,KAAe,QAAnB,EAA6B;MACzB,IAAI;QACA,OAAO4C,IAAI,CAACQ,GAAL,CAASC,CAAC,IAAI3D,IAAI,CAAC4D,YAAL,CAAkBD,CAAlB,CAAd,CAAP;MACH,CAFD,CAGA,OAAOE,EAAP,EAAW;QACP,MAAM,IAAI/C,KAAJ,CAAU,mDACZ,iDADE,CAAN;MAEH;IACJ;;IACD,OAAOoC,IAAP;EACH;EACD;;;EACMO,KAAK,GAAG;IAAA;;IAAA;MACV,MAAI,CAACF,eAAL;;MACA,MAAML,IAAI,SAASlB,SAAS,GAAGwB,IAAZ,CAAiB,MAAI,CAACd,MAAtB,CAAnB;;MACA,IAAI,MAAI,CAACpC,KAAL,KAAe,QAAnB,EAA6B;QACzB,OAAO4C,IAAP;MACH,CAFD,MAGK;QACD,OAAO,IAAIgB,UAAJ,CAAehB,IAAI,CAACF,MAApB,CAAP;MACH;IARS;EASb;EACD;AACJ;AACA;AACA;AACA;;;EACImB,OAAO,GAAG;IACN,IAAI,KAAKC,UAAT,EAAqB;MACjB;IACH;;IACDpC,SAAS,GAAGqC,aAAZ,CAA0B,IAA1B;IACA,KAAKxB,kBAAL,GAA0B,IAA1B;EACH;;EACa,IAAVuB,UAAU,GAAG;IACb,OAAO,KAAKvB,kBAAZ;EACH;;EACDU,eAAe,GAAG;IACd,IAAI,KAAKa,UAAT,EAAqB;MACjB,MAAM,IAAItD,KAAJ,CAAW,qBAAX,CAAN;IACH;EACJ;EACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;EACIwD,KAAK,CAACC,OAAO,GAAG,KAAX,EAAkB;IACnB,OAAOrC,SAAS,CAACoC,KAAV,CAAgB,IAAhB,EAAsBC,OAAtB,CAAP;EACH;EACD;AACJ;AACA;AACA;;;EACIC,KAAK,GAAG;IACJ,KAAKjB,eAAL;IACA,OAAOrB,SAAS,CAACsC,KAAV,CAAgB,IAAhB,CAAP;EACH;EACD;AACJ;AACA;AACA;AACA;;;EACIzB,QAAQ,CAACwB,OAAO,GAAG,KAAX,EAAkB;IACtB,MAAMtB,IAAI,GAAG,KAAKG,QAAL,EAAb;IACA,OAAOrD,cAAc,CAACkD,IAAD,EAAO,KAAK5C,KAAZ,EAAmB,KAAKC,KAAxB,EAA+BiE,OAA/B,CAArB;EACH;;EACDE,IAAI,CAACnE,KAAD,EAAQ;IACR,KAAKiD,eAAL;IACA,OAAOrB,SAAS,CAACuC,IAAV,CAAe,IAAf,EAAqBnE,KAArB,CAAP;EACH;;EACDoE,QAAQ,CAACC,SAAS,GAAG,IAAb,EAAmBC,IAAnB,EAAyBtE,KAAzB,EAAgC;IACpC,KAAKiD,eAAL;IACA,OAAOvB,SAAS,GAAG6C,YAAZ,CAAyB,IAAzB,EAA+BF,SAA/B,EAA0CC,IAA1C,EAAgDtE,KAAhD,CAAP;EACH;;AAtMe;AAwMpBwE,MAAM,CAACC,cAAP,CAAsBtC,MAAtB,EAA8BuC,MAAM,CAACC,WAArC,EAAkD;EAC9C/D,KAAK,EAAGgE,QAAD,IAAc;IACjB;IACA;IACA;IACA;IACA;IACA,OAAO,CAAC,CAACA,QAAF,IAAcA,QAAQ,CAAChC,IAAT,IAAiB,IAA/B,IAAuCgC,QAAQ,CAAC9B,QAAT,IAAqB,IAA5D,IACH8B,QAAQ,CAAC3B,eAAT,IAA4B,IADhC;EAEH;AAT6C,CAAlD;AAWA,OAAO,SAAS4B,oBAAT,GAAgC;EACnC;EACA;EACA;EACA,OAAOrF,SAAS,CAAC,QAAD,EAAW,MAAM;IAC7B,OAAO2C,MAAP;EACH,CAFe,CAAhB;AAGH,C,CACD;;AACA0C,oBAAoB;AACpB;AACA;AACA;AACA;AACA;;AACA,OAAO,MAAMC,QAAN,SAAuB3C,MAAvB,CAA8B;EACjCrC,WAAW,CAACiF,YAAD,EAAeV,SAAf,EAA0BC,IAA1B,EAAgCU,QAAhC,EAA0C;IACjD,MAAMD,YAAY,CAAChF,KAAnB,EAA0BgF,YAAY,CAAC/E,KAAvC,EAA8C+E,YAAY,CAAC3C,MAA3D,EAAmE4C,QAAnE;IACA,KAAKX,SAAL,GAAiBA,SAAjB;IACA,KAAKC,IAAL,GAAYA,IAAZ;EACH;EACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;;;EACIW,MAAM,CAACC,QAAD,EAAW;IACb,IAAIA,QAAQ,CAAClF,KAAT,KAAmB,KAAKA,KAA5B,EAAmC;MAC/B,MAAM,IAAIQ,KAAJ,CAAW,2BAA0B0E,QAAQ,CAAClF,KAAM,QAA1C,GACX,mBAAkB,KAAKA,KAAM,cAD5B,CAAN;IAEH;;IACD,IAAI,CAACN,IAAI,CAACyF,WAAL,CAAiBD,QAAQ,CAACnF,KAA1B,EAAiC,KAAKA,KAAtC,CAAL,EAAmD;MAC/C,MAAM,IAAIS,KAAJ,CAAW,2BAA0B0E,QAAQ,CAACnF,KAAM,QAA1C,GACX,mBAAkB,KAAKA,KAAM,cAD5B,CAAN;IAEH;;IACD2B,SAAS,GAAGqC,aAAZ,CAA0B,IAA1B;IACA,KAAK3B,MAAL,GAAc8C,QAAQ,CAAC9C,MAAvB;IACAV,SAAS,GAAG0D,MAAZ,CAAmB,IAAnB,EAAyB;IAAK;IAA9B;EACH;;EACDvB,OAAO,GAAG;IACNnC,SAAS,GAAG2D,eAAZ,CAA4B,IAA5B;IACA,KAAK9C,kBAAL,GAA0B,IAA1B;EACH;;AA9BgC;AAgCrCiC,MAAM,CAACC,cAAP,CAAsBK,QAAtB,EAAgCJ,MAAM,CAACC,WAAvC,EAAoD;EAChD/D,KAAK,EAAGgE,QAAD,IAAc;IACjB,OAAOA,QAAQ,YAAYzC,MAApB,IAA8ByC,QAAQ,CAACK,MAAT,IAAmB,IAAjD,IACHL,QAAQ,CAACK,MAAT,YAA2BK,QAD/B;EAEH;AAJ+C,CAApD"},"metadata":{},"sourceType":"module"}