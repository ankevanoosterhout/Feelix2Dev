{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { FusedConv2D } from '@tensorflow/tfjs-core';\nimport { applyActivation } from '../utils/fused_utils';\nimport { add } from './Add';\nimport { conv2D } from './Conv2D';\nimport { reshape } from './Reshape';\nexport function fusedConv2D(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x,\n    filter,\n    bias,\n    preluActivationWeights\n  } = inputs;\n  const {\n    strides,\n    pad,\n    dataFormat,\n    dilations,\n    dimRoundingMode,\n    activation,\n    leakyreluAlpha\n  } = attrs;\n  let result = conv2D({\n    inputs: {\n      x,\n      filter\n    },\n    backend,\n    attrs: {\n      strides,\n      pad,\n      dataFormat,\n      dilations,\n      dimRoundingMode\n    }\n  });\n\n  if (bias) {\n    const resultOld = result; // For NCHW format, if bias is a 1-D tensor, it is supposed to be aligned\n    // to the channel of the conv2d's result; if the bias is a scalar, the\n    // bias_add is computed as if the bias was broadcasted to the shape of the\n    // conv2d's result.\n\n    if (dataFormat === 'NCHW' && bias.shape.length === 1 && bias.shape[0] !== 1) {\n      const reshapedBias = reshape({\n        inputs: {\n          x: bias\n        },\n        backend,\n        attrs: {\n          shape: [bias.shape[0], 1, 1]\n        }\n      });\n      result = add({\n        inputs: {\n          a: result,\n          b: reshapedBias\n        },\n        backend\n      });\n      backend.disposeIntermediateTensorInfo(reshapedBias);\n    } else {\n      // This condition handles NHWC and NCHW (scalar case). The only other case\n      // for NCHW (1D case) is handled above.\n      result = add({\n        inputs: {\n          a: result,\n          b: bias\n        },\n        backend\n      });\n    }\n\n    backend.disposeIntermediateTensorInfo(resultOld);\n  }\n\n  if (activation) {\n    const resultOld = result; // For NCHW format, if PReLu activation weights is a 1-D tensor, it is\n    // supposed to be aligned with the channel of the conv2d's result. For other\n    // cases, whether NCHW or NHWC data format, the conv2d result is\n    // already aligned with the activation weights.\n\n    if (dataFormat === 'NCHW' && activation === 'prelu' && preluActivationWeights.shape.length === 1 && preluActivationWeights.shape[0] !== 1) {\n      const reshapedAlpha = reshape({\n        inputs: {\n          x: preluActivationWeights\n        },\n        backend,\n        attrs: {\n          shape: [preluActivationWeights.shape[0], 1, 1]\n        }\n      });\n      result = applyActivation(backend, result, activation, reshapedAlpha, leakyreluAlpha);\n      backend.disposeIntermediateTensorInfo(reshapedAlpha);\n    } else {\n      result = applyActivation(backend, result, activation, preluActivationWeights, leakyreluAlpha);\n    }\n\n    backend.disposeIntermediateTensorInfo(resultOld);\n  }\n\n  return result;\n}\nexport const fusedConv2DConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'cpu',\n  kernelFunc: fusedConv2D\n};","map":{"version":3,"names":["FusedConv2D","applyActivation","add","conv2D","reshape","fusedConv2D","args","inputs","backend","attrs","x","filter","bias","preluActivationWeights","strides","pad","dataFormat","dilations","dimRoundingMode","activation","leakyreluAlpha","result","resultOld","shape","length","reshapedBias","a","b","disposeIntermediateTensorInfo","reshapedAlpha","fusedConv2DConfig","kernelName","backendName","kernelFunc"],"sources":["C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@tensorflow/tfjs-backend-cpu/dist/kernels/FusedConv2D.js"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { FusedConv2D } from '@tensorflow/tfjs-core';\nimport { applyActivation } from '../utils/fused_utils';\nimport { add } from './Add';\nimport { conv2D } from './Conv2D';\nimport { reshape } from './Reshape';\nexport function fusedConv2D(args) {\n    const { inputs, backend, attrs } = args;\n    const { x, filter, bias, preluActivationWeights } = inputs;\n    const { strides, pad, dataFormat, dilations, dimRoundingMode, activation, leakyreluAlpha } = attrs;\n    let result = conv2D({\n        inputs: { x, filter },\n        backend,\n        attrs: { strides, pad, dataFormat, dilations, dimRoundingMode }\n    });\n    if (bias) {\n        const resultOld = result;\n        // For NCHW format, if bias is a 1-D tensor, it is supposed to be aligned\n        // to the channel of the conv2d's result; if the bias is a scalar, the\n        // bias_add is computed as if the bias was broadcasted to the shape of the\n        // conv2d's result.\n        if (dataFormat === 'NCHW' && bias.shape.length === 1 &&\n            bias.shape[0] !== 1) {\n            const reshapedBias = reshape({ inputs: { x: bias }, backend, attrs: { shape: [bias.shape[0], 1, 1] } });\n            result =\n                add({ inputs: { a: result, b: reshapedBias }, backend });\n            backend.disposeIntermediateTensorInfo(reshapedBias);\n        }\n        else {\n            // This condition handles NHWC and NCHW (scalar case). The only other case\n            // for NCHW (1D case) is handled above.\n            result = add({ inputs: { a: result, b: bias }, backend });\n        }\n        backend.disposeIntermediateTensorInfo(resultOld);\n    }\n    if (activation) {\n        const resultOld = result;\n        // For NCHW format, if PReLu activation weights is a 1-D tensor, it is\n        // supposed to be aligned with the channel of the conv2d's result. For other\n        // cases, whether NCHW or NHWC data format, the conv2d result is\n        // already aligned with the activation weights.\n        if (dataFormat === 'NCHW' && activation === 'prelu' &&\n            preluActivationWeights.shape.length === 1 &&\n            preluActivationWeights.shape[0] !== 1) {\n            const reshapedAlpha = reshape({\n                inputs: { x: preluActivationWeights },\n                backend,\n                attrs: { shape: [preluActivationWeights.shape[0], 1, 1] }\n            });\n            result = applyActivation(backend, result, activation, reshapedAlpha, leakyreluAlpha);\n            backend.disposeIntermediateTensorInfo(reshapedAlpha);\n        }\n        else {\n            result = applyActivation(backend, result, activation, preluActivationWeights, leakyreluAlpha);\n        }\n        backend.disposeIntermediateTensorInfo(resultOld);\n    }\n    return result;\n}\nexport const fusedConv2DConfig = {\n    kernelName: FusedConv2D,\n    backendName: 'cpu',\n    kernelFunc: fusedConv2D\n};\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,WAAT,QAA4B,uBAA5B;AACA,SAASC,eAAT,QAAgC,sBAAhC;AACA,SAASC,GAAT,QAAoB,OAApB;AACA,SAASC,MAAT,QAAuB,UAAvB;AACA,SAASC,OAAT,QAAwB,WAAxB;AACA,OAAO,SAASC,WAAT,CAAqBC,IAArB,EAA2B;EAC9B,MAAM;IAAEC,MAAF;IAAUC,OAAV;IAAmBC;EAAnB,IAA6BH,IAAnC;EACA,MAAM;IAAEI,CAAF;IAAKC,MAAL;IAAaC,IAAb;IAAmBC;EAAnB,IAA8CN,MAApD;EACA,MAAM;IAAEO,OAAF;IAAWC,GAAX;IAAgBC,UAAhB;IAA4BC,SAA5B;IAAuCC,eAAvC;IAAwDC,UAAxD;IAAoEC;EAApE,IAAuFX,KAA7F;EACA,IAAIY,MAAM,GAAGlB,MAAM,CAAC;IAChBI,MAAM,EAAE;MAAEG,CAAF;MAAKC;IAAL,CADQ;IAEhBH,OAFgB;IAGhBC,KAAK,EAAE;MAAEK,OAAF;MAAWC,GAAX;MAAgBC,UAAhB;MAA4BC,SAA5B;MAAuCC;IAAvC;EAHS,CAAD,CAAnB;;EAKA,IAAIN,IAAJ,EAAU;IACN,MAAMU,SAAS,GAAGD,MAAlB,CADM,CAEN;IACA;IACA;IACA;;IACA,IAAIL,UAAU,KAAK,MAAf,IAAyBJ,IAAI,CAACW,KAAL,CAAWC,MAAX,KAAsB,CAA/C,IACAZ,IAAI,CAACW,KAAL,CAAW,CAAX,MAAkB,CADtB,EACyB;MACrB,MAAME,YAAY,GAAGrB,OAAO,CAAC;QAAEG,MAAM,EAAE;UAAEG,CAAC,EAAEE;QAAL,CAAV;QAAuBJ,OAAvB;QAAgCC,KAAK,EAAE;UAAEc,KAAK,EAAE,CAACX,IAAI,CAACW,KAAL,CAAW,CAAX,CAAD,EAAgB,CAAhB,EAAmB,CAAnB;QAAT;MAAvC,CAAD,CAA5B;MACAF,MAAM,GACFnB,GAAG,CAAC;QAAEK,MAAM,EAAE;UAAEmB,CAAC,EAAEL,MAAL;UAAaM,CAAC,EAAEF;QAAhB,CAAV;QAA0CjB;MAA1C,CAAD,CADP;MAEAA,OAAO,CAACoB,6BAAR,CAAsCH,YAAtC;IACH,CAND,MAOK;MACD;MACA;MACAJ,MAAM,GAAGnB,GAAG,CAAC;QAAEK,MAAM,EAAE;UAAEmB,CAAC,EAAEL,MAAL;UAAaM,CAAC,EAAEf;QAAhB,CAAV;QAAkCJ;MAAlC,CAAD,CAAZ;IACH;;IACDA,OAAO,CAACoB,6BAAR,CAAsCN,SAAtC;EACH;;EACD,IAAIH,UAAJ,EAAgB;IACZ,MAAMG,SAAS,GAAGD,MAAlB,CADY,CAEZ;IACA;IACA;IACA;;IACA,IAAIL,UAAU,KAAK,MAAf,IAAyBG,UAAU,KAAK,OAAxC,IACAN,sBAAsB,CAACU,KAAvB,CAA6BC,MAA7B,KAAwC,CADxC,IAEAX,sBAAsB,CAACU,KAAvB,CAA6B,CAA7B,MAAoC,CAFxC,EAE2C;MACvC,MAAMM,aAAa,GAAGzB,OAAO,CAAC;QAC1BG,MAAM,EAAE;UAAEG,CAAC,EAAEG;QAAL,CADkB;QAE1BL,OAF0B;QAG1BC,KAAK,EAAE;UAAEc,KAAK,EAAE,CAACV,sBAAsB,CAACU,KAAvB,CAA6B,CAA7B,CAAD,EAAkC,CAAlC,EAAqC,CAArC;QAAT;MAHmB,CAAD,CAA7B;MAKAF,MAAM,GAAGpB,eAAe,CAACO,OAAD,EAAUa,MAAV,EAAkBF,UAAlB,EAA8BU,aAA9B,EAA6CT,cAA7C,CAAxB;MACAZ,OAAO,CAACoB,6BAAR,CAAsCC,aAAtC;IACH,CAVD,MAWK;MACDR,MAAM,GAAGpB,eAAe,CAACO,OAAD,EAAUa,MAAV,EAAkBF,UAAlB,EAA8BN,sBAA9B,EAAsDO,cAAtD,CAAxB;IACH;;IACDZ,OAAO,CAACoB,6BAAR,CAAsCN,SAAtC;EACH;;EACD,OAAOD,MAAP;AACH;AACD,OAAO,MAAMS,iBAAiB,GAAG;EAC7BC,UAAU,EAAE/B,WADiB;EAE7BgC,WAAW,EAAE,KAFgB;EAG7BC,UAAU,EAAE5B;AAHiB,CAA1B"},"metadata":{},"sourceType":"module"}