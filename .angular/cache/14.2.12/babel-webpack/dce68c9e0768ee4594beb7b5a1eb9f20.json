{"ast":null,"code":"import _asyncToGenerator from \"C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@babel/runtime/helpers/esm/asyncToGenerator.js\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, tidy, util } from '@tensorflow/tfjs-core';\nimport { getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName } from '../operations/executors/utils';\nimport { executeOp } from '../operations/operation_executor';\nimport { ExecutionContext } from './execution_context';\nimport { getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow } from './model_analysis';\nexport class GraphExecutor {\n  /**\n   *\n   * @param graph Graph the model or function graph to be executed.\n   * @param parent When building function exector you need to set the parent\n   * executor. Since the weights and function executor maps are set at parant\n   * level, that function executor can access the function maps and weight maps\n   * through the parent.\n   */\n  constructor(graph, parent) {\n    this.graph = graph;\n    this.parent = parent;\n    this.compiledMap = new Map();\n    this._weightMap = {};\n    this.SEPERATOR = ',';\n    this._functions = {};\n    this._functionExecutorMap = {};\n    this.intermediateTensors = {};\n    this.keepTensorForDebug = false;\n    this._outputs = graph.outputs;\n    this._inputs = graph.inputs;\n    this._initNodes = graph.initNodes;\n    this._signature = graph.signature;\n    this._functions = graph.functions; // create sub-graph executors\n\n    if (graph.functions != null) {\n      Object.keys(graph.functions).forEach(name => {\n        this._functionExecutorMap[name] = new GraphExecutor(graph.functions[name], this);\n      });\n    }\n  }\n\n  get weightIds() {\n    return this.parent ? this.parent.weightIds : this._weightIds;\n  }\n\n  get functionExecutorMap() {\n    return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;\n  }\n\n  get weightMap() {\n    return this.parent ? this.parent.weightMap : this._weightMap;\n  }\n\n  set weightMap(weightMap) {\n    const weightIds = Object.keys(weightMap).map(key => weightMap[key].map(tensor => tensor.id));\n    this._weightIds = [].concat(...weightIds);\n    this._weightMap = weightMap;\n  }\n  /**\n   * Set `ResourceManager` shared by executors of a model.\n   * @param resourceManager: `ResourceManager` of the `GraphModel`.\n   */\n\n\n  set resourceManager(resourceManager) {\n    this._resourceManager = resourceManager;\n  }\n\n  get inputs() {\n    return this._inputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ? node.attrParams['shape'].value : undefined,\n        dtype: node.attrParams['dtype'] ? node.attrParams['dtype'].value : undefined\n      };\n    });\n  }\n\n  get outputs() {\n    return this._outputs.map(node => {\n      return {\n        name: node.name,\n        shape: node.attrParams['shape'] ? node.attrParams['shape'].value : undefined,\n        dtype: node.attrParams['dtype'] ? node.attrParams['dtype'].value : undefined\n      };\n    });\n  }\n\n  get inputNodes() {\n    return this._inputs.map(node => node.signatureKey || node.name);\n  }\n\n  get outputNodes() {\n    return this._outputs.map(node => {\n      const name = node.signatureKey || node.name;\n      return node.defaultOutput ? `${name}:${node.defaultOutput}` : name;\n    });\n  }\n\n  get functions() {\n    return Object.keys(this._functions).reduce((map, key) => {\n      map[key] = this._functions[key].signature;\n      return map;\n    }, {});\n  }\n\n  getCompilationKey(inputs, outputs) {\n    const sortedInputs = inputs.map(node => node.name).sort();\n    const sortedOutputs = outputs.map(node => node.name).sort();\n    return sortedInputs.join(this.SEPERATOR) + '--' + sortedOutputs.join(this.SEPERATOR);\n  }\n  /**\n   * Compiles the inference graph and returns the minimal set of nodes that are\n   * required for execution, in the correct execution order.\n   */\n\n\n  compile(inputs, outputs) {\n    const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n    const {\n      missingInputs,\n      dynamicNode,\n      syncInputs\n    } = executionInfo;\n\n    if (dynamicNode != null) {\n      throw new Error(`This execution contains the node '${dynamicNode.name}', which has ` + `the dynamic op '${dynamicNode.op}'. Please use ` + `model.executeAsync() instead. Alternatively, to avoid the ` + `dynamic ops, specify the inputs [${syncInputs}]`);\n    }\n\n    if (missingInputs.length > 0) {\n      const outNames = outputs.map(n => n.name);\n      const inNames = Object.keys(inputs);\n      throw new Error(`Cannot compute the outputs [${outNames}] from the provided inputs ` + `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n    }\n\n    return getNodesInTopologicalOrder(this.graph, this.weightMap, executionInfo);\n  }\n  /**\n   * Executes the inference for given input tensors.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model, if\n   * no outputs are specified, the default outputs of the model would be used.\n   * You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   */\n\n\n  execute(inputs, outputs) {\n    inputs = this.mapInputs(inputs);\n    const names = Object.keys(inputs).sort();\n    this.checkInputs(inputs);\n    this.checkInputShapeAndType(inputs);\n    outputs = this.mapOutputs(outputs);\n    this.checkOutputs(outputs);\n    const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n    const outputNodeNames = outputs.map(name => parseNodeName(name)[0]);\n    let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n    this.resetIntermediateTensors(); // If no outputs are specified, then use the default outputs of the model.\n\n    if (outputNodes.length === 0) {\n      outputNodes = this._outputs;\n    }\n\n    const compilationKey = this.getCompilationKey(inputNodes, outputNodes); // Do nothing if the compiled graph cache contains the input.\n\n    let orderedNodes = this.compiledMap.get(compilationKey);\n\n    if (orderedNodes == null) {\n      orderedNodes = this.compile(inputs, outputNodes);\n      this.compiledMap.set(compilationKey, orderedNodes);\n    }\n\n    const tensorArrayMap = {};\n    const tensorListMap = {};\n    return tidy(() => {\n      const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n      const tensorsMap = Object.assign({}, this.weightMap);\n      Object.keys(inputs).forEach(name => {\n        const [nodeName, index] = parseNodeName(name);\n        const tensors = [];\n        tensors[index] = inputs[name];\n        tensorsMap[nodeName] = tensors;\n      });\n      const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n      const intermediateTensorConsumerCount = {};\n\n      for (let i = 0; i < orderedNodes.length; i++) {\n        const node = orderedNodes[i];\n\n        if (!tensorsMap[node.name]) {\n          const tensors = executeOp(node, tensorsMap, context, this._resourceManager);\n\n          if (util.isPromise(tensors)) {\n            throw new Error(`The execution of the op '${node.op}' returned a promise. ` + `Please use model.executeAsync() instead.`);\n          }\n\n          tensorsMap[node.name] = tensors;\n          this.checkTensorForDisposal(node.name, node, tensorsMap, context, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount);\n        }\n      } // dispose the context for the root executor\n\n\n      if (this.parent == null) {\n        context.dispose(tensorsToKeep);\n      }\n\n      return outputs.map(name => getTensor(name, tensorsMap, context));\n    });\n  }\n\n  getFrozenTensorIds(tensorMap) {\n    const ids = [].concat.apply([], Object.keys(tensorMap).map(key => tensorMap[key]).map(tensors => tensors.map(tensor => tensor.id)));\n    return new Set(ids);\n  }\n\n  checkTensorForDisposal(nodeName, node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount) {\n    // Skip output nodes and any control flow nodes, since its dependency is\n    // tricky to track correctly.\n    if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n      return;\n    }\n\n    tensorMap[nodeName].forEach(tensor => {\n      if (tensor != null) {\n        intermediateTensorConsumerCount[tensor.id] = (intermediateTensorConsumerCount[tensor.id] || 0) + node.children.length;\n      }\n    });\n    node.inputs.forEach(input => {\n      // Skip any control flow nodes, since its dependency is tricky to track\n      // correctly.\n      if (input.category !== 'control') {\n        const tensors = getTensorsForCurrentContenxt(input.name, tensorMap, context);\n\n        if (tensors != null) {\n          tensors.forEach(tensor => {\n            if (tensor && !tensor.kept && !tensorsToKeep.has(tensor.id)) {\n              const count = intermediateTensorConsumerCount[tensor.id];\n\n              if (count === 1) {\n                if (!this.keepTensorForDebug) {\n                  tensor.dispose();\n                } else {\n                  const [nodeName, index] = getNodeNameAndIndex(node.name, context);\n\n                  if (this.intermediateTensors[nodeName]) {\n                    this.intermediateTensors[nodeName][index] = tensor;\n                  } else {\n                    this.intermediateTensors[nodeName] = [];\n                    this.intermediateTensors[nodeName][index] = tensor;\n                  }\n                }\n\n                delete intermediateTensorConsumerCount[tensor.id];\n              } else if (count != null) {\n                // only intermediate nodes has count set, inputs and weights are\n                // not.\n                intermediateTensorConsumerCount[tensor.id]--;\n              }\n            }\n          });\n        }\n      }\n    });\n  }\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs output node name from the Tensorflow model, if no outputs\n   * are specified, the default outputs of the model would be used. You can\n   * inspect intermediate nodes of the model by adding them to the outputs\n   * array.\n   */\n\n\n  executeAsync(inputs, outputs) {\n    var _this = this;\n\n    return _asyncToGenerator(function* () {\n      return _this._executeAsync(inputs, outputs);\n    })();\n  }\n\n  disposeIntermediateTensors() {\n    if (!this.intermediateTensors) {\n      return;\n    }\n\n    Object.keys(this.intermediateTensors).forEach(key => this.intermediateTensors[key].forEach(tensor => tensor.dispose()));\n    this.disposeTensorsMap();\n  }\n\n  disposeTensorsMap() {\n    if (!this.tensorsMap) {\n      return;\n    }\n\n    Object.keys(this.tensorsMap).forEach(key => {\n      const tensorArray = this.tensorsMap[key];\n      tensorArray.forEach(tensor => {\n        if (tensor && !tensor.kept && !tensor.isDisposed && !this.keepIds.has(tensor.id)) {\n          tensor.dispose();\n        }\n      });\n    });\n  }\n\n  getIntermediateTensors() {\n    return this.tensorsMap;\n  }\n\n  resetIntermediateTensors() {\n    for (const key in this.intermediateTensors) {\n      this.intermediateTensors[key].forEach(tensor => tensor.dispose());\n      delete this.intermediateTensors[key];\n    }\n  }\n  /**\n   * Executes the inference for given input tensors in Async fashion.\n   * @param inputs Tensor map for the model inputs, keyed by the input node\n   * names.\n   * @param outputs Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   * @param isFunctionExecution Optional. Flag for executing a function.\n   * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n   * function execution.\n   * @param tensorArrayMap Optinal global TensorList map by id. Used for\n   * function execution.\n   */\n\n\n  _executeAsync(inputs, outputs, isFunctionExecution = false, tensorArrayMap = {}, tensorListMap = {}) {\n    var _this2 = this;\n\n    return _asyncToGenerator(function* () {\n      if (!isFunctionExecution) {\n        inputs = _this2.mapInputs(inputs);\n\n        _this2.checkInputs(inputs);\n\n        _this2.checkInputShapeAndType(inputs);\n\n        outputs = _this2.mapOutputs(outputs);\n\n        _this2.checkOutputs(outputs);\n      } // For model debug.\n\n\n      try {\n        _this2.keepTensorForDebug = env().getBool('KEEP_INTERMEDIATE_TENSORS');\n      } catch (e) {\n        console.warn(e.message);\n      }\n\n      _this2.resetIntermediateTensors();\n\n      const context = new ExecutionContext(_this2.weightMap, tensorArrayMap, tensorListMap, _this2.functionExecutorMap); // Graph with control flow op requires runtime evaluation of the execution\n      // order, while without control flow the execution order is pre-determined\n      // in the compile method.\n\n      _this2.tensorsMap = yield _this2.executeWithControlFlow(inputs, context, outputs, isFunctionExecution);\n      const results = outputs.map(name => getTensor(name, _this2.tensorsMap, context)); // dispose all the intermediate tensors\n\n      const outputIds = results.map(t => t.id);\n      const inputIds = Object.keys(inputs).map(name => inputs[name].id);\n      _this2.keepIds = new Set([...outputIds, ...inputIds, ..._this2.weightIds]);\n\n      if (!_this2.keepTensorForDebug) {\n        _this2.disposeTensorsMap();\n      } // dispose the context for the root executor\n\n\n      if (_this2.parent == null) {\n        context.dispose(_this2.keepIds);\n      }\n\n      return results;\n    })();\n  }\n\n  executeFunctionAsync(inputs, tensorArrayMap, tensorListMap) {\n    var _this3 = this;\n\n    return _asyncToGenerator(function* () {\n      const mappedInputs = inputs.reduce((map, tensor, index) => {\n        map[_this3.inputs[index].name] = tensor;\n        return map;\n      }, {});\n      return _this3._executeAsync(mappedInputs, _this3.outputNodes, true, tensorArrayMap, tensorListMap);\n    })();\n  }\n  /**\n   * When there are control flow nodes in the graph, the graph execution use\n   * ExecutionContext to keep track of the frames and loop iterators.\n   * @param inputs placeholder tensors for the graph.\n   * @param context the execution context object for current execution.\n   * @param outputNames Optional. output node name from the Tensorflow model,\n   * if no outputs are specified, the default outputs of the model would be\n   * used. You can inspect intermediate nodes of the model by adding them to the\n   * outputs array.\n   * @param isFunctionExecution Flag for executing a function.\n   */\n\n\n  executeWithControlFlow(inputs, context, outputNames, isFunctionExecution) {\n    var _this4 = this;\n\n    return _asyncToGenerator(function* () {\n      const names = Object.keys(inputs);\n      const inputNodes = names.map(name => _this4.graph.nodes[parseNodeName(name)[0]]);\n      const outputNodeNames = outputNames.map(name => parseNodeName(name)[0]);\n      let outputNodes = outputNodeNames.map(name => _this4.graph.nodes[name]); // If no outputs are specified, then use the default outputs of the model.\n\n      if (outputNodes.length === 0) {\n        outputNodes = _this4._outputs;\n      }\n\n      const {\n        usedNodes,\n        missingInputs,\n        dynamicNode,\n        syncInputs\n      } = getExecutionSubgraph(inputs, outputNodes, _this4.weightMap, _this4._initNodes); // First nodes to execute include inputNodes, weights, and initNodes.\n\n      const stack = [...inputNodes, ..._this4.graph.weights, ...(_this4._initNodes || [])].map(node => {\n        return {\n          node,\n          contexts: context.currentContext\n        };\n      });\n      const tensorsMap = Object.assign({}, _this4.weightMap);\n      Object.keys(inputs).forEach(name => {\n        const [nodeName, index] = parseNodeName(name);\n        const tensors = [];\n        tensors[index] = inputs[name];\n        tensorsMap[nodeName] = tensors;\n      });\n      const intermediateTensorConsumerCount = {};\n\n      const tensorsToKeep = _this4.getFrozenTensorIds(tensorsMap);\n\n      const added = {};\n\n      while (stack.length > 0) {\n        const promises = _this4.processStack(inputNodes, stack, context, tensorsMap, added, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount, usedNodes);\n\n        yield Promise.all(promises);\n      }\n\n      if (dynamicNode == null && !isFunctionExecution) {\n        console.warn(`This model execution did not contain any nodes with control flow ` + `or dynamic output shapes. You can use model.execute() instead.`);\n      }\n\n      const missingOutputs = outputNodes.filter(node => !isControlFlow(node) && !getTensor(node.name, tensorsMap, context)).map(node => node.name);\n\n      if (missingOutputs.length > 0) {\n        let alternativeMsg = '';\n\n        if (dynamicNode != null) {\n          alternativeMsg = `Alternatively, to avoid the dynamic ops, use model.execute() ` + `and specify the inputs [${syncInputs}]`;\n        }\n\n        throw new Error(`Cannot compute the outputs [${missingOutputs}] from the provided ` + `inputs [${names}]. Consider providing the following inputs: ` + `[${missingInputs}]. ${alternativeMsg}`);\n      }\n\n      return tensorsMap;\n    })();\n  }\n\n  processStack(inputNodes, stack, context, tensorMap, added, tensorsToKeep, outputNames, intermediateTensorConsumerCount, usedNodes) {\n    const promises = [];\n\n    while (stack.length > 0) {\n      const item = stack.pop();\n      context.currentContext = item.contexts;\n      let nodeName = ''; // The tensor of the Enter op with isConstant set should be set\n      // in the parent scope, so it will be available as constant for the\n      // whole loop.\n\n      if (item.node.op === 'Enter' && getParamValue('isConstant', item.node, tensorMap, context)) {\n        [nodeName] = getNodeNameAndIndex(item.node.name, context);\n      } // only process nodes that are not in the tensorMap yet, this include\n      // inputNodes and internal initNodes.\n\n\n      if (tensorMap[item.node.name] == null) {\n        const tensors = executeOp(item.node, tensorMap, context, this._resourceManager);\n\n        if (!nodeName) {\n          [nodeName] = getNodeNameAndIndex(item.node.name, context);\n        }\n\n        const currentContext = context.currentContext;\n\n        if (util.isPromise(tensors)) {\n          promises.push(tensors.then(t => {\n            tensorMap[nodeName] = t;\n            context.currentContext = currentContext;\n            this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n            this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n            return t;\n          }));\n        } else {\n          tensorMap[nodeName] = tensors;\n          this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n          this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      } else {\n        this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n      }\n    }\n\n    return promises;\n  }\n\n  processChildNodes(node, stack, context, tensorMap, added, usedNodes) {\n    node.children.forEach(childNode => {\n      const [nodeName] = getNodeNameAndIndex(childNode.name, context);\n\n      if (added[nodeName] || !usedNodes.has(childNode.name)) {\n        return;\n      } // Merge op can be pushed if any of its inputs has value.\n\n\n      if (childNode.op === 'Merge') {\n        if (childNode.inputNames.some(name => {\n          return !!getTensor(name, tensorMap, context);\n        })) {\n          added[nodeName] = true;\n          stack.push({\n            contexts: context.currentContext,\n            node: childNode\n          });\n        }\n      } else // Otherwise all inputs must to have value.\n        if (childNode.inputNames.every(name => {\n          return !!getTensor(name, tensorMap, context);\n        })) {\n          added[nodeName] = true;\n          stack.push({\n            contexts: context.currentContext,\n            node: childNode\n          });\n        }\n    });\n  }\n  /**\n   * Releases the memory used by the weight tensors.\n   */\n\n\n  dispose() {\n    Object.keys(this.weightMap).forEach(key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n  }\n\n  checkInputShapeAndType(inputs) {\n    Object.keys(inputs).forEach(name => {\n      const input = inputs[name];\n      const [nodeName] = parseNodeName(name);\n      const node = this.graph.nodes[nodeName];\n\n      if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n        const shape = node.attrParams['shape'].value;\n        const match = shape.length === input.shape.length && input.shape.every((dim, index) => shape[index] === -1 || shape[index] === dim);\n        util.assert(match, () => `The shape of dict['${node.name}'] provided in ` + `model.execute(dict) must be [${shape}], but was ` + `[${input.shape}]`);\n      }\n\n      if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n        util.assert(input.dtype === node.attrParams['dtype'].value, () => `The dtype of dict['${node.name}'] provided in ` + `model.execute(dict) must be ` + `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n      }\n    });\n  }\n\n  mapInputs(inputs) {\n    const result = {};\n\n    for (const inputName in inputs) {\n      if (this._signature != null && this._signature.inputs != null && this._signature.inputs[inputName] != null) {\n        const tensor = this._signature.inputs[inputName];\n        result[tensor.name] = inputs[inputName];\n      } else {\n        result[inputName] = inputs[inputName];\n      }\n    }\n\n    return result;\n  }\n\n  checkInputs(inputs) {\n    const notInGraph = Object.keys(inputs).filter(name => {\n      const [nodeName] = parseNodeName(name);\n      return this.graph.nodes[nodeName] == null;\n    });\n\n    if (notInGraph.length > 0) {\n      throw new Error(`The dict provided in model.execute(dict) has ` + `keys: [${notInGraph}] that are not part of graph`);\n    }\n  }\n\n  mapOutputs(outputs) {\n    return outputs.map(name => {\n      if (this._signature != null && this._signature.outputs != null && this._signature.outputs[name] != null) {\n        const tensor = this._signature.outputs[name];\n        return tensor.name;\n      }\n\n      return name;\n    }, {});\n  }\n\n  checkOutputs(outputs) {\n    outputs.forEach(name => {\n      const [normalizedName] = parseNodeName(name);\n\n      if (!this.graph.nodes[normalizedName]) {\n        throw new Error(`The output '${name}' is not found in the graph`);\n      }\n    });\n  }\n\n}","map":{"version":3,"names":["env","tidy","util","getNodeNameAndIndex","getParamValue","getTensor","getTensorsForCurrentContenxt","parseNodeName","executeOp","ExecutionContext","getExecutionSubgraph","getNodesInTopologicalOrder","isControlFlow","GraphExecutor","constructor","graph","parent","compiledMap","Map","_weightMap","SEPERATOR","_functions","_functionExecutorMap","intermediateTensors","keepTensorForDebug","_outputs","outputs","_inputs","inputs","_initNodes","initNodes","_signature","signature","functions","Object","keys","forEach","name","weightIds","_weightIds","functionExecutorMap","weightMap","map","key","tensor","id","concat","resourceManager","_resourceManager","node","shape","attrParams","value","undefined","dtype","inputNodes","signatureKey","outputNodes","defaultOutput","reduce","getCompilationKey","sortedInputs","sort","sortedOutputs","join","compile","executionInfo","missingInputs","dynamicNode","syncInputs","Error","op","length","outNames","n","inNames","execute","mapInputs","names","checkInputs","checkInputShapeAndType","mapOutputs","checkOutputs","nodes","outputNodeNames","resetIntermediateTensors","compilationKey","orderedNodes","get","set","tensorArrayMap","tensorListMap","context","tensorsMap","assign","nodeName","index","tensors","tensorsToKeep","getFrozenTensorIds","intermediateTensorConsumerCount","i","isPromise","checkTensorForDisposal","dispose","tensorMap","ids","apply","Set","outputNames","category","indexOf","children","input","kept","has","count","executeAsync","_executeAsync","disposeIntermediateTensors","disposeTensorsMap","tensorArray","isDisposed","keepIds","getIntermediateTensors","isFunctionExecution","getBool","e","console","warn","message","executeWithControlFlow","results","outputIds","t","inputIds","executeFunctionAsync","mappedInputs","usedNodes","stack","weights","contexts","currentContext","added","promises","processStack","Promise","all","missingOutputs","filter","alternativeMsg","item","pop","push","then","processChildNodes","childNode","inputNames","some","every","match","dim","assert","result","inputName","notInGraph","normalizedName"],"sources":["C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@tensorflow/tfjs-converter/dist/executor/graph_executor.js"],"sourcesContent":["/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env, tidy, util } from '@tensorflow/tfjs-core';\nimport { getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName } from '../operations/executors/utils';\nimport { executeOp } from '../operations/operation_executor';\nimport { ExecutionContext } from './execution_context';\nimport { getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow } from './model_analysis';\nexport class GraphExecutor {\n    /**\n     *\n     * @param graph Graph the model or function graph to be executed.\n     * @param parent When building function exector you need to set the parent\n     * executor. Since the weights and function executor maps are set at parant\n     * level, that function executor can access the function maps and weight maps\n     * through the parent.\n     */\n    constructor(graph, parent) {\n        this.graph = graph;\n        this.parent = parent;\n        this.compiledMap = new Map();\n        this._weightMap = {};\n        this.SEPERATOR = ',';\n        this._functions = {};\n        this._functionExecutorMap = {};\n        this.intermediateTensors = {};\n        this.keepTensorForDebug = false;\n        this._outputs = graph.outputs;\n        this._inputs = graph.inputs;\n        this._initNodes = graph.initNodes;\n        this._signature = graph.signature;\n        this._functions = graph.functions;\n        // create sub-graph executors\n        if (graph.functions != null) {\n            Object.keys(graph.functions).forEach(name => {\n                this._functionExecutorMap[name] =\n                    new GraphExecutor(graph.functions[name], this);\n            });\n        }\n    }\n    get weightIds() {\n        return this.parent ? this.parent.weightIds : this._weightIds;\n    }\n    get functionExecutorMap() {\n        return this.parent ? this.parent.functionExecutorMap :\n            this._functionExecutorMap;\n    }\n    get weightMap() {\n        return this.parent ? this.parent.weightMap : this._weightMap;\n    }\n    set weightMap(weightMap) {\n        const weightIds = Object.keys(weightMap).map(key => weightMap[key].map(tensor => tensor.id));\n        this._weightIds = [].concat(...weightIds);\n        this._weightMap = weightMap;\n    }\n    /**\n     * Set `ResourceManager` shared by executors of a model.\n     * @param resourceManager: `ResourceManager` of the `GraphModel`.\n     */\n    set resourceManager(resourceManager) {\n        this._resourceManager = resourceManager;\n    }\n    get inputs() {\n        return this._inputs.map(node => {\n            return {\n                name: node.name,\n                shape: node.attrParams['shape'] ?\n                    node.attrParams['shape'].value :\n                    undefined,\n                dtype: node.attrParams['dtype'] ?\n                    node.attrParams['dtype'].value :\n                    undefined\n            };\n        });\n    }\n    get outputs() {\n        return this._outputs.map(node => {\n            return {\n                name: node.name,\n                shape: node.attrParams['shape'] ?\n                    node.attrParams['shape'].value :\n                    undefined,\n                dtype: node.attrParams['dtype'] ?\n                    node.attrParams['dtype'].value :\n                    undefined\n            };\n        });\n    }\n    get inputNodes() {\n        return this._inputs.map(node => node.signatureKey || node.name);\n    }\n    get outputNodes() {\n        return this._outputs.map((node) => {\n            const name = node.signatureKey || node.name;\n            return node.defaultOutput ? (`${name}:${node.defaultOutput}`) : name;\n        });\n    }\n    get functions() {\n        return Object.keys(this._functions).reduce((map, key) => {\n            map[key] = this._functions[key].signature;\n            return map;\n        }, {});\n    }\n    getCompilationKey(inputs, outputs) {\n        const sortedInputs = inputs.map(node => node.name).sort();\n        const sortedOutputs = outputs.map(node => node.name).sort();\n        return sortedInputs.join(this.SEPERATOR) + '--' +\n            sortedOutputs.join(this.SEPERATOR);\n    }\n    /**\n     * Compiles the inference graph and returns the minimal set of nodes that are\n     * required for execution, in the correct execution order.\n     */\n    compile(inputs, outputs) {\n        const executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n        const { missingInputs, dynamicNode, syncInputs } = executionInfo;\n        if (dynamicNode != null) {\n            throw new Error(`This execution contains the node '${dynamicNode.name}', which has ` +\n                `the dynamic op '${dynamicNode.op}'. Please use ` +\n                `model.executeAsync() instead. Alternatively, to avoid the ` +\n                `dynamic ops, specify the inputs [${syncInputs}]`);\n        }\n        if (missingInputs.length > 0) {\n            const outNames = outputs.map(n => n.name);\n            const inNames = Object.keys(inputs);\n            throw new Error(`Cannot compute the outputs [${outNames}] from the provided inputs ` +\n                `[${inNames}]. Missing the following inputs: [${missingInputs}]`);\n        }\n        return getNodesInTopologicalOrder(this.graph, this.weightMap, executionInfo);\n    }\n    /**\n     * Executes the inference for given input tensors.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs Optional. output node name from the Tensorflow model, if\n     * no outputs are specified, the default outputs of the model would be used.\n     * You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     */\n    execute(inputs, outputs) {\n        inputs = this.mapInputs(inputs);\n        const names = Object.keys(inputs).sort();\n        this.checkInputs(inputs);\n        this.checkInputShapeAndType(inputs);\n        outputs = this.mapOutputs(outputs);\n        this.checkOutputs(outputs);\n        const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n        const outputNodeNames = outputs.map(name => parseNodeName(name)[0]);\n        let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n        this.resetIntermediateTensors();\n        // If no outputs are specified, then use the default outputs of the model.\n        if (outputNodes.length === 0) {\n            outputNodes = this._outputs;\n        }\n        const compilationKey = this.getCompilationKey(inputNodes, outputNodes);\n        // Do nothing if the compiled graph cache contains the input.\n        let orderedNodes = this.compiledMap.get(compilationKey);\n        if (orderedNodes == null) {\n            orderedNodes = this.compile(inputs, outputNodes);\n            this.compiledMap.set(compilationKey, orderedNodes);\n        }\n        const tensorArrayMap = {};\n        const tensorListMap = {};\n        return tidy(() => {\n            const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n            const tensorsMap = Object.assign({}, this.weightMap);\n            Object.keys(inputs).forEach(name => {\n                const [nodeName, index] = parseNodeName(name);\n                const tensors = [];\n                tensors[index] = inputs[name];\n                tensorsMap[nodeName] = tensors;\n            });\n            const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n            const intermediateTensorConsumerCount = {};\n            for (let i = 0; i < orderedNodes.length; i++) {\n                const node = orderedNodes[i];\n                if (!tensorsMap[node.name]) {\n                    const tensors = executeOp(node, tensorsMap, context, this._resourceManager);\n                    if (util.isPromise(tensors)) {\n                        throw new Error(`The execution of the op '${node.op}' returned a promise. ` +\n                            `Please use model.executeAsync() instead.`);\n                    }\n                    tensorsMap[node.name] = tensors;\n                    this.checkTensorForDisposal(node.name, node, tensorsMap, context, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount);\n                }\n            }\n            // dispose the context for the root executor\n            if (this.parent == null) {\n                context.dispose(tensorsToKeep);\n            }\n            return outputs.map(name => getTensor(name, tensorsMap, context));\n        });\n    }\n    getFrozenTensorIds(tensorMap) {\n        const ids = [].concat.apply([], Object.keys(tensorMap)\n            .map(key => tensorMap[key])\n            .map(tensors => tensors.map(tensor => tensor.id)));\n        return new Set(ids);\n    }\n    checkTensorForDisposal(nodeName, node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount) {\n        // Skip output nodes and any control flow nodes, since its dependency is\n        // tricky to track correctly.\n        if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n            return;\n        }\n        tensorMap[nodeName].forEach(tensor => {\n            if (tensor != null) {\n                intermediateTensorConsumerCount[tensor.id] =\n                    (intermediateTensorConsumerCount[tensor.id] || 0) +\n                        node.children.length;\n            }\n        });\n        node.inputs.forEach(input => {\n            // Skip any control flow nodes, since its dependency is tricky to track\n            // correctly.\n            if (input.category !== 'control') {\n                const tensors = getTensorsForCurrentContenxt(input.name, tensorMap, context);\n                if (tensors != null) {\n                    tensors.forEach(tensor => {\n                        if (tensor && !tensor.kept && !tensorsToKeep.has(tensor.id)) {\n                            const count = intermediateTensorConsumerCount[tensor.id];\n                            if (count === 1) {\n                                if (!this.keepTensorForDebug) {\n                                    tensor.dispose();\n                                }\n                                else {\n                                    const [nodeName, index] = getNodeNameAndIndex(node.name, context);\n                                    if (this.intermediateTensors[nodeName]) {\n                                        this.intermediateTensors[nodeName][index] = tensor;\n                                    }\n                                    else {\n                                        this.intermediateTensors[nodeName] = [];\n                                        this.intermediateTensors[nodeName][index] = tensor;\n                                    }\n                                }\n                                delete intermediateTensorConsumerCount[tensor.id];\n                            }\n                            else if (count != null) {\n                                // only intermediate nodes has count set, inputs and weights are\n                                // not.\n                                intermediateTensorConsumerCount[tensor.id]--;\n                            }\n                        }\n                    });\n                }\n            }\n        });\n    }\n    /**\n     * Executes the inference for given input tensors in Async fashion.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs output node name from the Tensorflow model, if no outputs\n     * are specified, the default outputs of the model would be used. You can\n     * inspect intermediate nodes of the model by adding them to the outputs\n     * array.\n     */\n    async executeAsync(inputs, outputs) {\n        return this._executeAsync(inputs, outputs);\n    }\n    disposeIntermediateTensors() {\n        if (!this.intermediateTensors) {\n            return;\n        }\n        Object.keys(this.intermediateTensors)\n            .forEach(key => this.intermediateTensors[key].forEach(tensor => tensor.dispose()));\n        this.disposeTensorsMap();\n    }\n    disposeTensorsMap() {\n        if (!this.tensorsMap) {\n            return;\n        }\n        Object.keys(this.tensorsMap).forEach(key => {\n            const tensorArray = this.tensorsMap[key];\n            tensorArray.forEach(tensor => {\n                if (tensor && !tensor.kept && !tensor.isDisposed &&\n                    !this.keepIds.has(tensor.id)) {\n                    tensor.dispose();\n                }\n            });\n        });\n    }\n    getIntermediateTensors() {\n        return this.tensorsMap;\n    }\n    resetIntermediateTensors() {\n        for (const key in this.intermediateTensors) {\n            this.intermediateTensors[key].forEach(tensor => tensor.dispose());\n            delete this.intermediateTensors[key];\n        }\n    }\n    /**\n     * Executes the inference for given input tensors in Async fashion.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs Optional. output node name from the Tensorflow model,\n     * if no outputs are specified, the default outputs of the model would be\n     * used. You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     * @param isFunctionExecution Optional. Flag for executing a function.\n     * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n     * function execution.\n     * @param tensorArrayMap Optinal global TensorList map by id. Used for\n     * function execution.\n     */\n    async _executeAsync(inputs, outputs, isFunctionExecution = false, tensorArrayMap = {}, tensorListMap = {}) {\n        if (!isFunctionExecution) {\n            inputs = this.mapInputs(inputs);\n            this.checkInputs(inputs);\n            this.checkInputShapeAndType(inputs);\n            outputs = this.mapOutputs(outputs);\n            this.checkOutputs(outputs);\n        }\n        // For model debug.\n        try {\n            this.keepTensorForDebug = env().getBool('KEEP_INTERMEDIATE_TENSORS');\n        }\n        catch (e) {\n            console.warn(e.message);\n        }\n        this.resetIntermediateTensors();\n        const context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap);\n        // Graph with control flow op requires runtime evaluation of the execution\n        // order, while without control flow the execution order is pre-determined\n        // in the compile method.\n        this.tensorsMap = await this.executeWithControlFlow(inputs, context, outputs, isFunctionExecution);\n        const results = outputs.map(name => getTensor(name, this.tensorsMap, context));\n        // dispose all the intermediate tensors\n        const outputIds = results.map(t => t.id);\n        const inputIds = Object.keys(inputs).map(name => inputs[name].id);\n        this.keepIds =\n            new Set([...outputIds, ...inputIds, ...this.weightIds]);\n        if (!this.keepTensorForDebug) {\n            this.disposeTensorsMap();\n        }\n        // dispose the context for the root executor\n        if (this.parent == null) {\n            context.dispose(this.keepIds);\n        }\n        return results;\n    }\n    async executeFunctionAsync(inputs, tensorArrayMap, tensorListMap) {\n        const mappedInputs = inputs.reduce((map, tensor, index) => {\n            map[this.inputs[index].name] = tensor;\n            return map;\n        }, {});\n        return this._executeAsync(mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap);\n    }\n    /**\n     * When there are control flow nodes in the graph, the graph execution use\n     * ExecutionContext to keep track of the frames and loop iterators.\n     * @param inputs placeholder tensors for the graph.\n     * @param context the execution context object for current execution.\n     * @param outputNames Optional. output node name from the Tensorflow model,\n     * if no outputs are specified, the default outputs of the model would be\n     * used. You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     * @param isFunctionExecution Flag for executing a function.\n     */\n    async executeWithControlFlow(inputs, context, outputNames, isFunctionExecution) {\n        const names = Object.keys(inputs);\n        const inputNodes = names.map(name => this.graph.nodes[parseNodeName(name)[0]]);\n        const outputNodeNames = outputNames.map(name => parseNodeName(name)[0]);\n        let outputNodes = outputNodeNames.map(name => this.graph.nodes[name]);\n        // If no outputs are specified, then use the default outputs of the model.\n        if (outputNodes.length === 0) {\n            outputNodes = this._outputs;\n        }\n        const { usedNodes, missingInputs, dynamicNode, syncInputs } = getExecutionSubgraph(inputs, outputNodes, this.weightMap, this._initNodes);\n        // First nodes to execute include inputNodes, weights, and initNodes.\n        const stack = [\n            ...inputNodes, ...this.graph.weights, ...(this._initNodes || [])\n        ].map(node => {\n            return { node, contexts: context.currentContext };\n        });\n        const tensorsMap = Object.assign({}, this.weightMap);\n        Object.keys(inputs).forEach(name => {\n            const [nodeName, index] = parseNodeName(name);\n            const tensors = [];\n            tensors[index] = inputs[name];\n            tensorsMap[nodeName] = tensors;\n        });\n        const intermediateTensorConsumerCount = {};\n        const tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n        const added = {};\n        while (stack.length > 0) {\n            const promises = this.processStack(inputNodes, stack, context, tensorsMap, added, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount, usedNodes);\n            await Promise.all(promises);\n        }\n        if (dynamicNode == null && !isFunctionExecution) {\n            console.warn(`This model execution did not contain any nodes with control flow ` +\n                `or dynamic output shapes. You can use model.execute() instead.`);\n        }\n        const missingOutputs = outputNodes\n            .filter(node => !isControlFlow(node) &&\n            !getTensor(node.name, tensorsMap, context))\n            .map(node => node.name);\n        if (missingOutputs.length > 0) {\n            let alternativeMsg = '';\n            if (dynamicNode != null) {\n                alternativeMsg =\n                    `Alternatively, to avoid the dynamic ops, use model.execute() ` +\n                        `and specify the inputs [${syncInputs}]`;\n            }\n            throw new Error(`Cannot compute the outputs [${missingOutputs}] from the provided ` +\n                `inputs [${names}]. Consider providing the following inputs: ` +\n                `[${missingInputs}]. ${alternativeMsg}`);\n        }\n        return tensorsMap;\n    }\n    processStack(inputNodes, stack, context, tensorMap, added, tensorsToKeep, outputNames, intermediateTensorConsumerCount, usedNodes) {\n        const promises = [];\n        while (stack.length > 0) {\n            const item = stack.pop();\n            context.currentContext = item.contexts;\n            let nodeName = '';\n            // The tensor of the Enter op with isConstant set should be set\n            // in the parent scope, so it will be available as constant for the\n            // whole loop.\n            if (item.node.op === 'Enter' &&\n                getParamValue('isConstant', item.node, tensorMap, context)) {\n                [nodeName] = getNodeNameAndIndex(item.node.name, context);\n            }\n            // only process nodes that are not in the tensorMap yet, this include\n            // inputNodes and internal initNodes.\n            if (tensorMap[item.node.name] == null) {\n                const tensors = executeOp(item.node, tensorMap, context, this._resourceManager);\n                if (!nodeName) {\n                    [nodeName] = getNodeNameAndIndex(item.node.name, context);\n                }\n                const currentContext = context.currentContext;\n                if (util.isPromise(tensors)) {\n                    promises.push(tensors.then(t => {\n                        tensorMap[nodeName] = t;\n                        context.currentContext = currentContext;\n                        this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n                        this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n                        return t;\n                    }));\n                }\n                else {\n                    tensorMap[nodeName] = tensors;\n                    this.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n                    this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n                }\n            }\n            else {\n                this.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n            }\n        }\n        return promises;\n    }\n    processChildNodes(node, stack, context, tensorMap, added, usedNodes) {\n        node.children.forEach((childNode) => {\n            const [nodeName,] = getNodeNameAndIndex(childNode.name, context);\n            if (added[nodeName] || !usedNodes.has(childNode.name)) {\n                return;\n            }\n            // Merge op can be pushed if any of its inputs has value.\n            if (childNode.op === 'Merge') {\n                if (childNode.inputNames.some(name => {\n                    return !!getTensor(name, tensorMap, context);\n                })) {\n                    added[nodeName] = true;\n                    stack.push({ contexts: context.currentContext, node: childNode });\n                }\n            }\n            else // Otherwise all inputs must to have value.\n             if (childNode.inputNames.every(name => {\n                return !!getTensor(name, tensorMap, context);\n            })) {\n                added[nodeName] = true;\n                stack.push({ contexts: context.currentContext, node: childNode });\n            }\n        });\n    }\n    /**\n     * Releases the memory used by the weight tensors.\n     */\n    dispose() {\n        Object.keys(this.weightMap)\n            .forEach(key => this.weightMap[key].forEach(tensor => tensor.dispose()));\n    }\n    checkInputShapeAndType(inputs) {\n        Object.keys(inputs).forEach(name => {\n            const input = inputs[name];\n            const [nodeName,] = parseNodeName(name);\n            const node = this.graph.nodes[nodeName];\n            if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n                const shape = node.attrParams['shape'].value;\n                const match = shape.length === input.shape.length &&\n                    input.shape.every((dim, index) => shape[index] === -1 || shape[index] === dim);\n                util.assert(match, () => `The shape of dict['${node.name}'] provided in ` +\n                    `model.execute(dict) must be [${shape}], but was ` +\n                    `[${input.shape}]`);\n            }\n            if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n                util.assert(input.dtype === node.attrParams['dtype'].value, () => `The dtype of dict['${node.name}'] provided in ` +\n                    `model.execute(dict) must be ` +\n                    `${node.attrParams['dtype'].value}, but was ${input.dtype}`);\n            }\n        });\n    }\n    mapInputs(inputs) {\n        const result = {};\n        for (const inputName in inputs) {\n            if (this._signature != null && this._signature.inputs != null &&\n                this._signature.inputs[inputName] != null) {\n                const tensor = this._signature.inputs[inputName];\n                result[tensor.name] = inputs[inputName];\n            }\n            else {\n                result[inputName] = inputs[inputName];\n            }\n        }\n        return result;\n    }\n    checkInputs(inputs) {\n        const notInGraph = Object.keys(inputs).filter(name => {\n            const [nodeName] = parseNodeName(name);\n            return this.graph.nodes[nodeName] == null;\n        });\n        if (notInGraph.length > 0) {\n            throw new Error(`The dict provided in model.execute(dict) has ` +\n                `keys: [${notInGraph}] that are not part of graph`);\n        }\n    }\n    mapOutputs(outputs) {\n        return outputs.map(name => {\n            if (this._signature != null && this._signature.outputs != null &&\n                this._signature.outputs[name] != null) {\n                const tensor = this._signature.outputs[name];\n                return tensor.name;\n            }\n            return name;\n        }, {});\n    }\n    checkOutputs(outputs) {\n        outputs.forEach(name => {\n            const [normalizedName] = parseNodeName(name);\n            if (!this.graph.nodes[normalizedName]) {\n                throw new Error(`The output '${name}' is not found in the graph`);\n            }\n        });\n    }\n}\n"],"mappings":";;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,GAAT,EAAcC,IAAd,EAAoBC,IAApB,QAAgC,uBAAhC;AACA,SAASC,mBAAT,EAA8BC,aAA9B,EAA6CC,SAA7C,EAAwDC,4BAAxD,EAAsFC,aAAtF,QAA2G,+BAA3G;AACA,SAASC,SAAT,QAA0B,kCAA1B;AACA,SAASC,gBAAT,QAAiC,qBAAjC;AACA,SAASC,oBAAT,EAA+BC,0BAA/B,EAA2DC,aAA3D,QAAgF,kBAAhF;AACA,OAAO,MAAMC,aAAN,CAAoB;EACvB;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;EACIC,WAAW,CAACC,KAAD,EAAQC,MAAR,EAAgB;IACvB,KAAKD,KAAL,GAAaA,KAAb;IACA,KAAKC,MAAL,GAAcA,MAAd;IACA,KAAKC,WAAL,GAAmB,IAAIC,GAAJ,EAAnB;IACA,KAAKC,UAAL,GAAkB,EAAlB;IACA,KAAKC,SAAL,GAAiB,GAAjB;IACA,KAAKC,UAAL,GAAkB,EAAlB;IACA,KAAKC,oBAAL,GAA4B,EAA5B;IACA,KAAKC,mBAAL,GAA2B,EAA3B;IACA,KAAKC,kBAAL,GAA0B,KAA1B;IACA,KAAKC,QAAL,GAAgBV,KAAK,CAACW,OAAtB;IACA,KAAKC,OAAL,GAAeZ,KAAK,CAACa,MAArB;IACA,KAAKC,UAAL,GAAkBd,KAAK,CAACe,SAAxB;IACA,KAAKC,UAAL,GAAkBhB,KAAK,CAACiB,SAAxB;IACA,KAAKX,UAAL,GAAkBN,KAAK,CAACkB,SAAxB,CAduB,CAevB;;IACA,IAAIlB,KAAK,CAACkB,SAAN,IAAmB,IAAvB,EAA6B;MACzBC,MAAM,CAACC,IAAP,CAAYpB,KAAK,CAACkB,SAAlB,EAA6BG,OAA7B,CAAqCC,IAAI,IAAI;QACzC,KAAKf,oBAAL,CAA0Be,IAA1B,IACI,IAAIxB,aAAJ,CAAkBE,KAAK,CAACkB,SAAN,CAAgBI,IAAhB,CAAlB,EAAyC,IAAzC,CADJ;MAEH,CAHD;IAIH;EACJ;;EACY,IAATC,SAAS,GAAG;IACZ,OAAO,KAAKtB,MAAL,GAAc,KAAKA,MAAL,CAAYsB,SAA1B,GAAsC,KAAKC,UAAlD;EACH;;EACsB,IAAnBC,mBAAmB,GAAG;IACtB,OAAO,KAAKxB,MAAL,GAAc,KAAKA,MAAL,CAAYwB,mBAA1B,GACH,KAAKlB,oBADT;EAEH;;EACY,IAATmB,SAAS,GAAG;IACZ,OAAO,KAAKzB,MAAL,GAAc,KAAKA,MAAL,CAAYyB,SAA1B,GAAsC,KAAKtB,UAAlD;EACH;;EACY,IAATsB,SAAS,CAACA,SAAD,EAAY;IACrB,MAAMH,SAAS,GAAGJ,MAAM,CAACC,IAAP,CAAYM,SAAZ,EAAuBC,GAAvB,CAA2BC,GAAG,IAAIF,SAAS,CAACE,GAAD,CAAT,CAAeD,GAAf,CAAmBE,MAAM,IAAIA,MAAM,CAACC,EAApC,CAAlC,CAAlB;IACA,KAAKN,UAAL,GAAkB,GAAGO,MAAH,CAAU,GAAGR,SAAb,CAAlB;IACA,KAAKnB,UAAL,GAAkBsB,SAAlB;EACH;EACD;AACJ;AACA;AACA;;;EACuB,IAAfM,eAAe,CAACA,eAAD,EAAkB;IACjC,KAAKC,gBAAL,GAAwBD,eAAxB;EACH;;EACS,IAANnB,MAAM,GAAG;IACT,OAAO,KAAKD,OAAL,CAAae,GAAb,CAAiBO,IAAI,IAAI;MAC5B,OAAO;QACHZ,IAAI,EAAEY,IAAI,CAACZ,IADR;QAEHa,KAAK,EAAED,IAAI,CAACE,UAAL,CAAgB,OAAhB,IACHF,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KADtB,GAEHC,SAJD;QAKHC,KAAK,EAAEL,IAAI,CAACE,UAAL,CAAgB,OAAhB,IACHF,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KADtB,GAEHC;MAPD,CAAP;IASH,CAVM,CAAP;EAWH;;EACU,IAAP3B,OAAO,GAAG;IACV,OAAO,KAAKD,QAAL,CAAciB,GAAd,CAAkBO,IAAI,IAAI;MAC7B,OAAO;QACHZ,IAAI,EAAEY,IAAI,CAACZ,IADR;QAEHa,KAAK,EAAED,IAAI,CAACE,UAAL,CAAgB,OAAhB,IACHF,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KADtB,GAEHC,SAJD;QAKHC,KAAK,EAAEL,IAAI,CAACE,UAAL,CAAgB,OAAhB,IACHF,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KADtB,GAEHC;MAPD,CAAP;IASH,CAVM,CAAP;EAWH;;EACa,IAAVE,UAAU,GAAG;IACb,OAAO,KAAK5B,OAAL,CAAae,GAAb,CAAiBO,IAAI,IAAIA,IAAI,CAACO,YAAL,IAAqBP,IAAI,CAACZ,IAAnD,CAAP;EACH;;EACc,IAAXoB,WAAW,GAAG;IACd,OAAO,KAAKhC,QAAL,CAAciB,GAAd,CAAmBO,IAAD,IAAU;MAC/B,MAAMZ,IAAI,GAAGY,IAAI,CAACO,YAAL,IAAqBP,IAAI,CAACZ,IAAvC;MACA,OAAOY,IAAI,CAACS,aAAL,GAAuB,GAAErB,IAAK,IAAGY,IAAI,CAACS,aAAc,EAApD,GAAyDrB,IAAhE;IACH,CAHM,CAAP;EAIH;;EACY,IAATJ,SAAS,GAAG;IACZ,OAAOC,MAAM,CAACC,IAAP,CAAY,KAAKd,UAAjB,EAA6BsC,MAA7B,CAAoC,CAACjB,GAAD,EAAMC,GAAN,KAAc;MACrDD,GAAG,CAACC,GAAD,CAAH,GAAW,KAAKtB,UAAL,CAAgBsB,GAAhB,EAAqBX,SAAhC;MACA,OAAOU,GAAP;IACH,CAHM,EAGJ,EAHI,CAAP;EAIH;;EACDkB,iBAAiB,CAAChC,MAAD,EAASF,OAAT,EAAkB;IAC/B,MAAMmC,YAAY,GAAGjC,MAAM,CAACc,GAAP,CAAWO,IAAI,IAAIA,IAAI,CAACZ,IAAxB,EAA8ByB,IAA9B,EAArB;IACA,MAAMC,aAAa,GAAGrC,OAAO,CAACgB,GAAR,CAAYO,IAAI,IAAIA,IAAI,CAACZ,IAAzB,EAA+ByB,IAA/B,EAAtB;IACA,OAAOD,YAAY,CAACG,IAAb,CAAkB,KAAK5C,SAAvB,IAAoC,IAApC,GACH2C,aAAa,CAACC,IAAd,CAAmB,KAAK5C,SAAxB,CADJ;EAEH;EACD;AACJ;AACA;AACA;;;EACI6C,OAAO,CAACrC,MAAD,EAASF,OAAT,EAAkB;IACrB,MAAMwC,aAAa,GAAGxD,oBAAoB,CAACkB,MAAD,EAASF,OAAT,EAAkB,KAAKe,SAAvB,EAAkC,KAAKZ,UAAvC,CAA1C;IACA,MAAM;MAAEsC,aAAF;MAAiBC,WAAjB;MAA8BC;IAA9B,IAA6CH,aAAnD;;IACA,IAAIE,WAAW,IAAI,IAAnB,EAAyB;MACrB,MAAM,IAAIE,KAAJ,CAAW,qCAAoCF,WAAW,CAAC/B,IAAK,eAAtD,GACX,mBAAkB+B,WAAW,CAACG,EAAG,gBADtB,GAEX,4DAFW,GAGX,oCAAmCF,UAAW,GAH7C,CAAN;IAIH;;IACD,IAAIF,aAAa,CAACK,MAAd,GAAuB,CAA3B,EAA8B;MAC1B,MAAMC,QAAQ,GAAG/C,OAAO,CAACgB,GAAR,CAAYgC,CAAC,IAAIA,CAAC,CAACrC,IAAnB,CAAjB;MACA,MAAMsC,OAAO,GAAGzC,MAAM,CAACC,IAAP,CAAYP,MAAZ,CAAhB;MACA,MAAM,IAAI0C,KAAJ,CAAW,+BAA8BG,QAAS,6BAAxC,GACX,IAAGE,OAAQ,qCAAoCR,aAAc,GAD5D,CAAN;IAEH;;IACD,OAAOxD,0BAA0B,CAAC,KAAKI,KAAN,EAAa,KAAK0B,SAAlB,EAA6ByB,aAA7B,CAAjC;EACH;EACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACIU,OAAO,CAAChD,MAAD,EAASF,OAAT,EAAkB;IACrBE,MAAM,GAAG,KAAKiD,SAAL,CAAejD,MAAf,CAAT;IACA,MAAMkD,KAAK,GAAG5C,MAAM,CAACC,IAAP,CAAYP,MAAZ,EAAoBkC,IAApB,EAAd;IACA,KAAKiB,WAAL,CAAiBnD,MAAjB;IACA,KAAKoD,sBAAL,CAA4BpD,MAA5B;IACAF,OAAO,GAAG,KAAKuD,UAAL,CAAgBvD,OAAhB,CAAV;IACA,KAAKwD,YAAL,CAAkBxD,OAAlB;IACA,MAAM6B,UAAU,GAAGuB,KAAK,CAACpC,GAAN,CAAUL,IAAI,IAAI,KAAKtB,KAAL,CAAWoE,KAAX,CAAiB5E,aAAa,CAAC8B,IAAD,CAAb,CAAoB,CAApB,CAAjB,CAAlB,CAAnB;IACA,MAAM+C,eAAe,GAAG1D,OAAO,CAACgB,GAAR,CAAYL,IAAI,IAAI9B,aAAa,CAAC8B,IAAD,CAAb,CAAoB,CAApB,CAApB,CAAxB;IACA,IAAIoB,WAAW,GAAG2B,eAAe,CAAC1C,GAAhB,CAAoBL,IAAI,IAAI,KAAKtB,KAAL,CAAWoE,KAAX,CAAiB9C,IAAjB,CAA5B,CAAlB;IACA,KAAKgD,wBAAL,GAVqB,CAWrB;;IACA,IAAI5B,WAAW,CAACe,MAAZ,KAAuB,CAA3B,EAA8B;MAC1Bf,WAAW,GAAG,KAAKhC,QAAnB;IACH;;IACD,MAAM6D,cAAc,GAAG,KAAK1B,iBAAL,CAAuBL,UAAvB,EAAmCE,WAAnC,CAAvB,CAfqB,CAgBrB;;IACA,IAAI8B,YAAY,GAAG,KAAKtE,WAAL,CAAiBuE,GAAjB,CAAqBF,cAArB,CAAnB;;IACA,IAAIC,YAAY,IAAI,IAApB,EAA0B;MACtBA,YAAY,GAAG,KAAKtB,OAAL,CAAarC,MAAb,EAAqB6B,WAArB,CAAf;MACA,KAAKxC,WAAL,CAAiBwE,GAAjB,CAAqBH,cAArB,EAAqCC,YAArC;IACH;;IACD,MAAMG,cAAc,GAAG,EAAvB;IACA,MAAMC,aAAa,GAAG,EAAtB;IACA,OAAO1F,IAAI,CAAC,MAAM;MACd,MAAM2F,OAAO,GAAG,IAAInF,gBAAJ,CAAqB,KAAKgC,SAA1B,EAAqCiD,cAArC,EAAqDC,aAArD,EAAoE,KAAKnD,mBAAzE,CAAhB;MACA,MAAMqD,UAAU,GAAG3D,MAAM,CAAC4D,MAAP,CAAc,EAAd,EAAkB,KAAKrD,SAAvB,CAAnB;MACAP,MAAM,CAACC,IAAP,CAAYP,MAAZ,EAAoBQ,OAApB,CAA4BC,IAAI,IAAI;QAChC,MAAM,CAAC0D,QAAD,EAAWC,KAAX,IAAoBzF,aAAa,CAAC8B,IAAD,CAAvC;QACA,MAAM4D,OAAO,GAAG,EAAhB;QACAA,OAAO,CAACD,KAAD,CAAP,GAAiBpE,MAAM,CAACS,IAAD,CAAvB;QACAwD,UAAU,CAACE,QAAD,CAAV,GAAuBE,OAAvB;MACH,CALD;MAMA,MAAMC,aAAa,GAAG,KAAKC,kBAAL,CAAwBN,UAAxB,CAAtB;MACA,MAAMO,+BAA+B,GAAG,EAAxC;;MACA,KAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGd,YAAY,CAACf,MAAjC,EAAyC6B,CAAC,EAA1C,EAA8C;QAC1C,MAAMpD,IAAI,GAAGsC,YAAY,CAACc,CAAD,CAAzB;;QACA,IAAI,CAACR,UAAU,CAAC5C,IAAI,CAACZ,IAAN,CAAf,EAA4B;UACxB,MAAM4D,OAAO,GAAGzF,SAAS,CAACyC,IAAD,EAAO4C,UAAP,EAAmBD,OAAnB,EAA4B,KAAK5C,gBAAjC,CAAzB;;UACA,IAAI9C,IAAI,CAACoG,SAAL,CAAeL,OAAf,CAAJ,EAA6B;YACzB,MAAM,IAAI3B,KAAJ,CAAW,4BAA2BrB,IAAI,CAACsB,EAAG,wBAApC,GACX,0CADC,CAAN;UAEH;;UACDsB,UAAU,CAAC5C,IAAI,CAACZ,IAAN,CAAV,GAAwB4D,OAAxB;UACA,KAAKM,sBAAL,CAA4BtD,IAAI,CAACZ,IAAjC,EAAuCY,IAAvC,EAA6C4C,UAA7C,EAAyDD,OAAzD,EAAkEM,aAAlE,EAAiFd,eAAjF,EAAkGgB,+BAAlG;QACH;MACJ,CAtBa,CAuBd;;;MACA,IAAI,KAAKpF,MAAL,IAAe,IAAnB,EAAyB;QACrB4E,OAAO,CAACY,OAAR,CAAgBN,aAAhB;MACH;;MACD,OAAOxE,OAAO,CAACgB,GAAR,CAAYL,IAAI,IAAIhC,SAAS,CAACgC,IAAD,EAAOwD,UAAP,EAAmBD,OAAnB,CAA7B,CAAP;IACH,CA5BU,CAAX;EA6BH;;EACDO,kBAAkB,CAACM,SAAD,EAAY;IAC1B,MAAMC,GAAG,GAAG,GAAG5D,MAAH,CAAU6D,KAAV,CAAgB,EAAhB,EAAoBzE,MAAM,CAACC,IAAP,CAAYsE,SAAZ,EAC3B/D,GAD2B,CACvBC,GAAG,IAAI8D,SAAS,CAAC9D,GAAD,CADO,EAE3BD,GAF2B,CAEvBuD,OAAO,IAAIA,OAAO,CAACvD,GAAR,CAAYE,MAAM,IAAIA,MAAM,CAACC,EAA7B,CAFY,CAApB,CAAZ;IAGA,OAAO,IAAI+D,GAAJ,CAAQF,GAAR,CAAP;EACH;;EACDH,sBAAsB,CAACR,QAAD,EAAW9C,IAAX,EAAiBwD,SAAjB,EAA4Bb,OAA5B,EAAqCM,aAArC,EAAoDW,WAApD,EAAiET,+BAAjE,EAAkG;IACpH;IACA;IACA,IAAInD,IAAI,CAAC6D,QAAL,KAAkB,SAAlB,IAA+BD,WAAW,CAACE,OAAZ,CAAoBhB,QAApB,MAAkC,CAAC,CAAtE,EAAyE;MACrE;IACH;;IACDU,SAAS,CAACV,QAAD,CAAT,CAAoB3D,OAApB,CAA4BQ,MAAM,IAAI;MAClC,IAAIA,MAAM,IAAI,IAAd,EAAoB;QAChBwD,+BAA+B,CAACxD,MAAM,CAACC,EAAR,CAA/B,GACI,CAACuD,+BAA+B,CAACxD,MAAM,CAACC,EAAR,CAA/B,IAA8C,CAA/C,IACII,IAAI,CAAC+D,QAAL,CAAcxC,MAFtB;MAGH;IACJ,CAND;IAOAvB,IAAI,CAACrB,MAAL,CAAYQ,OAAZ,CAAoB6E,KAAK,IAAI;MACzB;MACA;MACA,IAAIA,KAAK,CAACH,QAAN,KAAmB,SAAvB,EAAkC;QAC9B,MAAMb,OAAO,GAAG3F,4BAA4B,CAAC2G,KAAK,CAAC5E,IAAP,EAAaoE,SAAb,EAAwBb,OAAxB,CAA5C;;QACA,IAAIK,OAAO,IAAI,IAAf,EAAqB;UACjBA,OAAO,CAAC7D,OAAR,CAAgBQ,MAAM,IAAI;YACtB,IAAIA,MAAM,IAAI,CAACA,MAAM,CAACsE,IAAlB,IAA0B,CAAChB,aAAa,CAACiB,GAAd,CAAkBvE,MAAM,CAACC,EAAzB,CAA/B,EAA6D;cACzD,MAAMuE,KAAK,GAAGhB,+BAA+B,CAACxD,MAAM,CAACC,EAAR,CAA7C;;cACA,IAAIuE,KAAK,KAAK,CAAd,EAAiB;gBACb,IAAI,CAAC,KAAK5F,kBAAV,EAA8B;kBAC1BoB,MAAM,CAAC4D,OAAP;gBACH,CAFD,MAGK;kBACD,MAAM,CAACT,QAAD,EAAWC,KAAX,IAAoB7F,mBAAmB,CAAC8C,IAAI,CAACZ,IAAN,EAAYuD,OAAZ,CAA7C;;kBACA,IAAI,KAAKrE,mBAAL,CAAyBwE,QAAzB,CAAJ,EAAwC;oBACpC,KAAKxE,mBAAL,CAAyBwE,QAAzB,EAAmCC,KAAnC,IAA4CpD,MAA5C;kBACH,CAFD,MAGK;oBACD,KAAKrB,mBAAL,CAAyBwE,QAAzB,IAAqC,EAArC;oBACA,KAAKxE,mBAAL,CAAyBwE,QAAzB,EAAmCC,KAAnC,IAA4CpD,MAA5C;kBACH;gBACJ;;gBACD,OAAOwD,+BAA+B,CAACxD,MAAM,CAACC,EAAR,CAAtC;cACH,CAfD,MAgBK,IAAIuE,KAAK,IAAI,IAAb,EAAmB;gBACpB;gBACA;gBACAhB,+BAA+B,CAACxD,MAAM,CAACC,EAAR,CAA/B;cACH;YACJ;UACJ,CAzBD;QA0BH;MACJ;IACJ,CAlCD;EAmCH;EACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACUwE,YAAY,CAACzF,MAAD,EAASF,OAAT,EAAkB;IAAA;;IAAA;MAChC,OAAO,KAAI,CAAC4F,aAAL,CAAmB1F,MAAnB,EAA2BF,OAA3B,CAAP;IADgC;EAEnC;;EACD6F,0BAA0B,GAAG;IACzB,IAAI,CAAC,KAAKhG,mBAAV,EAA+B;MAC3B;IACH;;IACDW,MAAM,CAACC,IAAP,CAAY,KAAKZ,mBAAjB,EACKa,OADL,CACaO,GAAG,IAAI,KAAKpB,mBAAL,CAAyBoB,GAAzB,EAA8BP,OAA9B,CAAsCQ,MAAM,IAAIA,MAAM,CAAC4D,OAAP,EAAhD,CADpB;IAEA,KAAKgB,iBAAL;EACH;;EACDA,iBAAiB,GAAG;IAChB,IAAI,CAAC,KAAK3B,UAAV,EAAsB;MAClB;IACH;;IACD3D,MAAM,CAACC,IAAP,CAAY,KAAK0D,UAAjB,EAA6BzD,OAA7B,CAAqCO,GAAG,IAAI;MACxC,MAAM8E,WAAW,GAAG,KAAK5B,UAAL,CAAgBlD,GAAhB,CAApB;MACA8E,WAAW,CAACrF,OAAZ,CAAoBQ,MAAM,IAAI;QAC1B,IAAIA,MAAM,IAAI,CAACA,MAAM,CAACsE,IAAlB,IAA0B,CAACtE,MAAM,CAAC8E,UAAlC,IACA,CAAC,KAAKC,OAAL,CAAaR,GAAb,CAAiBvE,MAAM,CAACC,EAAxB,CADL,EACkC;UAC9BD,MAAM,CAAC4D,OAAP;QACH;MACJ,CALD;IAMH,CARD;EASH;;EACDoB,sBAAsB,GAAG;IACrB,OAAO,KAAK/B,UAAZ;EACH;;EACDR,wBAAwB,GAAG;IACvB,KAAK,MAAM1C,GAAX,IAAkB,KAAKpB,mBAAvB,EAA4C;MACxC,KAAKA,mBAAL,CAAyBoB,GAAzB,EAA8BP,OAA9B,CAAsCQ,MAAM,IAAIA,MAAM,CAAC4D,OAAP,EAAhD;MACA,OAAO,KAAKjF,mBAAL,CAAyBoB,GAAzB,CAAP;IACH;EACJ;EACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACU2E,aAAa,CAAC1F,MAAD,EAASF,OAAT,EAAkBmG,mBAAmB,GAAG,KAAxC,EAA+CnC,cAAc,GAAG,EAAhE,EAAoEC,aAAa,GAAG,EAApF,EAAwF;IAAA;;IAAA;MACvG,IAAI,CAACkC,mBAAL,EAA0B;QACtBjG,MAAM,GAAG,MAAI,CAACiD,SAAL,CAAejD,MAAf,CAAT;;QACA,MAAI,CAACmD,WAAL,CAAiBnD,MAAjB;;QACA,MAAI,CAACoD,sBAAL,CAA4BpD,MAA5B;;QACAF,OAAO,GAAG,MAAI,CAACuD,UAAL,CAAgBvD,OAAhB,CAAV;;QACA,MAAI,CAACwD,YAAL,CAAkBxD,OAAlB;MACH,CAPsG,CAQvG;;;MACA,IAAI;QACA,MAAI,CAACF,kBAAL,GAA0BxB,GAAG,GAAG8H,OAAN,CAAc,2BAAd,CAA1B;MACH,CAFD,CAGA,OAAOC,CAAP,EAAU;QACNC,OAAO,CAACC,IAAR,CAAaF,CAAC,CAACG,OAAf;MACH;;MACD,MAAI,CAAC7C,wBAAL;;MACA,MAAMO,OAAO,GAAG,IAAInF,gBAAJ,CAAqB,MAAI,CAACgC,SAA1B,EAAqCiD,cAArC,EAAqDC,aAArD,EAAoE,MAAI,CAACnD,mBAAzE,CAAhB,CAhBuG,CAiBvG;MACA;MACA;;MACA,MAAI,CAACqD,UAAL,SAAwB,MAAI,CAACsC,sBAAL,CAA4BvG,MAA5B,EAAoCgE,OAApC,EAA6ClE,OAA7C,EAAsDmG,mBAAtD,CAAxB;MACA,MAAMO,OAAO,GAAG1G,OAAO,CAACgB,GAAR,CAAYL,IAAI,IAAIhC,SAAS,CAACgC,IAAD,EAAO,MAAI,CAACwD,UAAZ,EAAwBD,OAAxB,CAA7B,CAAhB,CArBuG,CAsBvG;;MACA,MAAMyC,SAAS,GAAGD,OAAO,CAAC1F,GAAR,CAAY4F,CAAC,IAAIA,CAAC,CAACzF,EAAnB,CAAlB;MACA,MAAM0F,QAAQ,GAAGrG,MAAM,CAACC,IAAP,CAAYP,MAAZ,EAAoBc,GAApB,CAAwBL,IAAI,IAAIT,MAAM,CAACS,IAAD,CAAN,CAAaQ,EAA7C,CAAjB;MACA,MAAI,CAAC8E,OAAL,GACI,IAAIf,GAAJ,CAAQ,CAAC,GAAGyB,SAAJ,EAAe,GAAGE,QAAlB,EAA4B,GAAG,MAAI,CAACjG,SAApC,CAAR,CADJ;;MAEA,IAAI,CAAC,MAAI,CAACd,kBAAV,EAA8B;QAC1B,MAAI,CAACgG,iBAAL;MACH,CA7BsG,CA8BvG;;;MACA,IAAI,MAAI,CAACxG,MAAL,IAAe,IAAnB,EAAyB;QACrB4E,OAAO,CAACY,OAAR,CAAgB,MAAI,CAACmB,OAArB;MACH;;MACD,OAAOS,OAAP;IAlCuG;EAmC1G;;EACKI,oBAAoB,CAAC5G,MAAD,EAAS8D,cAAT,EAAyBC,aAAzB,EAAwC;IAAA;;IAAA;MAC9D,MAAM8C,YAAY,GAAG7G,MAAM,CAAC+B,MAAP,CAAc,CAACjB,GAAD,EAAME,MAAN,EAAcoD,KAAd,KAAwB;QACvDtD,GAAG,CAAC,MAAI,CAACd,MAAL,CAAYoE,KAAZ,EAAmB3D,IAApB,CAAH,GAA+BO,MAA/B;QACA,OAAOF,GAAP;MACH,CAHoB,EAGlB,EAHkB,CAArB;MAIA,OAAO,MAAI,CAAC4E,aAAL,CAAmBmB,YAAnB,EAAiC,MAAI,CAAChF,WAAtC,EAAmD,IAAnD,EAAyDiC,cAAzD,EAAyEC,aAAzE,CAAP;IAL8D;EAMjE;EACD;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;EACUwC,sBAAsB,CAACvG,MAAD,EAASgE,OAAT,EAAkBiB,WAAlB,EAA+BgB,mBAA/B,EAAoD;IAAA;;IAAA;MAC5E,MAAM/C,KAAK,GAAG5C,MAAM,CAACC,IAAP,CAAYP,MAAZ,CAAd;MACA,MAAM2B,UAAU,GAAGuB,KAAK,CAACpC,GAAN,CAAUL,IAAI,IAAI,MAAI,CAACtB,KAAL,CAAWoE,KAAX,CAAiB5E,aAAa,CAAC8B,IAAD,CAAb,CAAoB,CAApB,CAAjB,CAAlB,CAAnB;MACA,MAAM+C,eAAe,GAAGyB,WAAW,CAACnE,GAAZ,CAAgBL,IAAI,IAAI9B,aAAa,CAAC8B,IAAD,CAAb,CAAoB,CAApB,CAAxB,CAAxB;MACA,IAAIoB,WAAW,GAAG2B,eAAe,CAAC1C,GAAhB,CAAoBL,IAAI,IAAI,MAAI,CAACtB,KAAL,CAAWoE,KAAX,CAAiB9C,IAAjB,CAA5B,CAAlB,CAJ4E,CAK5E;;MACA,IAAIoB,WAAW,CAACe,MAAZ,KAAuB,CAA3B,EAA8B;QAC1Bf,WAAW,GAAG,MAAI,CAAChC,QAAnB;MACH;;MACD,MAAM;QAAEiH,SAAF;QAAavE,aAAb;QAA4BC,WAA5B;QAAyCC;MAAzC,IAAwD3D,oBAAoB,CAACkB,MAAD,EAAS6B,WAAT,EAAsB,MAAI,CAAChB,SAA3B,EAAsC,MAAI,CAACZ,UAA3C,CAAlF,CAT4E,CAU5E;;MACA,MAAM8G,KAAK,GAAG,CACV,GAAGpF,UADO,EACK,GAAG,MAAI,CAACxC,KAAL,CAAW6H,OADnB,EAC4B,IAAI,MAAI,CAAC/G,UAAL,IAAmB,EAAvB,CAD5B,EAEZa,GAFY,CAERO,IAAI,IAAI;QACV,OAAO;UAAEA,IAAF;UAAQ4F,QAAQ,EAAEjD,OAAO,CAACkD;QAA1B,CAAP;MACH,CAJa,CAAd;MAKA,MAAMjD,UAAU,GAAG3D,MAAM,CAAC4D,MAAP,CAAc,EAAd,EAAkB,MAAI,CAACrD,SAAvB,CAAnB;MACAP,MAAM,CAACC,IAAP,CAAYP,MAAZ,EAAoBQ,OAApB,CAA4BC,IAAI,IAAI;QAChC,MAAM,CAAC0D,QAAD,EAAWC,KAAX,IAAoBzF,aAAa,CAAC8B,IAAD,CAAvC;QACA,MAAM4D,OAAO,GAAG,EAAhB;QACAA,OAAO,CAACD,KAAD,CAAP,GAAiBpE,MAAM,CAACS,IAAD,CAAvB;QACAwD,UAAU,CAACE,QAAD,CAAV,GAAuBE,OAAvB;MACH,CALD;MAMA,MAAMG,+BAA+B,GAAG,EAAxC;;MACA,MAAMF,aAAa,GAAG,MAAI,CAACC,kBAAL,CAAwBN,UAAxB,CAAtB;;MACA,MAAMkD,KAAK,GAAG,EAAd;;MACA,OAAOJ,KAAK,CAACnE,MAAN,GAAe,CAAtB,EAAyB;QACrB,MAAMwE,QAAQ,GAAG,MAAI,CAACC,YAAL,CAAkB1F,UAAlB,EAA8BoF,KAA9B,EAAqC/C,OAArC,EAA8CC,UAA9C,EAA0DkD,KAA1D,EAAiE7C,aAAjE,EAAgFd,eAAhF,EAAiGgB,+BAAjG,EAAkIsC,SAAlI,CAAjB;;QACA,MAAMQ,OAAO,CAACC,GAAR,CAAYH,QAAZ,CAAN;MACH;;MACD,IAAI5E,WAAW,IAAI,IAAf,IAAuB,CAACyD,mBAA5B,EAAiD;QAC7CG,OAAO,CAACC,IAAR,CAAc,mEAAD,GACR,gEADL;MAEH;;MACD,MAAMmB,cAAc,GAAG3F,WAAW,CAC7B4F,MADkB,CACXpG,IAAI,IAAI,CAACrC,aAAa,CAACqC,IAAD,CAAd,IAChB,CAAC5C,SAAS,CAAC4C,IAAI,CAACZ,IAAN,EAAYwD,UAAZ,EAAwBD,OAAxB,CAFS,EAGlBlD,GAHkB,CAGdO,IAAI,IAAIA,IAAI,CAACZ,IAHC,CAAvB;;MAIA,IAAI+G,cAAc,CAAC5E,MAAf,GAAwB,CAA5B,EAA+B;QAC3B,IAAI8E,cAAc,GAAG,EAArB;;QACA,IAAIlF,WAAW,IAAI,IAAnB,EAAyB;UACrBkF,cAAc,GACT,+DAAD,GACK,2BAA0BjF,UAAW,GAF9C;QAGH;;QACD,MAAM,IAAIC,KAAJ,CAAW,+BAA8B8E,cAAe,sBAA9C,GACX,WAAUtE,KAAM,8CADL,GAEX,IAAGX,aAAc,MAAKmF,cAAe,EAFpC,CAAN;MAGH;;MACD,OAAOzD,UAAP;IAjD4E;EAkD/E;;EACDoD,YAAY,CAAC1F,UAAD,EAAaoF,KAAb,EAAoB/C,OAApB,EAA6Ba,SAA7B,EAAwCsC,KAAxC,EAA+C7C,aAA/C,EAA8DW,WAA9D,EAA2ET,+BAA3E,EAA4GsC,SAA5G,EAAuH;IAC/H,MAAMM,QAAQ,GAAG,EAAjB;;IACA,OAAOL,KAAK,CAACnE,MAAN,GAAe,CAAtB,EAAyB;MACrB,MAAM+E,IAAI,GAAGZ,KAAK,CAACa,GAAN,EAAb;MACA5D,OAAO,CAACkD,cAAR,GAAyBS,IAAI,CAACV,QAA9B;MACA,IAAI9C,QAAQ,GAAG,EAAf,CAHqB,CAIrB;MACA;MACA;;MACA,IAAIwD,IAAI,CAACtG,IAAL,CAAUsB,EAAV,KAAiB,OAAjB,IACAnE,aAAa,CAAC,YAAD,EAAemJ,IAAI,CAACtG,IAApB,EAA0BwD,SAA1B,EAAqCb,OAArC,CADjB,EACgE;QAC5D,CAACG,QAAD,IAAa5F,mBAAmB,CAACoJ,IAAI,CAACtG,IAAL,CAAUZ,IAAX,EAAiBuD,OAAjB,CAAhC;MACH,CAVoB,CAWrB;MACA;;;MACA,IAAIa,SAAS,CAAC8C,IAAI,CAACtG,IAAL,CAAUZ,IAAX,CAAT,IAA6B,IAAjC,EAAuC;QACnC,MAAM4D,OAAO,GAAGzF,SAAS,CAAC+I,IAAI,CAACtG,IAAN,EAAYwD,SAAZ,EAAuBb,OAAvB,EAAgC,KAAK5C,gBAArC,CAAzB;;QACA,IAAI,CAAC+C,QAAL,EAAe;UACX,CAACA,QAAD,IAAa5F,mBAAmB,CAACoJ,IAAI,CAACtG,IAAL,CAAUZ,IAAX,EAAiBuD,OAAjB,CAAhC;QACH;;QACD,MAAMkD,cAAc,GAAGlD,OAAO,CAACkD,cAA/B;;QACA,IAAI5I,IAAI,CAACoG,SAAL,CAAeL,OAAf,CAAJ,EAA6B;UACzB+C,QAAQ,CAACS,IAAT,CAAcxD,OAAO,CAACyD,IAAR,CAAapB,CAAC,IAAI;YAC5B7B,SAAS,CAACV,QAAD,CAAT,GAAsBuC,CAAtB;YACA1C,OAAO,CAACkD,cAAR,GAAyBA,cAAzB;YACA,KAAKvC,sBAAL,CAA4BR,QAA5B,EAAsCwD,IAAI,CAACtG,IAA3C,EAAiDwD,SAAjD,EAA4Db,OAA5D,EAAqEM,aAArE,EAAoFW,WAApF,EAAiGT,+BAAjG;YACA,KAAKuD,iBAAL,CAAuBJ,IAAI,CAACtG,IAA5B,EAAkC0F,KAAlC,EAAyC/C,OAAzC,EAAkDa,SAAlD,EAA6DsC,KAA7D,EAAoEL,SAApE;YACA,OAAOJ,CAAP;UACH,CANa,CAAd;QAOH,CARD,MASK;UACD7B,SAAS,CAACV,QAAD,CAAT,GAAsBE,OAAtB;UACA,KAAKM,sBAAL,CAA4BR,QAA5B,EAAsCwD,IAAI,CAACtG,IAA3C,EAAiDwD,SAAjD,EAA4Db,OAA5D,EAAqEM,aAArE,EAAoFW,WAApF,EAAiGT,+BAAjG;UACA,KAAKuD,iBAAL,CAAuBJ,IAAI,CAACtG,IAA5B,EAAkC0F,KAAlC,EAAyC/C,OAAzC,EAAkDa,SAAlD,EAA6DsC,KAA7D,EAAoEL,SAApE;QACH;MACJ,CApBD,MAqBK;QACD,KAAKiB,iBAAL,CAAuBJ,IAAI,CAACtG,IAA5B,EAAkC0F,KAAlC,EAAyC/C,OAAzC,EAAkDa,SAAlD,EAA6DsC,KAA7D,EAAoEL,SAApE;MACH;IACJ;;IACD,OAAOM,QAAP;EACH;;EACDW,iBAAiB,CAAC1G,IAAD,EAAO0F,KAAP,EAAc/C,OAAd,EAAuBa,SAAvB,EAAkCsC,KAAlC,EAAyCL,SAAzC,EAAoD;IACjEzF,IAAI,CAAC+D,QAAL,CAAc5E,OAAd,CAAuBwH,SAAD,IAAe;MACjC,MAAM,CAAC7D,QAAD,IAAc5F,mBAAmB,CAACyJ,SAAS,CAACvH,IAAX,EAAiBuD,OAAjB,CAAvC;;MACA,IAAImD,KAAK,CAAChD,QAAD,CAAL,IAAmB,CAAC2C,SAAS,CAACvB,GAAV,CAAcyC,SAAS,CAACvH,IAAxB,CAAxB,EAAuD;QACnD;MACH,CAJgC,CAKjC;;;MACA,IAAIuH,SAAS,CAACrF,EAAV,KAAiB,OAArB,EAA8B;QAC1B,IAAIqF,SAAS,CAACC,UAAV,CAAqBC,IAArB,CAA0BzH,IAAI,IAAI;UAClC,OAAO,CAAC,CAAChC,SAAS,CAACgC,IAAD,EAAOoE,SAAP,EAAkBb,OAAlB,CAAlB;QACH,CAFG,CAAJ,EAEI;UACAmD,KAAK,CAAChD,QAAD,CAAL,GAAkB,IAAlB;UACA4C,KAAK,CAACc,IAAN,CAAW;YAAEZ,QAAQ,EAAEjD,OAAO,CAACkD,cAApB;YAAoC7F,IAAI,EAAE2G;UAA1C,CAAX;QACH;MACJ,CAPD,MAQK;QACJ,IAAIA,SAAS,CAACC,UAAV,CAAqBE,KAArB,CAA2B1H,IAAI,IAAI;UACpC,OAAO,CAAC,CAAChC,SAAS,CAACgC,IAAD,EAAOoE,SAAP,EAAkBb,OAAlB,CAAlB;QACH,CAFI,CAAJ,EAEG;UACAmD,KAAK,CAAChD,QAAD,CAAL,GAAkB,IAAlB;UACA4C,KAAK,CAACc,IAAN,CAAW;YAAEZ,QAAQ,EAAEjD,OAAO,CAACkD,cAApB;YAAoC7F,IAAI,EAAE2G;UAA1C,CAAX;QACH;IACJ,CArBD;EAsBH;EACD;AACJ;AACA;;;EACIpD,OAAO,GAAG;IACNtE,MAAM,CAACC,IAAP,CAAY,KAAKM,SAAjB,EACKL,OADL,CACaO,GAAG,IAAI,KAAKF,SAAL,CAAeE,GAAf,EAAoBP,OAApB,CAA4BQ,MAAM,IAAIA,MAAM,CAAC4D,OAAP,EAAtC,CADpB;EAEH;;EACDxB,sBAAsB,CAACpD,MAAD,EAAS;IAC3BM,MAAM,CAACC,IAAP,CAAYP,MAAZ,EAAoBQ,OAApB,CAA4BC,IAAI,IAAI;MAChC,MAAM4E,KAAK,GAAGrF,MAAM,CAACS,IAAD,CAApB;MACA,MAAM,CAAC0D,QAAD,IAAcxF,aAAa,CAAC8B,IAAD,CAAjC;MACA,MAAMY,IAAI,GAAG,KAAKlC,KAAL,CAAWoE,KAAX,CAAiBY,QAAjB,CAAb;;MACA,IAAI9C,IAAI,CAACE,UAAL,CAAgB,OAAhB,KAA4BF,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KAAzD,EAAgE;QAC5D,MAAMF,KAAK,GAAGD,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KAAvC;QACA,MAAM4G,KAAK,GAAG9G,KAAK,CAACsB,MAAN,KAAiByC,KAAK,CAAC/D,KAAN,CAAYsB,MAA7B,IACVyC,KAAK,CAAC/D,KAAN,CAAY6G,KAAZ,CAAkB,CAACE,GAAD,EAAMjE,KAAN,KAAgB9C,KAAK,CAAC8C,KAAD,CAAL,KAAiB,CAAC,CAAlB,IAAuB9C,KAAK,CAAC8C,KAAD,CAAL,KAAiBiE,GAA1E,CADJ;QAEA/J,IAAI,CAACgK,MAAL,CAAYF,KAAZ,EAAmB,MAAO,sBAAqB/G,IAAI,CAACZ,IAAK,iBAAhC,GACpB,gCAA+Ba,KAAM,aADjB,GAEpB,IAAG+D,KAAK,CAAC/D,KAAM,GAFpB;MAGH;;MACD,IAAID,IAAI,CAACE,UAAL,CAAgB,OAAhB,KAA4BF,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KAAzD,EAAgE;QAC5DlD,IAAI,CAACgK,MAAL,CAAYjD,KAAK,CAAC3D,KAAN,KAAgBL,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KAArD,EAA4D,MAAO,sBAAqBH,IAAI,CAACZ,IAAK,iBAAhC,GAC7D,8BAD6D,GAE7D,GAAEY,IAAI,CAACE,UAAL,CAAgB,OAAhB,EAAyBC,KAAM,aAAY6D,KAAK,CAAC3D,KAAM,EAF9D;MAGH;IACJ,CAjBD;EAkBH;;EACDuB,SAAS,CAACjD,MAAD,EAAS;IACd,MAAMuI,MAAM,GAAG,EAAf;;IACA,KAAK,MAAMC,SAAX,IAAwBxI,MAAxB,EAAgC;MAC5B,IAAI,KAAKG,UAAL,IAAmB,IAAnB,IAA2B,KAAKA,UAAL,CAAgBH,MAAhB,IAA0B,IAArD,IACA,KAAKG,UAAL,CAAgBH,MAAhB,CAAuBwI,SAAvB,KAAqC,IADzC,EAC+C;QAC3C,MAAMxH,MAAM,GAAG,KAAKb,UAAL,CAAgBH,MAAhB,CAAuBwI,SAAvB,CAAf;QACAD,MAAM,CAACvH,MAAM,CAACP,IAAR,CAAN,GAAsBT,MAAM,CAACwI,SAAD,CAA5B;MACH,CAJD,MAKK;QACDD,MAAM,CAACC,SAAD,CAAN,GAAoBxI,MAAM,CAACwI,SAAD,CAA1B;MACH;IACJ;;IACD,OAAOD,MAAP;EACH;;EACDpF,WAAW,CAACnD,MAAD,EAAS;IAChB,MAAMyI,UAAU,GAAGnI,MAAM,CAACC,IAAP,CAAYP,MAAZ,EAAoByH,MAApB,CAA2BhH,IAAI,IAAI;MAClD,MAAM,CAAC0D,QAAD,IAAaxF,aAAa,CAAC8B,IAAD,CAAhC;MACA,OAAO,KAAKtB,KAAL,CAAWoE,KAAX,CAAiBY,QAAjB,KAA8B,IAArC;IACH,CAHkB,CAAnB;;IAIA,IAAIsE,UAAU,CAAC7F,MAAX,GAAoB,CAAxB,EAA2B;MACvB,MAAM,IAAIF,KAAJ,CAAW,+CAAD,GACX,UAAS+F,UAAW,8BADnB,CAAN;IAEH;EACJ;;EACDpF,UAAU,CAACvD,OAAD,EAAU;IAChB,OAAOA,OAAO,CAACgB,GAAR,CAAYL,IAAI,IAAI;MACvB,IAAI,KAAKN,UAAL,IAAmB,IAAnB,IAA2B,KAAKA,UAAL,CAAgBL,OAAhB,IAA2B,IAAtD,IACA,KAAKK,UAAL,CAAgBL,OAAhB,CAAwBW,IAAxB,KAAiC,IADrC,EAC2C;QACvC,MAAMO,MAAM,GAAG,KAAKb,UAAL,CAAgBL,OAAhB,CAAwBW,IAAxB,CAAf;QACA,OAAOO,MAAM,CAACP,IAAd;MACH;;MACD,OAAOA,IAAP;IACH,CAPM,EAOJ,EAPI,CAAP;EAQH;;EACD6C,YAAY,CAACxD,OAAD,EAAU;IAClBA,OAAO,CAACU,OAAR,CAAgBC,IAAI,IAAI;MACpB,MAAM,CAACiI,cAAD,IAAmB/J,aAAa,CAAC8B,IAAD,CAAtC;;MACA,IAAI,CAAC,KAAKtB,KAAL,CAAWoE,KAAX,CAAiBmF,cAAjB,CAAL,EAAuC;QACnC,MAAM,IAAIhG,KAAJ,CAAW,eAAcjC,IAAK,6BAA9B,CAAN;MACH;IACJ,CALD;EAMH;;AAxhBsB"},"metadata":{},"sourceType":"module"}