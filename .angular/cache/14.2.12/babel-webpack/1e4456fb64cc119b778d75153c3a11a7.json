{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, sumOutType, util } from '@tensorflow/tfjs-core';\nimport { reduce } from '../kernel_utils/reduce';\nimport { reshape } from './Reshape';\nimport { transposeImpl } from './Transpose_impl';\nexport function sumImpl(x, axis, keepDims, backend) {\n  const reductionIndices = axis;\n  const xRank = x.shape.length;\n  const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n  let axes = origAxes;\n  const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n  const sumInputIsTransposed = permutedAxes != null;\n  let sumInput = x;\n\n  if (sumInputIsTransposed) {\n    sumInput = transposeImpl(x, permutedAxes, backend);\n    axes = backend_util.getInnerMostAxes(axes.length, xRank);\n  }\n\n  backend_util.assertAxesAreInnerMostDims('sum', axes, xRank);\n  const [sumOutShape, reduceShape] = backend_util.computeOutAndReduceShapes(sumInput.shape, axes);\n  let outShape = sumOutShape;\n\n  if (keepDims) {\n    // rather than reshape at the end, set the target shape here.\n    outShape = backend_util.expandShapeToKeepDim(sumOutShape, origAxes);\n  }\n\n  const inSize = util.sizeFromShape(reduceShape);\n  const xSize = util.sizeFromShape(x.shape);\n  const batchSize = xSize / inSize;\n  const reshapedInput = reshape({\n    inputs: {\n      x: sumInput\n    },\n    attrs: {\n      shape: [batchSize, inSize]\n    },\n    backend\n  });\n  const outType = sumOutType(x.dtype);\n  const reduced = reduce(reshapedInput, outType, 'sum', backend);\n  const out = reshape({\n    inputs: {\n      x: reduced\n    },\n    attrs: {\n      shape: outShape\n    },\n    backend\n  });\n  backend.disposeIntermediateTensorInfo(reshapedInput);\n  backend.disposeIntermediateTensorInfo(reduced);\n\n  if (sumInputIsTransposed) {\n    backend.disposeIntermediateTensorInfo(sumInput);\n  }\n\n  return out;\n}","map":{"version":3,"names":["backend_util","sumOutType","util","reduce","reshape","transposeImpl","sumImpl","x","axis","keepDims","backend","reductionIndices","xRank","shape","length","origAxes","parseAxisParam","axes","permutedAxes","getAxesPermutation","sumInputIsTransposed","sumInput","getInnerMostAxes","assertAxesAreInnerMostDims","sumOutShape","reduceShape","computeOutAndReduceShapes","outShape","expandShapeToKeepDim","inSize","sizeFromShape","xSize","batchSize","reshapedInput","inputs","attrs","outType","dtype","reduced","out","disposeIntermediateTensorInfo"],"sources":["C:/Users/Anke/Documents/Feelix documents/Feelix2.0-dev/Feelix v2/node_modules/@tensorflow/tfjs-backend-webgl/dist/kernels/Sum_impl.js"],"sourcesContent":["/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, sumOutType, util } from '@tensorflow/tfjs-core';\nimport { reduce } from '../kernel_utils/reduce';\nimport { reshape } from './Reshape';\nimport { transposeImpl } from './Transpose_impl';\nexport function sumImpl(x, axis, keepDims, backend) {\n    const reductionIndices = axis;\n    const xRank = x.shape.length;\n    const origAxes = util.parseAxisParam(reductionIndices, x.shape);\n    let axes = origAxes;\n    const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n    const sumInputIsTransposed = permutedAxes != null;\n    let sumInput = x;\n    if (sumInputIsTransposed) {\n        sumInput = transposeImpl(x, permutedAxes, backend);\n        axes = backend_util.getInnerMostAxes(axes.length, xRank);\n    }\n    backend_util.assertAxesAreInnerMostDims('sum', axes, xRank);\n    const [sumOutShape, reduceShape] = backend_util.computeOutAndReduceShapes(sumInput.shape, axes);\n    let outShape = sumOutShape;\n    if (keepDims) {\n        // rather than reshape at the end, set the target shape here.\n        outShape = backend_util.expandShapeToKeepDim(sumOutShape, origAxes);\n    }\n    const inSize = util.sizeFromShape(reduceShape);\n    const xSize = util.sizeFromShape(x.shape);\n    const batchSize = xSize / inSize;\n    const reshapedInput = reshape({ inputs: { x: sumInput }, attrs: { shape: [batchSize, inSize] }, backend });\n    const outType = sumOutType(x.dtype);\n    const reduced = reduce(reshapedInput, outType, 'sum', backend);\n    const out = reshape({ inputs: { x: reduced }, attrs: { shape: outShape }, backend });\n    backend.disposeIntermediateTensorInfo(reshapedInput);\n    backend.disposeIntermediateTensorInfo(reduced);\n    if (sumInputIsTransposed) {\n        backend.disposeIntermediateTensorInfo(sumInput);\n    }\n    return out;\n}\n"],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,SAASA,YAAT,EAAuBC,UAAvB,EAAmCC,IAAnC,QAA+C,uBAA/C;AACA,SAASC,MAAT,QAAuB,wBAAvB;AACA,SAASC,OAAT,QAAwB,WAAxB;AACA,SAASC,aAAT,QAA8B,kBAA9B;AACA,OAAO,SAASC,OAAT,CAAiBC,CAAjB,EAAoBC,IAApB,EAA0BC,QAA1B,EAAoCC,OAApC,EAA6C;EAChD,MAAMC,gBAAgB,GAAGH,IAAzB;EACA,MAAMI,KAAK,GAAGL,CAAC,CAACM,KAAF,CAAQC,MAAtB;EACA,MAAMC,QAAQ,GAAGb,IAAI,CAACc,cAAL,CAAoBL,gBAApB,EAAsCJ,CAAC,CAACM,KAAxC,CAAjB;EACA,IAAII,IAAI,GAAGF,QAAX;EACA,MAAMG,YAAY,GAAGlB,YAAY,CAACmB,kBAAb,CAAgCF,IAAhC,EAAsCL,KAAtC,CAArB;EACA,MAAMQ,oBAAoB,GAAGF,YAAY,IAAI,IAA7C;EACA,IAAIG,QAAQ,GAAGd,CAAf;;EACA,IAAIa,oBAAJ,EAA0B;IACtBC,QAAQ,GAAGhB,aAAa,CAACE,CAAD,EAAIW,YAAJ,EAAkBR,OAAlB,CAAxB;IACAO,IAAI,GAAGjB,YAAY,CAACsB,gBAAb,CAA8BL,IAAI,CAACH,MAAnC,EAA2CF,KAA3C,CAAP;EACH;;EACDZ,YAAY,CAACuB,0BAAb,CAAwC,KAAxC,EAA+CN,IAA/C,EAAqDL,KAArD;EACA,MAAM,CAACY,WAAD,EAAcC,WAAd,IAA6BzB,YAAY,CAAC0B,yBAAb,CAAuCL,QAAQ,CAACR,KAAhD,EAAuDI,IAAvD,CAAnC;EACA,IAAIU,QAAQ,GAAGH,WAAf;;EACA,IAAIf,QAAJ,EAAc;IACV;IACAkB,QAAQ,GAAG3B,YAAY,CAAC4B,oBAAb,CAAkCJ,WAAlC,EAA+CT,QAA/C,CAAX;EACH;;EACD,MAAMc,MAAM,GAAG3B,IAAI,CAAC4B,aAAL,CAAmBL,WAAnB,CAAf;EACA,MAAMM,KAAK,GAAG7B,IAAI,CAAC4B,aAAL,CAAmBvB,CAAC,CAACM,KAArB,CAAd;EACA,MAAMmB,SAAS,GAAGD,KAAK,GAAGF,MAA1B;EACA,MAAMI,aAAa,GAAG7B,OAAO,CAAC;IAAE8B,MAAM,EAAE;MAAE3B,CAAC,EAAEc;IAAL,CAAV;IAA2Bc,KAAK,EAAE;MAAEtB,KAAK,EAAE,CAACmB,SAAD,EAAYH,MAAZ;IAAT,CAAlC;IAAkEnB;EAAlE,CAAD,CAA7B;EACA,MAAM0B,OAAO,GAAGnC,UAAU,CAACM,CAAC,CAAC8B,KAAH,CAA1B;EACA,MAAMC,OAAO,GAAGnC,MAAM,CAAC8B,aAAD,EAAgBG,OAAhB,EAAyB,KAAzB,EAAgC1B,OAAhC,CAAtB;EACA,MAAM6B,GAAG,GAAGnC,OAAO,CAAC;IAAE8B,MAAM,EAAE;MAAE3B,CAAC,EAAE+B;IAAL,CAAV;IAA0BH,KAAK,EAAE;MAAEtB,KAAK,EAAEc;IAAT,CAAjC;IAAsDjB;EAAtD,CAAD,CAAnB;EACAA,OAAO,CAAC8B,6BAAR,CAAsCP,aAAtC;EACAvB,OAAO,CAAC8B,6BAAR,CAAsCF,OAAtC;;EACA,IAAIlB,oBAAJ,EAA0B;IACtBV,OAAO,CAAC8B,6BAAR,CAAsCnB,QAAtC;EACH;;EACD,OAAOkB,GAAP;AACH"},"metadata":{},"sourceType":"module"}